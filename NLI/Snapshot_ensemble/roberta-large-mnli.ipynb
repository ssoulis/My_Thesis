{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:05.082133Z",
     "iopub.status.busy": "2024-05-21T15:50:05.081746Z",
     "iopub.status.idle": "2024-05-21T15:50:06.080089Z",
     "shell.execute_reply": "2024-05-21T15:50:06.079131Z",
     "shell.execute_reply.started": "2024-05-21T15:50:05.082096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 28 01:53:32 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    57W / 400W |   5640MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    54W / 400W |      4MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    56W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  Off  | 00000000:4D:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    77W / 400W |   9452MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM...  On   | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    58W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM...  On   | 00000000:8D:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    61W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM...  On   | 00000000:C7:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    66W / 400W |      4MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM...  Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    63W / 400W |   1438MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    559832      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    0   N/A  N/A    570195      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    0   N/A  N/A   1716425      C   .../envs/torchenv/bin/python      850MiB |\n",
      "|    0   N/A  N/A   1769536      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    3   N/A  N/A    559832      C   .../envs/tsai_env/bin/python     3148MiB |\n",
      "|    3   N/A  N/A    570195      C   .../envs/tsai_env/bin/python     3150MiB |\n",
      "|    3   N/A  N/A   1769536      C   .../envs/tsai_env/bin/python     3152MiB |\n",
      "|    7   N/A  N/A   4094804      C   .../envs/torchenv/bin/python     1436MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:06.083286Z",
     "iopub.status.busy": "2024-05-21T15:50:06.082487Z",
     "iopub.status.idle": "2024-05-21T15:50:11.776437Z",
     "shell.execute_reply": "2024-05-21T15:50:11.775485Z",
     "shell.execute_reply.started": "2024-05-21T15:50:06.083243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      "0: NVIDIA A100-SXM4-40GB\n",
      "1: NVIDIA A100-SXM4-40GB\n",
      "2: NVIDIA A100-SXM4-40GB\n",
      "3: NVIDIA A100-SXM4-40GB\n",
      "4: NVIDIA A100-SXM4-40GB\n",
      "5: NVIDIA A100-SXM4-40GB\n",
      "6: NVIDIA A100-SXM4-40GB\n",
      "7: NVIDIA A100-SXM4-40GB\n",
      "Select GPU by entering the device ID (default 0): 0\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Function to list available GPUs and select one\n",
    "def select_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Available GPUs:\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"{i}: {torch.cuda.get_device_name(i)}\")\n",
    "        device_id = int(input(\"Select GPU by entering the device ID (default 0): \") or 0)\n",
    "        if device_id < torch.cuda.device_count():\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(device_id)}\")\n",
    "            return torch.device(f\"cuda:{device_id}\")\n",
    "        else:\n",
    "            print(f\"Invalid device ID. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            return torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# Select the device\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:11.777901Z",
     "iopub.status.busy": "2024-05-21T15:50:11.777525Z",
     "iopub.status.idle": "2024-05-21T15:50:19.547019Z",
     "shell.execute_reply": "2024-05-21T15:50:19.546204Z",
     "shell.execute_reply.started": "2024-05-21T15:50:11.777878Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Define the model and tokenizer for RoBERTa large\n",
    "model_name = \"FacebookAI/roberta-large\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Assuming 3 labels for the task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:19.549648Z",
     "iopub.status.busy": "2024-05-21T15:50:19.549248Z",
     "iopub.status.idle": "2024-05-21T15:50:22.771893Z",
     "shell.execute_reply": "2024-05-21T15:50:22.770944Z",
     "shell.execute_reply.started": "2024-05-21T15:50:19.549623Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# MNLI train dataset\n",
    "\n",
    "df_mnli_train = pd.read_csv('MNLI/mnli_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:22.773664Z",
     "iopub.status.busy": "2024-05-21T15:50:22.773301Z",
     "iopub.status.idle": "2024-05-21T15:50:22.793641Z",
     "shell.execute_reply": "2024-05-21T15:50:22.792608Z",
     "shell.execute_reply.started": "2024-05-21T15:50:22.773631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "      <td>This information belongs to them.</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "      <td>The tennis shoes have a range of prices.</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392697</th>\n",
       "      <td>Clearly, California can - and must - do better.</td>\n",
       "      <td>California cannot do any better.</td>\n",
       "      <td>2</td>\n",
       "      <td>392697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392698</th>\n",
       "      <td>It was once regarded as the most beautiful str...</td>\n",
       "      <td>So many of the original buildings had been rep...</td>\n",
       "      <td>1</td>\n",
       "      <td>392698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392699</th>\n",
       "      <td>Houseboats are a beautifully preserved traditi...</td>\n",
       "      <td>The tradition of houseboats originated while t...</td>\n",
       "      <td>0</td>\n",
       "      <td>392699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392700</th>\n",
       "      <td>Obituaries fondly recalled his on-air debates ...</td>\n",
       "      <td>The obituaries were beautiful and written in k...</td>\n",
       "      <td>1</td>\n",
       "      <td>392700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392701</th>\n",
       "      <td>in that other you know uh that i should do it ...</td>\n",
       "      <td>My husband has been so overworked lately that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>392701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392702 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  premise  \\\n",
       "0       Conceptually cream skimming has two basic dime...   \n",
       "1       you know during the season and i guess at at y...   \n",
       "2       One of our number will carry out your instruct...   \n",
       "3       How do you know? All this is their information...   \n",
       "4       yeah i tell you what though if you go price so...   \n",
       "...                                                   ...   \n",
       "392697    Clearly, California can - and must - do better.   \n",
       "392698  It was once regarded as the most beautiful str...   \n",
       "392699  Houseboats are a beautifully preserved traditi...   \n",
       "392700  Obituaries fondly recalled his on-air debates ...   \n",
       "392701  in that other you know uh that i should do it ...   \n",
       "\n",
       "                                               hypothesis  label     idx  \n",
       "0       Product and geography are what make cream skim...      1       0  \n",
       "1       You lose the things to the following level if ...      0       1  \n",
       "2       A member of my team will execute your orders w...      0       2  \n",
       "3                       This information belongs to them.      0       3  \n",
       "4                The tennis shoes have a range of prices.      1       4  \n",
       "...                                                   ...    ...     ...  \n",
       "392697                   California cannot do any better.      2  392697  \n",
       "392698  So many of the original buildings had been rep...      1  392698  \n",
       "392699  The tradition of houseboats originated while t...      0  392699  \n",
       "392700  The obituaries were beautiful and written in k...      1  392700  \n",
       "392701  My husband has been so overworked lately that ...      1  392701  \n",
       "\n",
       "[392702 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mnli_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:22.794950Z",
     "iopub.status.busy": "2024-05-21T15:50:22.794646Z",
     "iopub.status.idle": "2024-05-21T15:50:22.904314Z",
     "shell.execute_reply": "2024-05-21T15:50:22.903326Z",
     "shell.execute_reply.started": "2024-05-21T15:50:22.794926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 392702 entries, 0 to 392701\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   premise     392702 non-null  object\n",
      " 1   hypothesis  392662 non-null  object\n",
      " 2   label       392702 non-null  int64 \n",
      " 3   idx         392702 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_mnli_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:22.905792Z",
     "iopub.status.busy": "2024-05-21T15:50:22.905516Z",
     "iopub.status.idle": "2024-05-21T15:50:23.153282Z",
     "shell.execute_reply": "2024-05-21T15:50:23.152304Z",
     "shell.execute_reply.started": "2024-05-21T15:50:22.905768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "def clean_text_and_label_data(df):\n",
    "    # Drop any rows with NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Ensure text columns are of string type and labels are of integer type using .loc\n",
    "    df.loc[:, 'premise'] = df['premise'].astype(str)\n",
    "    df.loc[:, 'hypothesis'] = df['hypothesis'].astype(str)\n",
    "    df.loc[:, 'label'] = df['label'].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clean the entire dataset first\n",
    "df_mnli_train = clean_text_and_label_data(df_mnli_train)\n",
    "\n",
    "\n",
    "# Check for any NaN values across the entire DataFrame\n",
    "nan_check = df_mnli_train.isna().any().any()\n",
    "\n",
    "# Print the result to see if there are any NaN values left\n",
    "if nan_check:\n",
    "    print(\"There are still NaN values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"No NaN values found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:23.155017Z",
     "iopub.status.busy": "2024-05-21T15:50:23.154596Z",
     "iopub.status.idle": "2024-05-21T15:50:24.383152Z",
     "shell.execute_reply": "2024-05-21T15:50:24.382108Z",
     "shell.execute_reply.started": "2024-05-21T15:50:23.154967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (353395, 4)\n",
      "Test set size: (39267, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Now perform the train-test split\n",
    "train_df, test_df = train_test_split(df_mnli_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Verifying the size of the datasets\n",
    "print(f\"Training set size: {train_df.shape}\")\n",
    "print(f\"Test set size: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:50:24.384847Z",
     "iopub.status.busy": "2024-05-21T15:50:24.384387Z",
     "iopub.status.idle": "2024-05-21T15:54:26.604121Z",
     "shell.execute_reply": "2024-05-21T15:54:26.603108Z",
     "shell.execute_reply.started": "2024-05-21T15:50:24.384821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token length: 408\n",
      "Average token length: 20.335832089685276\n",
      "95th percentile of token lengths: 46.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to tokenize and calculate the length of tokenized sentences\n",
    "def calculate_token_lengths(texts, tokenizer):\n",
    "    token_lengths = []\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=True)  # add_special_tokens=True for [CLS] and [SEP]\n",
    "        token_lengths.append(len(tokens))\n",
    "    return token_lengths\n",
    "\n",
    "# Concatenate premises and hypotheses for length calculation\n",
    "all_texts = pd.concat([df_mnli_train['premise'], df_mnli_train['hypothesis']]).dropna()\n",
    "\n",
    "# Calculate token lengths\n",
    "token_lengths = calculate_token_lengths(all_texts, tokenizer)\n",
    "\n",
    "# Basic statistics about token lengths\n",
    "max_length = np.max(token_lengths)\n",
    "avg_length = np.mean(token_lengths)\n",
    "percentile_95 = np.percentile(token_lengths, 95)  # 95th percentile\n",
    "\n",
    "print(f\"Maximum token length: {max_length}\")\n",
    "print(f\"Average token length: {avg_length}\")\n",
    "print(f\"95th percentile of token lengths: {percentile_95}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T15:54:26.606889Z",
     "iopub.status.busy": "2024-05-21T15:54:26.606599Z",
     "iopub.status.idle": "2024-05-21T15:58:13.764226Z",
     "shell.execute_reply": "2024-05-21T15:58:13.763301Z",
     "shell.execute_reply.started": "2024-05-21T15:54:26.606864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input IDs shape: torch.Size([353395, 50])\n",
      "Validation input IDs shape: torch.Size([39267, 50])\n",
      "Training labels shape: torch.Size([353395])\n",
      "Validation labels shape: torch.Size([39267])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "def tokenize_and_prepare_inputs(df, tokenizer, max_length=50):\n",
    "    # Tokenize, pad, and create attention masks\n",
    "    # 'max_length' is a parameter you can tune depending on the maximum length you observed in your dataset analysis\n",
    "    tokenized_inputs = tokenizer(\n",
    "        df['premise'].tolist(),\n",
    "        df['hypothesis'].tolist(),\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Extracting input_ids and attention masks from the tokenized inputs\n",
    "    input_ids = tokenized_inputs['input_ids']\n",
    "    attention_masks = tokenized_inputs['attention_mask']\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize training data\n",
    "train_input_ids, train_attention_masks = tokenize_and_prepare_inputs(train_df, tokenizer)\n",
    "\n",
    "# Tokenize validation (test) data\n",
    "validation_input_ids, validation_attention_masks = tokenize_and_prepare_inputs(test_df, tokenizer)\n",
    "\n",
    "# Convert labels to tensors\n",
    "train_labels = torch.tensor(train_df['label'].values)\n",
    "validation_labels = torch.tensor(test_df['label'].values)\n",
    "\n",
    "# Print some details to verify everything is as expected\n",
    "print(\"Training input IDs shape:\", train_input_ids.shape)\n",
    "print(\"Validation input IDs shape:\", validation_input_ids.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Validation labels shape:\", validation_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T16:01:13.887206Z",
     "iopub.status.busy": "2024-05-21T16:01:13.886607Z",
     "iopub.status.idle": "2024-05-21T16:01:13.894814Z",
     "shell.execute_reply": "2024-05-21T16:01:13.893908Z",
     "shell.execute_reply.started": "2024-05-21T16:01:13.887173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader setup with 11044 batches of size 32.\n",
      "Validation DataLoader setup with 1228 batches of size 32.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming you have train_input_ids, train_attention_masks, train_labels,\n",
    "# validation_input_ids, validation_attention_masks, validation_labels already defined\n",
    "\n",
    "# Create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "validation_dataset = TensorDataset(validation_input_ids, validation_attention_masks, validation_labels)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32  # You can adjust this based on your GPU memory availability and model complexity\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print to confirm setup\n",
    "print(f\"Train DataLoader setup with {len(train_loader)} batches of size {batch_size}.\")\n",
    "print(f\"Validation DataLoader setup with {len(validation_loader)} batches of size {batch_size}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T16:03:51.142523Z",
     "iopub.status.busy": "2024-05-21T16:03:51.141694Z",
     "iopub.status.idle": "2024-05-21T16:04:08.217384Z",
     "shell.execute_reply": "2024-05-21T16:04:08.216093Z",
     "shell.execute_reply.started": "2024-05-21T16:03:51.142487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d81fc50d17461f9aa444b7d4d0102e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/11044 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 11044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1228 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.3235 | Validation Accuracy: 87.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d7459f54544072adb85f6c8ff9a80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/11044 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 22088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1228 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.3364 | Validation Accuracy: 87.84%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9be6e87441414d9520b3805a0cdf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/11044 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 33132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1228 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.3641 | Validation Accuracy: 87.84%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d33a633447c4f69a48231e4a1f96c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/11044 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 44176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1228 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.4127 | Validation Accuracy: 87.56%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb71f01cec41428990f50740377563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/11044 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 55220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1228 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.4747 | Validation Accuracy: 87.35%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "\n",
    "# CLR Scheduler setup\n",
    "scheduler = CyclicLR(optimizer, base_lr=5e-6, max_lr=1e-5, \n",
    "                     step_size_up=len(train_loader)//2, step_size_down=len(train_loader)//2,\n",
    "                     mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# Ensure the save directory exists\n",
    "save_path = '/storage/data/st1070263'\n",
    "\n",
    "\n",
    "# Training and validation functions\n",
    "def train_model(model, train_loader, validation_loader, optimizer, scheduler, epochs=3):\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch')\n",
    "\n",
    "        for batch_index, (input_ids, attention_masks, labels) in enumerate(progress_bar):\n",
    "            input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n",
    "            model.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update the learning rate after each batch\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            accuracy = 100. * correct / total\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "            progress_bar.set_postfix(loss=train_loss/(batch_index + 1), accuracy=f'{accuracy:.2f}%', lr=f'{lr:.6f}')\n",
    "\n",
    "            # Save snapshot at the end of each cycle\n",
    "            current_step = epoch * steps_per_epoch + batch_index\n",
    "            if (current_step + 1) % scheduler.total_size == 0:\n",
    "                torch.save(model.state_dict(), f'{save_path}/roberta_large_mnli_cycle_{current_step + 1}.pth')\n",
    "                print(f\"Snapshot saved at step {current_step + 1}\")\n",
    "\n",
    "        validate_model(model, validation_loader, device)\n",
    "\n",
    "def validate_model(model, validation_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_masks, labels in tqdm(validation_loader, desc='Validating', leave=False, unit='batch'):\n",
    "            input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100. * correct / total\n",
    "    print(f'\\nValidation Loss: {val_loss / len(validation_loader):.4f} | Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "# Start training\n",
    "train_model(model, train_loader, validation_loader, optimizer, scheduler, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1670,
     "sourceId": 2933,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2655798,
     "sourceId": 4548821,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2656775,
     "sourceId": 4550791,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4771616,
     "sourceId": 8083662,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4771621,
     "sourceId": 8083668,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4771629,
     "sourceId": 8083678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4772442,
     "sourceId": 8084913,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
