{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:38:06.748340Z",
     "iopub.status.busy": "2024-05-28T12:38:06.748076Z",
     "iopub.status.idle": "2024-05-28T12:38:07.732133Z",
     "shell.execute_reply": "2024-05-28T12:38:07.730991Z",
     "shell.execute_reply.started": "2024-05-28T12:38:06.748316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 29 20:00:15 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    56W / 400W |   5640MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    72W / 400W |  38006MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    56W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  Off  | 00000000:4D:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    59W / 400W |   9452MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM...  On   | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    52W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM...  On   | 00000000:8D:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    54W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM...  On   | 00000000:C7:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    73W / 400W |  38006MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM...  Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    50W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    559832      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    0   N/A  N/A    570195      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    0   N/A  N/A   1716425      C   .../envs/torchenv/bin/python      850MiB |\n",
      "|    0   N/A  N/A   1769536      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    1   N/A  N/A   3851212      C   ...onserver/bin/tritonserver    37520MiB |\n",
      "|    1   N/A  N/A   3851213      C   ...onserver/bin/tritonserver      478MiB |\n",
      "|    3   N/A  N/A    559832      C   .../envs/tsai_env/bin/python     3148MiB |\n",
      "|    3   N/A  N/A    570195      C   .../envs/tsai_env/bin/python     3150MiB |\n",
      "|    3   N/A  N/A   1769536      C   .../envs/tsai_env/bin/python     3152MiB |\n",
      "|    6   N/A  N/A   3851212      C   ...onserver/bin/tritonserver      478MiB |\n",
      "|    6   N/A  N/A   3851213      C   ...onserver/bin/tritonserver    37520MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:38:07.734203Z",
     "iopub.status.busy": "2024-05-28T12:38:07.733882Z",
     "iopub.status.idle": "2024-05-28T12:40:37.039336Z",
     "shell.execute_reply": "2024-05-28T12:40:37.038387Z",
     "shell.execute_reply.started": "2024-05-28T12:38:07.734173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      "0: NVIDIA A100-SXM4-40GB\n",
      "1: NVIDIA A100-SXM4-40GB\n",
      "2: NVIDIA A100-SXM4-40GB\n",
      "3: NVIDIA A100-SXM4-40GB\n",
      "4: NVIDIA A100-SXM4-40GB\n",
      "5: NVIDIA A100-SXM4-40GB\n",
      "6: NVIDIA A100-SXM4-40GB\n",
      "7: NVIDIA A100-SXM4-40GB\n",
      "Select GPU by entering the device ID (default 0): 0\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Function to list available GPUs and select one\n",
    "def select_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Available GPUs:\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"{i}: {torch.cuda.get_device_name(i)}\")\n",
    "        device_id = int(input(\"Select GPU by entering the device ID (default 0): \") or 0)\n",
    "        if device_id < torch.cuda.device_count():\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(device_id)}\")\n",
    "            return torch.device(f\"cuda:{device_id}\")\n",
    "        else:\n",
    "            print(f\"Invalid device ID. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            return torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# Select the device\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:40:37.040853Z",
     "iopub.status.busy": "2024-05-28T12:40:37.040426Z",
     "iopub.status.idle": "2024-05-28T12:40:48.079886Z",
     "shell.execute_reply": "2024-05-28T12:40:48.079101Z",
     "shell.execute_reply.started": "2024-05-28T12:40:37.040827Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Define the model and tokenizer for DeBERTa v3 large\n",
    "model_name = \"microsoft/deberta-v3-large\"\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(model_name)\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Assuming 3 labels for NLI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:40:48.082431Z",
     "iopub.status.busy": "2024-05-28T12:40:48.082015Z",
     "iopub.status.idle": "2024-05-28T12:40:49.389954Z",
     "shell.execute_reply": "2024-05-28T12:40:49.388624Z",
     "shell.execute_reply.started": "2024-05-28T12:40:48.082406Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ANLItrain dataset\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('ANLI/train_r1.csv')\n",
    "dev_df = pd.read_csv('ANLI/dev_r1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:41:43.216284Z",
     "iopub.status.busy": "2024-05-28T12:41:43.215621Z",
     "iopub.status.idle": "2024-05-28T12:41:43.241059Z",
     "shell.execute_reply": "2024-05-28T12:41:43.239890Z",
     "shell.execute_reply.started": "2024-05-28T12:41:43.216254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in the train DataFrame.\n",
      "No NaN values found in the eval DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and concatenation of premise, hypothesis, and reason\n",
    "def clean_and_concatenate(df):\n",
    "    # Fill NaN values in 'reason' column with empty strings\n",
    "    df['reason'] = df['reason'].fillna('')\n",
    "    # Concatenate texts\n",
    "    df['text'] = df['premise'] + \" [SEP] \" + df['hypothesis'] + \" [SEP] \" + df['reason']\n",
    "    return df.dropna(subset=['text', 'label'])\n",
    "\n",
    "train_df = clean_and_concatenate(train_df)\n",
    "dev_df = clean_and_concatenate(dev_df)\n",
    "\n",
    "\n",
    "\n",
    "# Check for any NaN values across the entire DataFrame\n",
    "nan_check1 = train_df.isna().any().any()\n",
    "nan_check2 = dev_df.isna().any().any()\n",
    "\n",
    "# Print the result to see if there are any NaN values left\n",
    "if nan_check1:\n",
    "    print(\"There are still NaN values in the train DataFrame.\")\n",
    "else:\n",
    "    print(\"No NaN values found in the train DataFrame.\")\n",
    "\n",
    "# Print the result to see if there are any NaN values left\n",
    "if nan_check2:\n",
    "    print(\"There are still NaN values in the eval DataFrame.\")\n",
    "else:\n",
    "    print(\"No NaN values found in the eval DataFrame.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:41:47.018625Z",
     "iopub.status.busy": "2024-05-28T12:41:47.017926Z",
     "iopub.status.idle": "2024-05-28T12:41:47.023828Z",
     "shell.execute_reply": "2024-05-28T12:41:47.022709Z",
     "shell.execute_reply.started": "2024-05-28T12:41:47.018595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (16946, 6)\n",
      "Test set size: (1000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Verifying the size of the datasets\n",
    "print(f\"Training set size: {train_df.shape}\")\n",
    "print(f\"Test set size: {dev_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:42:56.550105Z",
     "iopub.status.busy": "2024-05-28T12:42:56.549722Z",
     "iopub.status.idle": "2024-05-28T12:42:59.992814Z",
     "shell.execute_reply": "2024-05-28T12:42:59.991839Z",
     "shell.execute_reply.started": "2024-05-28T12:42:56.550075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token length: 255\n",
      "Average token length: 92.86055706361383\n",
      "95th percentile of token lengths: 129.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to concatenate and clean data for token length calculation\n",
    "def prepare_text_for_token_length(df):\n",
    "    # Filling NaN values in 'reason' with empty strings for safe concatenation\n",
    "    df['reason'] = df['reason'].fillna('')\n",
    "    # Concatenate 'premise', 'hypothesis', and 'reason' into a single string\n",
    "    concatenated_texts = df['premise'] + \" [SEP] \" + df['hypothesis'] + \" [SEP] \" + df['reason']\n",
    "    return concatenated_texts.dropna()\n",
    "\n",
    "# Function to calculate token lengths\n",
    "def calculate_token_lengths(texts, tokenizer):\n",
    "    token_lengths = []\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=True)  # Using [CLS] and [SEP] tokens\n",
    "        token_lengths.append(len(tokens))\n",
    "    return token_lengths\n",
    "\n",
    "# Prepare texts for token length calculation by including 'reason'\n",
    "all_texts = prepare_text_for_token_length(train_df)  # Assuming train_df is your DataFrame after cleaning\n",
    "\n",
    "# Calculate token lengths using the tokenizer\n",
    "token_lengths = calculate_token_lengths(all_texts, tokenizer)\n",
    "\n",
    "# Compute basic statistics about token lengths\n",
    "max_length = np.max(token_lengths)\n",
    "avg_length = np.mean(token_lengths)\n",
    "percentile_95 = np.percentile(token_lengths, 95)  # 95th percentile, commonly used for setting max token length\n",
    "\n",
    "print(f\"Maximum token length: {max_length}\")\n",
    "print(f\"Average token length: {avg_length}\")\n",
    "print(f\"95th percentile of token lengths: {percentile_95}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-28T12:40:49.876327Z",
     "iopub.status.idle": "2024-05-28T12:40:49.876668Z",
     "shell.execute_reply": "2024-05-28T12:40:49.876522Z",
     "shell.execute_reply.started": "2024-05-28T12:40:49.876509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input IDs shape: torch.Size([16946, 150])\n",
      "Validation input IDs shape: torch.Size([1000, 150])\n",
      "Training labels shape: torch.Size([16946])\n",
      "Validation labels shape: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "# Tokenization and data preparation\n",
    "def tokenize_data(df, tokenizer, max_len=150):\n",
    "    tokenized = tokenizer(\n",
    "        df['text'].tolist(),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokenized['input_ids'], tokenized['attention_mask']\n",
    "\n",
    "# Tokenize datasets\n",
    "max_token_len = 150  # You can adjust this based on your specific needs\n",
    "train_input_ids, train_attention_masks = tokenize_data(train_df, tokenizer, max_token_len)\n",
    "dev_input_ids, dev_attention_masks = tokenize_data(dev_df, tokenizer, max_token_len)\n",
    "\n",
    "train_labels = torch.tensor(train_df['label'].values)\n",
    "dev_labels = torch.tensor(dev_df['label'].values)\n",
    "\n",
    "\n",
    "# Print some details to verify everything is as expected\n",
    "print(\"Training input IDs shape:\", train_input_ids.shape)\n",
    "print(\"Validation input IDs shape:\", dev_input_ids.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Validation labels shape:\", dev_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-28T12:40:49.878036Z",
     "iopub.status.idle": "2024-05-28T12:40:49.878333Z",
     "shell.execute_reply": "2024-05-28T12:40:49.878197Z",
     "shell.execute_reply.started": "2024-05-28T12:40:49.878185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader setup with 1060 batches of size 16.\n",
      "Validation DataLoader setup with 63 batches of size 16.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create TensorDataset\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "dev_dataset = TensorDataset(dev_input_ids, dev_attention_masks, dev_labels)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print to confirm setup\n",
    "print(f\"Train DataLoader setup with {len(train_loader)} batches of size {batch_size}.\")\n",
    "print(f\"Validation DataLoader setup with {len(dev_loader)} batches of size {batch_size}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-28T12:40:49.879780Z",
     "iopub.status.idle": "2024-05-28T12:40:49.880104Z",
     "shell.execute_reply": "2024-05-28T12:40:49.879959Z",
     "shell.execute_reply.started": "2024-05-28T12:40:49.879945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075ef971bf1f4457be3a0ab7f57463f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1060 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 1060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/63 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.4857 | Validation Accuracy: 81.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7168b3fb1fdc4add9735989e3e50568e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1060 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 2120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/63 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.4800 | Validation Accuracy: 82.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137eeece02a40538842fa3bd9d63166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1060 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 3180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/63 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.4847 | Validation Accuracy: 83.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadb3afdaf76486ab5462bafc6610024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1060 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 4240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/63 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.5556 | Validation Accuracy: 82.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc23b8048e947b38a6f4497d44008e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1060 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot saved at step 5300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/63 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Loss: 0.5738 | Validation Accuracy: 84.30%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "\n",
    "# CLR Scheduler setup\n",
    "scheduler = CyclicLR(optimizer, base_lr=5e-6, max_lr=1e-5, \n",
    "                     step_size_up=len(train_loader)//2, step_size_down=len(train_loader)//2,\n",
    "                     mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# Ensure the save directory exists\n",
    "save_path = '/storage/data/st1070263'\n",
    "\n",
    "\n",
    "# Training and validation functions\n",
    "def train_model(model, train_loader, dev_loader, optimizer, scheduler, epochs=3):\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch')\n",
    "\n",
    "        for batch_index, (input_ids, attention_masks, labels) in enumerate(progress_bar):\n",
    "            input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n",
    "            model.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update the learning rate after each batch\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            accuracy = 100. * correct / total\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "            progress_bar.set_postfix(loss=train_loss/(batch_index + 1), accuracy=f'{accuracy:.2f}%', lr=f'{lr:.6f}')\n",
    "\n",
    "            # Save snapshot at the end of each cycle\n",
    "            current_step = epoch * steps_per_epoch + batch_index\n",
    "            if (current_step + 1) % scheduler.total_size == 0:\n",
    "                torch.save(model.state_dict(), f'{save_path}/deberta_large_anli1_cycle_{current_step + 1}.pth')\n",
    "                print(f\"Snapshot saved at step {current_step + 1}\")\n",
    "\n",
    "        validate_model(model, dev_loader, device)\n",
    "\n",
    "# Update the parameter to dev_loader instead of validation_loader\n",
    "def validate_model(model, dev_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_masks, labels in tqdm(dev_loader, desc='Validating', leave=False, unit='batch'):\n",
    "            input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100. * correct / total\n",
    "    print(f'\\nValidation Loss: {val_loss / len(dev_loader):.4f} | Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# Start training with the correct validation DataLoader\n",
    "train_model(model, train_loader, dev_loader, optimizer, scheduler, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1670,
     "sourceId": 2933,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2655798,
     "sourceId": 4548821,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2656775,
     "sourceId": 4550791,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4771616,
     "sourceId": 8083662,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4771621,
     "sourceId": 8083668,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4771629,
     "sourceId": 8083678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4772442,
     "sourceId": 8084913,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
