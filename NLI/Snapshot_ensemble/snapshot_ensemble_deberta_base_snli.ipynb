{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 18 16:47:35 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    70W / 400W |   5640MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   24C    P0    51W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    55W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  Off  | 00000000:4D:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    59W / 400W |   9452MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM...  Off  | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    55W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM...  Off  | 00000000:8D:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    76W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM...  Off  | 00000000:C7:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    52W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM...  Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    55W / 400W |   4626MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    559832      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    0   N/A  N/A    570195      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    0   N/A  N/A   1716425      C   .../envs/torchenv/bin/python      850MiB |\n",
      "|    0   N/A  N/A   1769536      C   .../envs/tsai_env/bin/python     1596MiB |\n",
      "|    3   N/A  N/A    559832      C   .../envs/tsai_env/bin/python     3148MiB |\n",
      "|    3   N/A  N/A    570195      C   .../envs/tsai_env/bin/python     3150MiB |\n",
      "|    3   N/A  N/A   1769536      C   .../envs/tsai_env/bin/python     3152MiB |\n",
      "|    7   N/A  N/A   1157318      C   .../envs/torchenv/bin/python     1430MiB |\n",
      "|    7   N/A  N/A   2682638      C   .../envs/torchenv/bin/python     1598MiB |\n",
      "|    7   N/A  N/A   2722600      C   .../envs/torchenv/bin/python     1596MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      "0: NVIDIA A100-SXM4-40GB\n",
      "1: NVIDIA A100-SXM4-40GB\n",
      "2: NVIDIA A100-SXM4-40GB\n",
      "3: NVIDIA A100-SXM4-40GB\n",
      "4: NVIDIA A100-SXM4-40GB\n",
      "5: NVIDIA A100-SXM4-40GB\n",
      "6: NVIDIA A100-SXM4-40GB\n",
      "7: NVIDIA A100-SXM4-40GB\n",
      "Select GPU by entering the device ID (default 0): 0\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Function to list available GPUs and select one\n",
    "def select_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Available GPUs:\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"{i}: {torch.cuda.get_device_name(i)}\")\n",
    "        device_id = int(input(\"Select GPU by entering the device ID (default 0): \") or 0)\n",
    "        if device_id < torch.cuda.device_count():\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(device_id)}\")\n",
    "            return torch.device(f\"cuda:{device_id}\")\n",
    "        else:\n",
    "            print(f\"Invalid device ID. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            return torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# Select the device\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Device Configuration\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import DebertaV2ForSequenceClassification\n",
    "\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(snapshot_path, model_name=\"microsoft/deberta-v3-base\", num_labels=3):\n",
    "    model = DebertaV2ForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    model.load_state_dict(torch.load(snapshot_path, map_location=device))\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "# Function to list all model snapshot files in a directory\n",
    "def list_snapshot_files(snapshot_directory):\n",
    "    return [os.path.join(snapshot_directory, file_name) for file_name in os.listdir(snapshot_directory) if file_name.endswith('.pth')]\n",
    "\n",
    "# Load all models\n",
    "snapshot_directory = 'Snapshots'\n",
    "snapshot_files = list_snapshot_files(snapshot_directory)\n",
    "model_snapshots = [load_model(snapshot) for snapshot in snapshot_files]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This church choir sings to the masses as they ...</td>\n",
       "      <td>The church has cracks in the ceiling.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This church choir sings to the masses as they ...</td>\n",
       "      <td>The church is filled with song.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This church choir sings to the masses as they ...</td>\n",
       "      <td>A choir singing at a baseball game.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
       "      <td>The woman is young.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman with a green headscarf, blue shirt and...</td>\n",
       "      <td>The woman is very happy.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Two women are observing something together.</td>\n",
       "      <td>Two women are standing with their eyes closed.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Two women are observing something together.</td>\n",
       "      <td>Two girls are looking at something.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>A man in a black leather jacket and a book in ...</td>\n",
       "      <td>A man is flying a kite.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A man in a black leather jacket and a book in ...</td>\n",
       "      <td>A man is speaking in a classroom.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>A man in a black leather jacket and a book in ...</td>\n",
       "      <td>A man is teaching science in a classroom.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "0     This church choir sings to the masses as they ...   \n",
       "1     This church choir sings to the masses as they ...   \n",
       "2     This church choir sings to the masses as they ...   \n",
       "3     A woman with a green headscarf, blue shirt and...   \n",
       "4     A woman with a green headscarf, blue shirt and...   \n",
       "...                                                 ...   \n",
       "9995        Two women are observing something together.   \n",
       "9996        Two women are observing something together.   \n",
       "9997  A man in a black leather jacket and a book in ...   \n",
       "9998  A man in a black leather jacket and a book in ...   \n",
       "9999  A man in a black leather jacket and a book in ...   \n",
       "\n",
       "                                           sentence2     gold_label  \n",
       "0              The church has cracks in the ceiling.        neutral  \n",
       "1                    The church is filled with song.     entailment  \n",
       "2                A choir singing at a baseball game.  contradiction  \n",
       "3                                The woman is young.        neutral  \n",
       "4                           The woman is very happy.     entailment  \n",
       "...                                              ...            ...  \n",
       "9995  Two women are standing with their eyes closed.  contradiction  \n",
       "9996             Two girls are looking at something.     entailment  \n",
       "9997                         A man is flying a kite.  contradiction  \n",
       "9998               A man is speaking in a classroom.     entailment  \n",
       "9999       A man is teaching science in a classroom.        neutral  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the test data\n",
    "test_data_path = 'SNLI/snli_1.0_test.csv'\n",
    "df_snli_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# Select the necessary columns\n",
    "df_snli_test = df_snli_test[['sentence1', 'sentence2', 'gold_label']]\n",
    "\n",
    "\n",
    "df_snli_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentences to lowercase\n",
    "df_snli_test['sentence1'] = df_snli_test['sentence1'].str.lower()\n",
    "df_snli_test['sentence2'] = df_snli_test['sentence2'].str.lower()\n",
    "\n",
    "# Map textual labels to integers (ensure this matches your training setup)\n",
    "label_mapping = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "df_snli_test['gold_label'] = df_snli_test['gold_label'].map(label_mapping)\n",
    "\n",
    "# Drop any rows with NaN values which may result from missing labels\n",
    "df_snli_test.dropna(subset=['sentence1', 'sentence2', 'gold_label'], inplace=True)\n",
    "\n",
    "# Convert 'gold_label' to integer type as it may be required by the model\n",
    "df_snli_test['gold_label'] = df_snli_test['gold_label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this church choir sings to the masses as they ...</td>\n",
       "      <td>the church has cracks in the ceiling.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this church choir sings to the masses as they ...</td>\n",
       "      <td>the church is filled with song.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this church choir sings to the masses as they ...</td>\n",
       "      <td>a choir singing at a baseball game.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a woman with a green headscarf, blue shirt and...</td>\n",
       "      <td>the woman is young.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a woman with a green headscarf, blue shirt and...</td>\n",
       "      <td>the woman is very happy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  this church choir sings to the masses as they ...   \n",
       "1  this church choir sings to the masses as they ...   \n",
       "2  this church choir sings to the masses as they ...   \n",
       "3  a woman with a green headscarf, blue shirt and...   \n",
       "4  a woman with a green headscarf, blue shirt and...   \n",
       "\n",
       "                               sentence2  gold_label  \n",
       "0  the church has cracks in the ceiling.           1  \n",
       "1        the church is filled with song.           0  \n",
       "2    a choir singing at a baseball game.           2  \n",
       "3                    the woman is young.           1  \n",
       "4               the woman is very happy.           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snli_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "0    3368\n",
       "2    3237\n",
       "1    3219\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snli_test['gold_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaV2Tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Assuming the tokenizer has already been defined elsewhere in your notebook\n",
    "# If not, reinitialize it here\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "\n",
    "class SNLITestDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping tensors for SNLI test data.\"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Tokenize the test data\n",
    "def tokenize_data(df, tokenizer):\n",
    "    return tokenizer(df['sentence1'].tolist(), df['sentence2'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Prepare the test dataset\n",
    "encodings = tokenize_data(df_snli_test, tokenizer)\n",
    "test_dataset = SNLITestDataset(encodings, df_snli_test['gold_label'].tolist())\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Adjust batch size based on your system's capability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                                                                   | 0/307 [00:00<?, ?it/s]/tmp/ipykernel_3916906/2879907429.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                            \r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Evaluate model and get predictions\n",
    "def get_model_predictions(model, loader):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            all_probs.append(probabilities.detach())\n",
    "    torch.cuda.empty_cache()\n",
    "    return torch.cat(all_probs, dim=0)\n",
    "\n",
    "model_probs = {}\n",
    "for i, model in enumerate(model_snapshots):\n",
    "    print(f\"Processing Model {i+1}\")\n",
    "    probabilities = get_model_predictions(model, test_loader)\n",
    "    model_probs[f'model_{i+1}_probs'] = probabilities.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions stored in 'model_probabilities.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "model_prob_df = pd.DataFrame()\n",
    "for key, probs in model_probs.items():\n",
    "    df_probs = pd.DataFrame(probs, columns=[f'{key}_class_0', f'{key}_class_1', f'{key}_class_2'])\n",
    "    model_prob_df = pd.concat([model_prob_df, df_probs], axis=1)\n",
    "\n",
    "model_prob_df.to_csv('model_probabilities.csv', index=False)\n",
    "print(\"Model predictions stored in 'model_probabilities.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1_probs_class_0</th>\n",
       "      <th>model_1_probs_class_1</th>\n",
       "      <th>model_1_probs_class_2</th>\n",
       "      <th>model_2_probs_class_0</th>\n",
       "      <th>model_2_probs_class_1</th>\n",
       "      <th>model_2_probs_class_2</th>\n",
       "      <th>model_3_probs_class_0</th>\n",
       "      <th>model_3_probs_class_1</th>\n",
       "      <th>model_3_probs_class_2</th>\n",
       "      <th>model_4_probs_class_0</th>\n",
       "      <th>model_4_probs_class_1</th>\n",
       "      <th>model_4_probs_class_2</th>\n",
       "      <th>model_5_probs_class_0</th>\n",
       "      <th>model_5_probs_class_1</th>\n",
       "      <th>model_5_probs_class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.984123</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.885760</td>\n",
       "      <td>0.109031</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.874816</td>\n",
       "      <td>0.114748</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.997485</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.996107</td>\n",
       "      <td>0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933360</td>\n",
       "      <td>0.066387</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.919744</td>\n",
       "      <td>0.078766</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.872018</td>\n",
       "      <td>0.122956</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.954541</td>\n",
       "      <td>0.045271</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.944261</td>\n",
       "      <td>0.055517</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.990607</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.999135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.980574</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.010341</td>\n",
       "      <td>0.989316</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.982003</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.993846</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.989614</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451494</td>\n",
       "      <td>0.548059</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.642906</td>\n",
       "      <td>0.356337</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.679323</td>\n",
       "      <td>0.319482</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.223343</td>\n",
       "      <td>0.776097</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.634156</td>\n",
       "      <td>0.365477</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.997740</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.996242</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.998738</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.998604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>0.879818</td>\n",
       "      <td>0.118495</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.933448</td>\n",
       "      <td>0.062962</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.964908</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.871968</td>\n",
       "      <td>0.125429</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.861723</td>\n",
       "      <td>0.136308</td>\n",
       "      <td>0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.999907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9822</th>\n",
       "      <td>0.987308</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.987050</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.987734</td>\n",
       "      <td>0.011960</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.980925</td>\n",
       "      <td>0.018765</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.987907</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9823</th>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.995855</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.995026</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.986951</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.995344</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.004025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9824 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_1_probs_class_0  model_1_probs_class_1  model_1_probs_class_2  \\\n",
       "0                  0.003650               0.984123               0.012227   \n",
       "1                  0.933360               0.066387               0.000253   \n",
       "2                  0.000043               0.000703               0.999254   \n",
       "3                  0.019063               0.980574               0.000362   \n",
       "4                  0.451494               0.548059               0.000447   \n",
       "...                     ...                    ...                    ...   \n",
       "9819               0.000059               0.000364               0.999578   \n",
       "9820               0.879818               0.118495               0.001687   \n",
       "9821               0.000029               0.000065               0.999906   \n",
       "9822               0.987308               0.012535               0.000157   \n",
       "9823               0.000713               0.995855               0.003432   \n",
       "\n",
       "      model_2_probs_class_0  model_2_probs_class_1  model_2_probs_class_2  \\\n",
       "0                  0.005208               0.885760               0.109031   \n",
       "1                  0.919744               0.078766               0.001490   \n",
       "2                  0.000249               0.003541               0.996210   \n",
       "3                  0.010341               0.989316               0.000343   \n",
       "4                  0.642906               0.356337               0.000757   \n",
       "...                     ...                    ...                    ...   \n",
       "9819               0.000443               0.001817               0.997740   \n",
       "9820               0.933448               0.062962               0.003590   \n",
       "9821               0.000119               0.000124               0.999757   \n",
       "9822               0.987050               0.012126               0.000823   \n",
       "9823               0.001109               0.995026               0.003865   \n",
       "\n",
       "      model_3_probs_class_0  model_3_probs_class_1  model_3_probs_class_2  \\\n",
       "0                  0.010436               0.874816               0.114748   \n",
       "1                  0.872018               0.122956               0.005025   \n",
       "2                  0.000629               0.008764               0.990607   \n",
       "3                  0.017067               0.982003               0.000930   \n",
       "4                  0.679323               0.319482               0.001194   \n",
       "...                     ...                    ...                    ...   \n",
       "9819               0.000427               0.003330               0.996242   \n",
       "9820               0.964908               0.033915               0.001177   \n",
       "9821               0.000155               0.000321               0.999524   \n",
       "9822               0.987734               0.011960               0.000306   \n",
       "9823               0.001514               0.986951               0.011535   \n",
       "\n",
       "      model_4_probs_class_0  model_4_probs_class_1  model_4_probs_class_2  \\\n",
       "0                  0.001246               0.997485               0.001269   \n",
       "1                  0.954541               0.045271               0.000188   \n",
       "2                  0.000021               0.000568               0.999411   \n",
       "3                  0.005564               0.993846               0.000589   \n",
       "4                  0.223343               0.776097               0.000560   \n",
       "...                     ...                    ...                    ...   \n",
       "9819               0.000146               0.001116               0.998738   \n",
       "9820               0.871968               0.125429               0.002602   \n",
       "9821               0.000009               0.000048               0.999943   \n",
       "9822               0.980925               0.018765               0.000310   \n",
       "9823               0.000498               0.995344               0.004159   \n",
       "\n",
       "      model_5_probs_class_0  model_5_probs_class_1  model_5_probs_class_2  \n",
       "0                  0.002010               0.996107               0.001882  \n",
       "1                  0.944261               0.055517               0.000221  \n",
       "2                  0.000059               0.000806               0.999135  \n",
       "3                  0.010004               0.989614               0.000382  \n",
       "4                  0.634156               0.365477               0.000367  \n",
       "...                     ...                    ...                    ...  \n",
       "9819               0.000236               0.001161               0.998604  \n",
       "9820               0.861723               0.136308               0.001969  \n",
       "9821               0.000028               0.000066               0.999907  \n",
       "9822               0.987907               0.011804               0.000289  \n",
       "9823               0.000346               0.995629               0.004025  \n",
       "\n",
       "[9824 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1_probs_class_0</th>\n",
       "      <th>model_1_probs_class_1</th>\n",
       "      <th>model_1_probs_class_2</th>\n",
       "      <th>model_2_probs_class_0</th>\n",
       "      <th>model_2_probs_class_1</th>\n",
       "      <th>model_2_probs_class_2</th>\n",
       "      <th>model_3_probs_class_0</th>\n",
       "      <th>model_3_probs_class_1</th>\n",
       "      <th>model_3_probs_class_2</th>\n",
       "      <th>model_4_probs_class_0</th>\n",
       "      <th>model_4_probs_class_1</th>\n",
       "      <th>model_4_probs_class_2</th>\n",
       "      <th>model_5_probs_class_0</th>\n",
       "      <th>model_5_probs_class_1</th>\n",
       "      <th>model_5_probs_class_2</th>\n",
       "      <th>True_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.984123</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.885760</td>\n",
       "      <td>0.109031</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.874816</td>\n",
       "      <td>0.114748</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.997485</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.996107</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933360</td>\n",
       "      <td>0.066387</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.919744</td>\n",
       "      <td>0.078766</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.872018</td>\n",
       "      <td>0.122956</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.954541</td>\n",
       "      <td>0.045271</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.944261</td>\n",
       "      <td>0.055517</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.990607</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.999135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.980574</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.010341</td>\n",
       "      <td>0.989316</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.982003</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.993846</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.989614</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451494</td>\n",
       "      <td>0.548059</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.642906</td>\n",
       "      <td>0.356337</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.679323</td>\n",
       "      <td>0.319482</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.223343</td>\n",
       "      <td>0.776097</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.634156</td>\n",
       "      <td>0.365477</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_1_probs_class_0  model_1_probs_class_1  model_1_probs_class_2  \\\n",
       "0               0.003650               0.984123               0.012227   \n",
       "1               0.933360               0.066387               0.000253   \n",
       "2               0.000043               0.000703               0.999254   \n",
       "3               0.019063               0.980574               0.000362   \n",
       "4               0.451494               0.548059               0.000447   \n",
       "\n",
       "   model_2_probs_class_0  model_2_probs_class_1  model_2_probs_class_2  \\\n",
       "0               0.005208               0.885760               0.109031   \n",
       "1               0.919744               0.078766               0.001490   \n",
       "2               0.000249               0.003541               0.996210   \n",
       "3               0.010341               0.989316               0.000343   \n",
       "4               0.642906               0.356337               0.000757   \n",
       "\n",
       "   model_3_probs_class_0  model_3_probs_class_1  model_3_probs_class_2  \\\n",
       "0               0.010436               0.874816               0.114748   \n",
       "1               0.872018               0.122956               0.005025   \n",
       "2               0.000629               0.008764               0.990607   \n",
       "3               0.017067               0.982003               0.000930   \n",
       "4               0.679323               0.319482               0.001194   \n",
       "\n",
       "   model_4_probs_class_0  model_4_probs_class_1  model_4_probs_class_2  \\\n",
       "0               0.001246               0.997485               0.001269   \n",
       "1               0.954541               0.045271               0.000188   \n",
       "2               0.000021               0.000568               0.999411   \n",
       "3               0.005564               0.993846               0.000589   \n",
       "4               0.223343               0.776097               0.000560   \n",
       "\n",
       "   model_5_probs_class_0  model_5_probs_class_1  model_5_probs_class_2  \\\n",
       "0               0.002010               0.996107               0.001882   \n",
       "1               0.944261               0.055517               0.000221   \n",
       "2               0.000059               0.000806               0.999135   \n",
       "3               0.010004               0.989614               0.000382   \n",
       "4               0.634156               0.365477               0.000367   \n",
       "\n",
       "   True_labels  \n",
       "0            1  \n",
       "1            0  \n",
       "2            2  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the true labels to the model probabilities DataFrame\n",
    "model_prob_df['True_labels'] = df_snli_test['gold_label'].values\n",
    "\n",
    "# Display the updated DataFrame to confirm the true labels are added correctly\n",
    "model_prob_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per model: {'model_1': 0.9225366449511401, 'model_2': 0.9238599348534202, 'model_3': 0.9202972312703583, 'model_4': 0.9231473941368078, 'model_5': 0.9236563517915309}\n",
      "Correlation matrix between model predictions:\n",
      " [[1.         0.98947051 0.98361874 0.98627941 0.98882723]\n",
      " [0.98947051 1.         0.98859856 0.98324871 0.98686791]\n",
      " [0.98361874 0.98859856 1.         0.9737799  0.97845907]\n",
      " [0.98627941 0.98324871 0.9737799  1.         0.98802715]\n",
      " [0.98882723 0.98686791 0.97845907 0.98802715 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Calculate Individual Model Accuracy\n",
    "def calculate_accuracy(predictions, true_labels):\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    return accuracy\n",
    "\n",
    "# Extract probabilities for each class and compute accuracy\n",
    "accuracy_per_model = {}\n",
    "n_models = 5  # Assuming you have 5 models, adjust if different\n",
    "for i in range(1, n_models + 1):\n",
    "    probs = model_prob_df[[f'model_{i}_probs_class_0', f'model_{i}_probs_class_1', f'model_{i}_probs_class_2']].values\n",
    "    accuracy_per_model[f'model_{i}'] = calculate_accuracy(probs, model_prob_df['True_labels'].values)\n",
    "\n",
    "# Step 2: Calculate Correlations Between Model Predictions\n",
    "correlation_matrix = np.zeros((n_models, n_models))\n",
    "for i in range(1, n_models + 1):\n",
    "    for j in range(1, n_models + 1):\n",
    "        # Extract the probabilities of the true class for correlation calculation\n",
    "        true_class_probs_i = model_prob_df[[f'model_{i}_probs_class_{k}' for k in model_prob_df['True_labels']]].values\n",
    "        true_class_probs_j = model_prob_df[[f'model_{j}_probs_class_{k}' for k in model_prob_df['True_labels']]].values\n",
    "        correlation_matrix[i-1, j-1] = np.corrcoef(true_class_probs_i.ravel(), true_class_probs_j.ravel())[0, 1]\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy per model:\", accuracy_per_model)\n",
    "print(\"Correlation matrix between model predictions:\\n\", correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the averaged model: 0.9271172638436482\n"
     ]
    }
   ],
   "source": [
    "# Compute the average probabilities across all models\n",
    "average_probs = np.mean([\n",
    "    model_prob_df[[f'model_{i}_probs_class_0', f'model_{i}_probs_class_1', f'model_{i}_probs_class_2']].values\n",
    "    for i in range(1, n_models + 1)\n",
    "], axis=0)\n",
    "\n",
    "# Determine predicted labels from the average probabilities\n",
    "predicted_labels_from_average = np.argmax(average_probs, axis=1)\n",
    "\n",
    "# Calculate accuracy of the averaged model\n",
    "average_model_accuracy = np.mean(predicted_labels_from_average == model_prob_df['True_labels'].values)\n",
    "\n",
    "print(\"Accuracy of the averaged model:\", average_model_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Cross-Entropy Loss of the averaged model: 0.21595251917503508\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    \"\"\" Convert array of labels to one-hot encoded numpy array. \"\"\"\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def categorical_cross_entropy(true_labels, predicted_probs):\n",
    "    \"\"\" Compute the categorical cross-entropy loss. \"\"\"\n",
    "    true_labels_one_hot = one_hot_encode(true_labels, num_classes=predicted_probs.shape[1])\n",
    "    log_probs = np.log(predicted_probs + 1e-15)  # Adding a small epsilon to avoid log(0)\n",
    "    loss = -np.sum(true_labels_one_hot * log_probs) / true_labels_one_hot.shape[0]\n",
    "    return loss\n",
    "\n",
    "# Assuming 'average_probs' is already calculated as suggested in the previous step\n",
    "true_labels = model_prob_df['True_labels'].values\n",
    "loss = categorical_cross_entropy(true_labels, average_probs)\n",
    "\n",
    "print(\"Categorical Cross-Entropy Loss of the averaged model:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
