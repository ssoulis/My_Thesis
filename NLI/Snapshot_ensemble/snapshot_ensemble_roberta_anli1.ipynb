{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 31 16:48:56 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   318W / 400W |  12232MiB / 40960MiB |     99%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   33C    P0   144W / 400W |  37904MiB / 40960MiB |     93%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    56W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  Off  | 00000000:4D:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   283W / 400W |  16698MiB / 40960MiB |     99%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM...  On   | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    53W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM...  On   | 00000000:8D:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    55W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM...  On   | 00000000:C7:00.0 Off |                    0 |\n",
      "| N/A   34C    P0   154W / 400W |  37904MiB / 40960MiB |     93%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM...  Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    51W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    482132      C   /opt/anaconda3/bin/python       11380MiB |\n",
      "|    0   N/A  N/A   1716425      C   .../envs/torchenv/bin/python      850MiB |\n",
      "|    1   N/A  N/A    298480      C   ...onserver/bin/tritonserver    37418MiB |\n",
      "|    1   N/A  N/A    298481      C   ...onserver/bin/tritonserver      478MiB |\n",
      "|    3   N/A  N/A    526390      C   /opt/anaconda3/bin/python       16696MiB |\n",
      "|    6   N/A  N/A    298480      C   ...onserver/bin/tritonserver      478MiB |\n",
      "|    6   N/A  N/A    298481      C   ...onserver/bin/tritonserver    37418MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      "0: NVIDIA A100-SXM4-40GB\n",
      "1: NVIDIA A100-SXM4-40GB\n",
      "2: NVIDIA A100-SXM4-40GB\n",
      "3: NVIDIA A100-SXM4-40GB\n",
      "4: NVIDIA A100-SXM4-40GB\n",
      "5: NVIDIA A100-SXM4-40GB\n",
      "6: NVIDIA A100-SXM4-40GB\n",
      "7: NVIDIA A100-SXM4-40GB\n",
      "Select GPU by entering the device ID (default 0): 4\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Function to list available GPUs and select one\n",
    "def select_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Available GPUs:\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"{i}: {torch.cuda.get_device_name(i)}\")\n",
    "        device_id = int(input(\"Select GPU by entering the device ID (default 0): \") or 0)\n",
    "        if device_id < torch.cuda.device_count():\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(device_id)}\")\n",
    "            return torch.device(f\"cuda:{device_id}\")\n",
    "        else:\n",
    "            print(f\"Invalid device ID. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            return torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# Select the device\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(snapshot_path, model_name=\"FacebookAI/roberta-large\", num_labels=3):\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    model.load_state_dict(torch.load(snapshot_path, map_location=device))\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "# Function to list all model snapshot files in a directory that match the naming pattern\n",
    "def list_snapshot_files(snapshot_directory):\n",
    "    return [os.path.join(snapshot_directory, file_name) for file_name in os.listdir(snapshot_directory) \n",
    "            if file_name.startswith('roberta_large_anli1_cycle_') and file_name.endswith('.pth')]\n",
    "\n",
    "# Load all models\n",
    "snapshot_directory = '/storage/data/st1070263'\n",
    "snapshot_files = list_snapshot_files(snapshot_directory)\n",
    "model_snapshots = [load_model(snapshot) for snapshot in snapshot_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the test data and loading it\n",
    "test_data_path = 'ANLI/test_r1.csv'\n",
    "df_anli_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# Including 'reason' column in the contextual input\n",
    "df_anli_test['contextual_input'] = df_anli_test['premise'] + \" [SEP] \" + df_anli_test['hypothesis'] + \" [SEP] \" + df_anli_test['reason']\n",
    "df_anli_test.dropna(subset=['contextual_input', 'label'], inplace=True)\n",
    "df_anli_test['label'] = df_anli_test['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "# Tokenization and Dataset Preparation\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"FacebookAI/roberta-large\")\n",
    "\n",
    "\n",
    "class ANLITestDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def tokenize_data_with_reason(df, tokenizer):\n",
    "    return tokenizer(df['contextual_input'].tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# Prepare the test dataset\n",
    "encodings_with_reason = tokenize_data_with_reason(df_anli_test, tokenizer)\n",
    "anli_test_dataset_with_reason = ANLITestDataset(encodings_with_reason, df_anli_test['label'].tolist())\n",
    "anli_test_loader_with_reason = DataLoader(anli_test_dataset_with_reason, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 1 with reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                        | 0/32 [00:00<?, ?it/s]/tmp/ipykernel_609842/788940528.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 2 with reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 3 with reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 4 with reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 5 with reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 6 with reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model 7 with reason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Evaluate model and get predictions with reason\n",
    "def get_model_predictions_with_reason(model, loader):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            all_probs.append(probabilities.detach())\n",
    "    torch.cuda.empty_cache()\n",
    "    return torch.cat(all_probs, dim=0)\n",
    "\n",
    "model_probs_with_reason = {}\n",
    "for i, model in enumerate(model_snapshots):\n",
    "    print(f\"Processing Model {i+1} with reason\")\n",
    "    probabilities_with_reason = get_model_predictions_with_reason(model, anli_test_loader_with_reason)\n",
    "    model_probs_with_reason[f'model_{i+1}_probs'] = probabilities_with_reason.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions stored in 'model_probabilities_with_reason.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the data for predictions that include the reason column\n",
    "model_prob_df = pd.DataFrame()\n",
    "for key, probs in model_probs_with_reason.items():\n",
    "    df_probs = pd.DataFrame(probs, columns=[f'{key}_class_0', f'{key}_class_1', f'{key}_class_2'])\n",
    "    model_prob_df = pd.concat([model_prob_df, df_probs], axis=1)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "model_prob_df.to_csv('model_probabilities_with_reason.csv', index=False)\n",
    "print(\"Model predictions stored in 'model_probabilities_with_reason.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1_probs_class_0</th>\n",
       "      <th>model_1_probs_class_1</th>\n",
       "      <th>model_1_probs_class_2</th>\n",
       "      <th>model_2_probs_class_0</th>\n",
       "      <th>model_2_probs_class_1</th>\n",
       "      <th>model_2_probs_class_2</th>\n",
       "      <th>model_3_probs_class_0</th>\n",
       "      <th>model_3_probs_class_1</th>\n",
       "      <th>model_3_probs_class_2</th>\n",
       "      <th>model_4_probs_class_0</th>\n",
       "      <th>...</th>\n",
       "      <th>model_4_probs_class_2</th>\n",
       "      <th>model_5_probs_class_0</th>\n",
       "      <th>model_5_probs_class_1</th>\n",
       "      <th>model_5_probs_class_2</th>\n",
       "      <th>model_6_probs_class_0</th>\n",
       "      <th>model_6_probs_class_1</th>\n",
       "      <th>model_6_probs_class_2</th>\n",
       "      <th>model_7_probs_class_0</th>\n",
       "      <th>model_7_probs_class_1</th>\n",
       "      <th>model_7_probs_class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.453937</td>\n",
       "      <td>0.234938</td>\n",
       "      <td>0.311125</td>\n",
       "      <td>0.975081</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.994125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.478546</td>\n",
       "      <td>0.209742</td>\n",
       "      <td>0.311712</td>\n",
       "      <td>0.708032</td>\n",
       "      <td>0.113943</td>\n",
       "      <td>0.178025</td>\n",
       "      <td>0.967613</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>0.014712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921673</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.074754</td>\n",
       "      <td>0.447572</td>\n",
       "      <td>0.240428</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.716421</td>\n",
       "      <td>0.074690</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>0.399538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589406</td>\n",
       "      <td>0.460462</td>\n",
       "      <td>0.222988</td>\n",
       "      <td>0.316550</td>\n",
       "      <td>0.393119</td>\n",
       "      <td>0.038234</td>\n",
       "      <td>0.568647</td>\n",
       "      <td>0.808556</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.180666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.981688</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.444473</td>\n",
       "      <td>0.240985</td>\n",
       "      <td>0.314542</td>\n",
       "      <td>0.962230</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.030924</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.425426</td>\n",
       "      <td>0.201559</td>\n",
       "      <td>0.373015</td>\n",
       "      <td>0.800167</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.177798</td>\n",
       "      <td>0.898381</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.089934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.879213</td>\n",
       "      <td>0.035879</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>0.239167</td>\n",
       "      <td>0.316038</td>\n",
       "      <td>0.769570</td>\n",
       "      <td>0.131701</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.847227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029856</td>\n",
       "      <td>0.419022</td>\n",
       "      <td>0.239622</td>\n",
       "      <td>0.341356</td>\n",
       "      <td>0.443442</td>\n",
       "      <td>0.322854</td>\n",
       "      <td>0.233704</td>\n",
       "      <td>0.609160</td>\n",
       "      <td>0.303432</td>\n",
       "      <td>0.087409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023634</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.972481</td>\n",
       "      <td>0.440584</td>\n",
       "      <td>0.238663</td>\n",
       "      <td>0.320753</td>\n",
       "      <td>0.121195</td>\n",
       "      <td>0.029225</td>\n",
       "      <td>0.849580</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995001</td>\n",
       "      <td>0.406080</td>\n",
       "      <td>0.209482</td>\n",
       "      <td>0.384438</td>\n",
       "      <td>0.137451</td>\n",
       "      <td>0.041743</td>\n",
       "      <td>0.820806</td>\n",
       "      <td>0.032372</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.958437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.440914</td>\n",
       "      <td>0.239054</td>\n",
       "      <td>0.320032</td>\n",
       "      <td>0.298985</td>\n",
       "      <td>0.023508</td>\n",
       "      <td>0.677507</td>\n",
       "      <td>0.074218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913583</td>\n",
       "      <td>0.392680</td>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.409281</td>\n",
       "      <td>0.058636</td>\n",
       "      <td>0.041714</td>\n",
       "      <td>0.899649</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.031401</td>\n",
       "      <td>0.923609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.029680</td>\n",
       "      <td>0.965641</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.441487</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>0.317718</td>\n",
       "      <td>0.066286</td>\n",
       "      <td>0.904615</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.442189</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>0.268948</td>\n",
       "      <td>0.096896</td>\n",
       "      <td>0.783850</td>\n",
       "      <td>0.119254</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.942460</td>\n",
       "      <td>0.014578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.444698</td>\n",
       "      <td>0.245506</td>\n",
       "      <td>0.309795</td>\n",
       "      <td>0.977880</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.994544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.276622</td>\n",
       "      <td>0.270658</td>\n",
       "      <td>0.918582</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.012487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.989728</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.446451</td>\n",
       "      <td>0.241364</td>\n",
       "      <td>0.312185</td>\n",
       "      <td>0.963514</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.994335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.443536</td>\n",
       "      <td>0.244333</td>\n",
       "      <td>0.312131</td>\n",
       "      <td>0.497367</td>\n",
       "      <td>0.347122</td>\n",
       "      <td>0.155510</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.014197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.269801</td>\n",
       "      <td>0.443719</td>\n",
       "      <td>0.236480</td>\n",
       "      <td>0.319801</td>\n",
       "      <td>0.622749</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.364444</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878499</td>\n",
       "      <td>0.426096</td>\n",
       "      <td>0.182541</td>\n",
       "      <td>0.391363</td>\n",
       "      <td>0.561835</td>\n",
       "      <td>0.032563</td>\n",
       "      <td>0.405603</td>\n",
       "      <td>0.431053</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.533191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_1_probs_class_0  model_1_probs_class_1  model_1_probs_class_2  \\\n",
       "0                 0.995955               0.002309               0.001735   \n",
       "1                 0.921673               0.003573               0.074754   \n",
       "2                 0.981688               0.001364               0.016947   \n",
       "3                 0.879213               0.035879               0.084908   \n",
       "4                 0.023634               0.003885               0.972481   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.005234               0.002231               0.992535   \n",
       "996               0.029680               0.965641               0.004679   \n",
       "997               0.994565               0.001283               0.004151   \n",
       "998               0.989728               0.007850               0.002422   \n",
       "999               0.709434               0.020765               0.269801   \n",
       "\n",
       "     model_2_probs_class_0  model_2_probs_class_1  model_2_probs_class_2  \\\n",
       "0                 0.453937               0.234938               0.311125   \n",
       "1                 0.447572               0.240428               0.312000   \n",
       "2                 0.444473               0.240985               0.314542   \n",
       "3                 0.444795               0.239167               0.316038   \n",
       "4                 0.440584               0.238663               0.320753   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.440914               0.239054               0.320032   \n",
       "996               0.441487               0.240795               0.317718   \n",
       "997               0.444698               0.245506               0.309795   \n",
       "998               0.446451               0.241364               0.312185   \n",
       "999               0.443719               0.236480               0.319801   \n",
       "\n",
       "     model_3_probs_class_0  model_3_probs_class_1  model_3_probs_class_2  \\\n",
       "0                 0.975081               0.015052               0.009867   \n",
       "1                 0.716421               0.074690               0.208889   \n",
       "2                 0.962230               0.006846               0.030924   \n",
       "3                 0.769570               0.131701               0.098730   \n",
       "4                 0.121195               0.029225               0.849580   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.298985               0.023508               0.677507   \n",
       "996               0.066286               0.904615               0.029099   \n",
       "997               0.977880               0.011210               0.010910   \n",
       "998               0.963514               0.024877               0.011609   \n",
       "999               0.622749               0.012807               0.364444   \n",
       "\n",
       "     model_4_probs_class_0  ...  model_4_probs_class_2  model_5_probs_class_0  \\\n",
       "0                 0.994125  ...               0.003181               0.478546   \n",
       "1                 0.399538  ...               0.589406               0.460462   \n",
       "2                 0.982405  ...               0.016667               0.425426   \n",
       "3                 0.847227  ...               0.029856               0.419022   \n",
       "4                 0.003300  ...               0.995001               0.406080   \n",
       "..                     ...  ...                    ...                    ...   \n",
       "995               0.074218  ...               0.913583               0.392680   \n",
       "996               0.005243  ...               0.001050               0.442189   \n",
       "997               0.994544  ...               0.004345               0.452720   \n",
       "998               0.994335  ...               0.001671               0.443536   \n",
       "999               0.056365  ...               0.878499               0.426096   \n",
       "\n",
       "     model_5_probs_class_1  model_5_probs_class_2  model_6_probs_class_0  \\\n",
       "0                 0.209742               0.311712               0.708032   \n",
       "1                 0.222988               0.316550               0.393119   \n",
       "2                 0.201559               0.373015               0.800167   \n",
       "3                 0.239622               0.341356               0.443442   \n",
       "4                 0.209482               0.384438               0.137451   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.198039               0.409281               0.058636   \n",
       "996               0.288863               0.268948               0.096896   \n",
       "997               0.276622               0.270658               0.918582   \n",
       "998               0.244333               0.312131               0.497367   \n",
       "999               0.182541               0.391363               0.561835   \n",
       "\n",
       "     model_6_probs_class_1  model_6_probs_class_2  model_7_probs_class_0  \\\n",
       "0                 0.113943               0.178025               0.967613   \n",
       "1                 0.038234               0.568647               0.808556   \n",
       "2                 0.022035               0.177798               0.898381   \n",
       "3                 0.322854               0.233704               0.609160   \n",
       "4                 0.041743               0.820806               0.032372   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.041714               0.899649               0.044990   \n",
       "996               0.783850               0.119254               0.042962   \n",
       "997               0.033409               0.048009               0.978822   \n",
       "998               0.347122               0.155510               0.965385   \n",
       "999               0.032563               0.405603               0.431053   \n",
       "\n",
       "     model_7_probs_class_1  model_7_probs_class_2  \n",
       "0                 0.017675               0.014712  \n",
       "1                 0.010778               0.180666  \n",
       "2                 0.011686               0.089934  \n",
       "3                 0.303432               0.087409  \n",
       "4                 0.009191               0.958437  \n",
       "..                     ...                    ...  \n",
       "995               0.031401               0.923609  \n",
       "996               0.942460               0.014578  \n",
       "997               0.008691               0.012487  \n",
       "998               0.020418               0.014197  \n",
       "999               0.035756               0.533191  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the true labels to the model probabilities DataFrame\n",
    "model_prob_df['True_labels'] = df_anli_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1_probs_class_0</th>\n",
       "      <th>model_1_probs_class_1</th>\n",
       "      <th>model_1_probs_class_2</th>\n",
       "      <th>model_2_probs_class_0</th>\n",
       "      <th>model_2_probs_class_1</th>\n",
       "      <th>model_2_probs_class_2</th>\n",
       "      <th>model_3_probs_class_0</th>\n",
       "      <th>model_3_probs_class_1</th>\n",
       "      <th>model_3_probs_class_2</th>\n",
       "      <th>model_4_probs_class_0</th>\n",
       "      <th>...</th>\n",
       "      <th>model_5_probs_class_0</th>\n",
       "      <th>model_5_probs_class_1</th>\n",
       "      <th>model_5_probs_class_2</th>\n",
       "      <th>model_6_probs_class_0</th>\n",
       "      <th>model_6_probs_class_1</th>\n",
       "      <th>model_6_probs_class_2</th>\n",
       "      <th>model_7_probs_class_0</th>\n",
       "      <th>model_7_probs_class_1</th>\n",
       "      <th>model_7_probs_class_2</th>\n",
       "      <th>True_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.453937</td>\n",
       "      <td>0.234938</td>\n",
       "      <td>0.311125</td>\n",
       "      <td>0.975081</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.994125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478546</td>\n",
       "      <td>0.209742</td>\n",
       "      <td>0.311712</td>\n",
       "      <td>0.708032</td>\n",
       "      <td>0.113943</td>\n",
       "      <td>0.178025</td>\n",
       "      <td>0.967613</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921673</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.074754</td>\n",
       "      <td>0.447572</td>\n",
       "      <td>0.240428</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.716421</td>\n",
       "      <td>0.074690</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>0.399538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460462</td>\n",
       "      <td>0.222988</td>\n",
       "      <td>0.316550</td>\n",
       "      <td>0.393119</td>\n",
       "      <td>0.038234</td>\n",
       "      <td>0.568647</td>\n",
       "      <td>0.808556</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.180666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.981688</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.444473</td>\n",
       "      <td>0.240985</td>\n",
       "      <td>0.314542</td>\n",
       "      <td>0.962230</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.030924</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425426</td>\n",
       "      <td>0.201559</td>\n",
       "      <td>0.373015</td>\n",
       "      <td>0.800167</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.177798</td>\n",
       "      <td>0.898381</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.089934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.879213</td>\n",
       "      <td>0.035879</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>0.239167</td>\n",
       "      <td>0.316038</td>\n",
       "      <td>0.769570</td>\n",
       "      <td>0.131701</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.847227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419022</td>\n",
       "      <td>0.239622</td>\n",
       "      <td>0.341356</td>\n",
       "      <td>0.443442</td>\n",
       "      <td>0.322854</td>\n",
       "      <td>0.233704</td>\n",
       "      <td>0.609160</td>\n",
       "      <td>0.303432</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023634</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.972481</td>\n",
       "      <td>0.440584</td>\n",
       "      <td>0.238663</td>\n",
       "      <td>0.320753</td>\n",
       "      <td>0.121195</td>\n",
       "      <td>0.029225</td>\n",
       "      <td>0.849580</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406080</td>\n",
       "      <td>0.209482</td>\n",
       "      <td>0.384438</td>\n",
       "      <td>0.137451</td>\n",
       "      <td>0.041743</td>\n",
       "      <td>0.820806</td>\n",
       "      <td>0.032372</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.958437</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.440914</td>\n",
       "      <td>0.239054</td>\n",
       "      <td>0.320032</td>\n",
       "      <td>0.298985</td>\n",
       "      <td>0.023508</td>\n",
       "      <td>0.677507</td>\n",
       "      <td>0.074218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392680</td>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.409281</td>\n",
       "      <td>0.058636</td>\n",
       "      <td>0.041714</td>\n",
       "      <td>0.899649</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.031401</td>\n",
       "      <td>0.923609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.029680</td>\n",
       "      <td>0.965641</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.441487</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>0.317718</td>\n",
       "      <td>0.066286</td>\n",
       "      <td>0.904615</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442189</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>0.268948</td>\n",
       "      <td>0.096896</td>\n",
       "      <td>0.783850</td>\n",
       "      <td>0.119254</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.942460</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.444698</td>\n",
       "      <td>0.245506</td>\n",
       "      <td>0.309795</td>\n",
       "      <td>0.977880</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.994544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.276622</td>\n",
       "      <td>0.270658</td>\n",
       "      <td>0.918582</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.989728</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.446451</td>\n",
       "      <td>0.241364</td>\n",
       "      <td>0.312185</td>\n",
       "      <td>0.963514</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.994335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443536</td>\n",
       "      <td>0.244333</td>\n",
       "      <td>0.312131</td>\n",
       "      <td>0.497367</td>\n",
       "      <td>0.347122</td>\n",
       "      <td>0.155510</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.269801</td>\n",
       "      <td>0.443719</td>\n",
       "      <td>0.236480</td>\n",
       "      <td>0.319801</td>\n",
       "      <td>0.622749</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.364444</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426096</td>\n",
       "      <td>0.182541</td>\n",
       "      <td>0.391363</td>\n",
       "      <td>0.561835</td>\n",
       "      <td>0.032563</td>\n",
       "      <td>0.405603</td>\n",
       "      <td>0.431053</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.533191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_1_probs_class_0  model_1_probs_class_1  model_1_probs_class_2  \\\n",
       "0                 0.995955               0.002309               0.001735   \n",
       "1                 0.921673               0.003573               0.074754   \n",
       "2                 0.981688               0.001364               0.016947   \n",
       "3                 0.879213               0.035879               0.084908   \n",
       "4                 0.023634               0.003885               0.972481   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.005234               0.002231               0.992535   \n",
       "996               0.029680               0.965641               0.004679   \n",
       "997               0.994565               0.001283               0.004151   \n",
       "998               0.989728               0.007850               0.002422   \n",
       "999               0.709434               0.020765               0.269801   \n",
       "\n",
       "     model_2_probs_class_0  model_2_probs_class_1  model_2_probs_class_2  \\\n",
       "0                 0.453937               0.234938               0.311125   \n",
       "1                 0.447572               0.240428               0.312000   \n",
       "2                 0.444473               0.240985               0.314542   \n",
       "3                 0.444795               0.239167               0.316038   \n",
       "4                 0.440584               0.238663               0.320753   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.440914               0.239054               0.320032   \n",
       "996               0.441487               0.240795               0.317718   \n",
       "997               0.444698               0.245506               0.309795   \n",
       "998               0.446451               0.241364               0.312185   \n",
       "999               0.443719               0.236480               0.319801   \n",
       "\n",
       "     model_3_probs_class_0  model_3_probs_class_1  model_3_probs_class_2  \\\n",
       "0                 0.975081               0.015052               0.009867   \n",
       "1                 0.716421               0.074690               0.208889   \n",
       "2                 0.962230               0.006846               0.030924   \n",
       "3                 0.769570               0.131701               0.098730   \n",
       "4                 0.121195               0.029225               0.849580   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.298985               0.023508               0.677507   \n",
       "996               0.066286               0.904615               0.029099   \n",
       "997               0.977880               0.011210               0.010910   \n",
       "998               0.963514               0.024877               0.011609   \n",
       "999               0.622749               0.012807               0.364444   \n",
       "\n",
       "     model_4_probs_class_0  ...  model_5_probs_class_0  model_5_probs_class_1  \\\n",
       "0                 0.994125  ...               0.478546               0.209742   \n",
       "1                 0.399538  ...               0.460462               0.222988   \n",
       "2                 0.982405  ...               0.425426               0.201559   \n",
       "3                 0.847227  ...               0.419022               0.239622   \n",
       "4                 0.003300  ...               0.406080               0.209482   \n",
       "..                     ...  ...                    ...                    ...   \n",
       "995               0.074218  ...               0.392680               0.198039   \n",
       "996               0.005243  ...               0.442189               0.288863   \n",
       "997               0.994544  ...               0.452720               0.276622   \n",
       "998               0.994335  ...               0.443536               0.244333   \n",
       "999               0.056365  ...               0.426096               0.182541   \n",
       "\n",
       "     model_5_probs_class_2  model_6_probs_class_0  model_6_probs_class_1  \\\n",
       "0                 0.311712               0.708032               0.113943   \n",
       "1                 0.316550               0.393119               0.038234   \n",
       "2                 0.373015               0.800167               0.022035   \n",
       "3                 0.341356               0.443442               0.322854   \n",
       "4                 0.384438               0.137451               0.041743   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.409281               0.058636               0.041714   \n",
       "996               0.268948               0.096896               0.783850   \n",
       "997               0.270658               0.918582               0.033409   \n",
       "998               0.312131               0.497367               0.347122   \n",
       "999               0.391363               0.561835               0.032563   \n",
       "\n",
       "     model_6_probs_class_2  model_7_probs_class_0  model_7_probs_class_1  \\\n",
       "0                 0.178025               0.967613               0.017675   \n",
       "1                 0.568647               0.808556               0.010778   \n",
       "2                 0.177798               0.898381               0.011686   \n",
       "3                 0.233704               0.609160               0.303432   \n",
       "4                 0.820806               0.032372               0.009191   \n",
       "..                     ...                    ...                    ...   \n",
       "995               0.899649               0.044990               0.031401   \n",
       "996               0.119254               0.042962               0.942460   \n",
       "997               0.048009               0.978822               0.008691   \n",
       "998               0.155510               0.965385               0.020418   \n",
       "999               0.405603               0.431053               0.035756   \n",
       "\n",
       "     model_7_probs_class_2  True_labels  \n",
       "0                 0.014712            0  \n",
       "1                 0.180666            0  \n",
       "2                 0.089934            0  \n",
       "3                 0.087409            1  \n",
       "4                 0.958437            2  \n",
       "..                     ...          ...  \n",
       "995               0.923609            0  \n",
       "996               0.014578            1  \n",
       "997               0.012487            0  \n",
       "998               0.014197            1  \n",
       "999               0.533191            2  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per model: {'model_1': 0.777, 'model_2': 0.334, 'model_3': 0.779, 'model_4': 0.778, 'model_5': 0.349, 'model_6': 0.777, 'model_7': 0.802}\n",
      "Correlation matrix between model predictions:\n",
      " [[ 1.00000000e+00  1.84177276e-01  9.27903807e-01  8.74202161e-01\n",
      "   2.67127875e-01  8.46463283e-01  9.19075203e-01]\n",
      " [ 1.84177276e-01  1.00000000e+00  1.87143927e-01 -6.96046003e-04\n",
      "   8.87902297e-01  4.21013921e-02  8.83961511e-02]\n",
      " [ 9.27903807e-01  1.87143927e-01  1.00000000e+00  8.66484268e-01\n",
      "   2.80358618e-01  8.80810020e-01  9.34758154e-01]\n",
      " [ 8.74202161e-01 -6.96046003e-04  8.66484268e-01  1.00000000e+00\n",
      "   1.15659596e-01  8.51816087e-01  9.05410223e-01]\n",
      " [ 2.67127875e-01  8.87902297e-01  2.80358618e-01  1.15659596e-01\n",
      "   1.00000000e+00  1.52898658e-01  1.99944269e-01]\n",
      " [ 8.46463283e-01  4.21013921e-02  8.80810020e-01  8.51816087e-01\n",
      "   1.52898658e-01  1.00000000e+00  9.10073932e-01]\n",
      " [ 9.19075203e-01  8.83961511e-02  9.34758154e-01  9.05410223e-01\n",
      "   1.99944269e-01  9.10073932e-01  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Calculate Individual Model Accuracy\n",
    "def calculate_accuracy(predictions, true_labels):\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    return accuracy\n",
    "\n",
    "n_models = len(model_snapshots)  # Adjust the number of models based on your ensemble\n",
    "accuracy_per_model = {}\n",
    "for i in range(1, n_models + 1):\n",
    "    probs = model_prob_df[[f'model_{i}_probs_class_0', f'model_{i}_probs_class_1', f'model_{i}_probs_class_2']].values\n",
    "    accuracy_per_model[f'model_{i}'] = calculate_accuracy(probs, model_prob_df['True_labels'].values)\n",
    "\n",
    "# Step 2: Calculate Correlations Between Model Predictions\n",
    "correlation_matrix = np.zeros((n_models, n_models))\n",
    "for i in range(1, n_models + 1):\n",
    "    for j in range(1, n_models + 1):\n",
    "        true_class_probs_i = model_prob_df[[f'model_{i}_probs_class_{k}' for k in model_prob_df['True_labels']]].values\n",
    "        true_class_probs_j = model_prob_df[[f'model_{j}_probs_class_{k}' for k in model_prob_df['True_labels']]].values\n",
    "        correlation_matrix[i-1, j-1] = np.corrcoef(true_class_probs_i.ravel(), true_class_probs_j.ravel())[0, 1]\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy per model:\", accuracy_per_model)\n",
    "print(\"Correlation matrix between model predictions:\\n\", correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(true_labels, predictions, title):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, linewidths=.5)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the averaged model: 0.807\n",
      "Categorical Cross-Entropy Loss of the averaged model: 0.5934909352362155\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIhCAYAAABpMPNPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABNAklEQVR4nO3dd3gU1f/28XvTK4EQQgmEKh3pRpqhCIiCIiLSQxEVAQUR/fFFCSgIYgGlqnSlqRTpShMBQUFBBSMWuvQWSEhCynn+8MnKkkICSXaQ9+u6csGcOTPzmc1kcmf2zKzNGGMEAAAAWJCLswsAAAAAMkJYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYRbp+/vln9ezZU6VLl5aXl5f8/PxUq1YtjRs3TufPn8/Vbe/evVvh4eEKCAiQzWbThAkTcnwbNptNI0aMyPH13sjs2bNls9lks9n09ddfp5lvjFG5cuVks9nUuHHjm9rGlClTNHv27Gwt8/XXX2dYU27bsGGD6tSpI19fX9lsNi1btizDvkePHtWzzz6r8uXLy9vbW4GBgapWrZr69Omjo0eP2vuNGDFCNpstD6pPX6lSpdSjR49cWXe7du1ks9nUv3//XFm/Mzn7+zZx4kSVK1dOHh4estlsunjxYq5t69pzgc1mk5ubm4oWLaqOHTvqjz/+uKl1pr5+Z8+ezeFq0zd//vxcOT/n9X7A+tycXQCs56OPPtKzzz6rChUqaMiQIapcubISExO1a9cuTZs2Tdu3b9fSpUtzbfu9evVSbGysFi5cqAIFCqhUqVI5vo3t27erePHiOb7erPL399eMGTPSBNLNmzfrr7/+kr+//02ve8qUKQoKCspWWKpVq5a2b9+uypUr3/R2b4YxRh06dFD58uW1fPly+fr6qkKFCun2PXbsmGrVqqX8+fNr8ODBqlChgqKjo/Xrr7/q008/1YEDB1SiRAlJ0pNPPqkHHnggL3clT5w+fVorV66UJM2bN09vv/22vLy8nFxVznHm923Pnj167rnn9OSTTyoiIkJubm639HOYVbNmzVLFihUVHx+vbdu2afTo0dq0aZN+++03FShQINe3fyvmz5+vvXv3auDAgc4uBf9xhFU42L59u/r27avmzZtr2bJl8vT0tM9r3ry5Bg8erLVr1+ZqDXv37lWfPn3UqlWrXNvGvffem2vrzoonnnhC8+bN0+TJk5UvXz57+4wZM1SvXj1dunQpT+pITEyUzWZTvnz5nPKaHD9+XOfPn9ejjz6qZs2aZdr3o48+0tmzZ/X999+rdOnS9va2bdvqf//7n1JSUuxtxYsXd+ofI7ll7ty5SkxM1EMPPaRVq1ZpyZIl6ty5c57WkHrMuLnl/K8PZ37f9u3bJ0nq06eP7rnnnhxZ55UrV+Tj45Npn6pVq6pOnTqSpMaNGys5OVmRkZFatmyZevbsmSN15LSs7JeVJScnKykpyeH3G6yNYQBw8MYbb8hms+nDDz9M9wfZw8NDDz/8sH06JSVF48aNU8WKFeXp6ang4GB1795dx44dc1iucePGqlq1qnbu3KlGjRrJx8dHZcqU0dixY+0hI/VtsaSkJE2dOtX+9piU8duDqcscOnTI3rZx40Y1btxYBQsWlLe3t0JDQ/XYY4/pypUr9j7pDQPYu3evHnnkERUoUEBeXl6qUaOG5syZ49An9e3yBQsWaNiwYSpWrJjy5cun+++/X/v378/aiyypU6dOkqQFCxbY26Kjo7V48WL16tUr3WVGjhypsLAwBQYGKl++fKpVq5ZmzJghY4y9T6lSpbRv3z5t3rzZ/vqlXplOrf3jjz/W4MGDFRISIk9PT/35559phgGcPXtWJUqUUP369ZWYmGhf/6+//ipfX19169bthvu4detWNWvWTP7+/vLx8VH9+vW1atUq+/wRI0bYg8nLL7/sUGt6zp07JxcXFwUHB6c738Xl39NZesdLqVKl1Lp1a61cuVI1a9aUt7e3KlWqZL9SOXv2bFWqVEm+vr665557tGvXLofle/ToIT8/P+3bt0/NmjWTr6+vChUqpP79+zscWxm5dOmSXnzxRZUuXVoeHh4KCQnRwIEDFRsbe8NlU82cOVOFCxfWnDlz5O3trZkzZ9rn/fTTT7LZbJoxY0aa5dasWSObzably5fb2/744w917txZwcHB8vT0VKVKlTR58mSH5TI7Zs6cOaNnn31WlStXlp+fn4KDg9W0aVNt2bIlzfaPHTum9u3by9/fX/nz51eXLl20c+dO2Ww2hyErmX3f1q5dq1q1asnb21sVK1Z02PdUW7duVb169eTl5aWQkBC9+uqrmj59eppzxPUaN26srl27SpLCwsJks9kc3pmYOXOmqlevLi8vLwUGBurRRx9VVFSUwzpSj49ffvlFLVq0kL+//w3/AEtPanA9deqUQ/vy5ctVr149+fj4yN/fX82bN9f27dvTXcfRo0fVrl075cuXTwEBAeratavOnDmTpt+iRYtUr149+fr6ys/PTy1bttTu3buztF+NGzfWqlWrdPjwYYfhDKmycr66FVk9/g4dOiSbzaZx48Zp1KhRKl26tDw9PbVp0yZJ0hdffKG7775bnp6eKlOmjN577710j0NjjKZMmaIaNWrI29tbBQoUUPv27XXgwIEc2R/cgAH+v6SkJOPj42PCwsKyvMxTTz1lJJn+/fubtWvXmmnTpplChQqZEiVKmDNnztj7hYeHm4IFC5q77rrLTJs2zaxbt848++yzRpKZM2eOMcaY06dPm+3btxtJpn379mb79u1m+/btxhhjIiMjTXqH66xZs4wkc/DgQWOMMQcPHjReXl6mefPmZtmyZebrr7828+bNM926dTMXLlywLyfJREZG2qd/++034+/vb8qWLWvmzp1rVq1aZTp16mQkmTfffNPeb9OmTUaSKVWqlOnSpYtZtWqVWbBggQkNDTV33XWXSUpKyvT1Sq13586dplu3buaee+6xz5s6darx9fU1ly5dMlWqVDHh4eEOy/bo0cPMmDHDrFu3zqxbt868/vrrxtvb24wcOdLe58cffzRlypQxNWvWtL9+P/74o0PtISEhpn379mb58uVm5cqV5ty5c/Z5mzZtsq9r69atxs3NzQwaNMgYY0xsbKypXLmyqVixoomJicl0P7/++mvj7u5uateubRYtWmSWLVtmWrRoYWw2m1m4cKExxpijR4+aJUuWGElmwIABDrWm55NPPjGSTIsWLczatWtNdHR0hn3TO15KlixpihcvbqpWrWoWLFhgVq9ebcLCwoy7u7sZPny4adCggVmyZIlZunSpKV++vClcuLC5cuWKffmIiAjj4eFhQkNDzejRo81XX31lRowYYdzc3Ezr1q3TbCsiIsI+HRsba2rUqGGCgoLMu+++a9avX2/ee+89ExAQYJo2bWpSUlIyfT2NMWbbtm1GkhkyZIgxxpiuXbsam81mDhw4YO9Ts2ZN06BBgzTLdujQwQQHB5vExERjjDH79u0zAQEBplq1ambu3Lnmq6++MoMHDzYuLi5mxIgR9uUyO2Z+++0307dvX7Nw4ULz9ddfm5UrV5revXsbFxcXh+MoJibGlCtXzgQGBprJkyebL7/80gwaNMiULl3aSDKzZs3K0vetcuXKZu7cuebLL780jz/+uJFkNm/ebO/3008/GS8vL3P33XebhQsXmuXLl5sHH3zQlCpVyuEckZ59+/aZV155xV7P9u3bzZ9//mmMMeaNN94wkkynTp3MqlWrzNy5c02ZMmVMQECA+f333+3riIiIMO7u7qZUqVJmzJgxZsOGDebLL7/McJvXnguuNWnSJCPJLF682N42b948+7G/bNkys2jRIlO7dm3j4eFhtmzZkub1K1mypBkyZIj58ssvzbvvvmt8fX1NzZo1zdWrV+19R48ebWw2m+nVq5dZuXKlWbJkialXr57x9fU1+/btu+F+7du3zzRo0MAUKVLEfq5JPV8bk7XzVUZS9+Pa3yHXy+rxd/DgQfsx3KRJE/P555+br776yhw8eNCsWbPGuLi4mMaNG5ulS5eazz77zISFhdmPmWv16dPHuLu7m8GDB5u1a9ea+fPnm4oVK5rChQubkydP3nCfcGsIq7A7efKkkWQ6duyYpf5RUVFGknn22Wcd2r/77jsjyfzvf/+zt4WHhxtJ5rvvvnPoW7lyZdOyZUuHNkmmX79+Dm1ZDauff/65kWT27NmTae3Xh9WOHTsaT09Pc+TIEYd+rVq1Mj4+PubixYvGmH9/eT/44IMO/T799FMjyeFknZ5rf0Glrmvv3r3GGGPq1q1revToYYwx6YbVayUnJ5vExETz2muvmYIFCzqEnYyWTd3efffdl+G8a0/yxhjz5ptvGklm6dKlJiIiwnh7e5uff/450300xph7773XBAcHm8uXL9vbkpKSTNWqVU3x4sXt9ab+InnrrbduuM6UlBTz9NNPGxcXFyPJ2Gw2U6lSJTNo0KA0QSSj0OPt7W2OHTtmb9uzZ4+RZIoWLWpiY2Pt7cuWLTOSzPLly+1tERERRpJ57733HNY7evRoI8ls3brVYVvXhtUxY8YYFxeXNMEk9XhdvXr1Dfe/V69eRpKJiooyxvz7PXv11Vftfd5//30jyezfv9/edv78eePp6WkGDx5sb2vZsqUpXrx4msDfv39/4+XlZc6fP++wjfSOmeslJSWZxMRE06xZM/Poo4/a2ydPnmwkmTVr1jj0f/rpp7McVr28vMzhw4ftbXFxcSYwMNA8/fTT9rbHH3/c+Pr6OgSc5ORkU7ly5RuGVWPSD48XLlww3t7eaX7ejxw5Yjw9PU3nzp3tbanHx8yZMzPdzvXb27Fjh0lMTDSXL182a9euNUWKFDH33Xef/Q+L5ORkU6xYMVOtWjWTnJxsX/7y5csmODjY1K9f396W+vql/oGZKjXsfvLJJ/b63dzczIABAxz6Xb582RQpUsR06NAhS/v10EMPmZIlS95wXzM7X6UnK2H1ehkdf6nnmLJlyzqEdWP+OeeWKFHCJCQk2NsuX75sChYs6HAcpl5EeeeddxyWP3r0qPH29jYvvfRSluvEzWEYAG5a6tso19/Ic88996hSpUrasGGDQ3uRIkXSjAW7++67dfjw4RyrqUaNGvLw8NBTTz2lOXPmZPktmo0bN6pZs2b2G3RS9ejRQ1euXEnzdtu1QyGkf/ZDUrb2JTw8XGXLltXMmTP1yy+/aOfOnRkOAUit8f7771dAQIBcXV3l7u6u4cOH69y5czp9+nSWt/vYY49lue+QIUP00EMPqVOnTpozZ44mTpyoatWqZbpMbGysvvvuO7Vv315+fn72dldXV3Xr1k3Hjh3L1pCJVDabTdOmTdOBAwc0ZcoU9ezZU4mJiRo/fryqVKmizZs333AdNWrUUEhIiH26UqVKkv55G/jaMXip7el9P7t06eIwnTpmNPXnIT0rV65U1apVVaNGDSUlJdm/WrZsmaWnMMTExOjTTz9V/fr1VbFiRUn/Hj+zZ8+2D6Xp0qWLPD09Hd5aX7BggRISEuzjH+Pj47VhwwY9+uij8vHxcajnwQcfVHx8vHbs2OGw/YyOmWnTpqlWrVry8vKSm5ub3N3dtWHDBoe3yDdv3ix/f/80N06lDoXJiho1aig0NNQ+7eXlpfLlyzt8fzZv3qymTZsqKCjI3ubi4qIOHTpkeTvX2759u+Li4tKc40qUKKGmTZumOcdJ2fv5kv4ZP+/u7m5/jQoUKKAvvvjCPiZ4//79On78uLp16+Yw1MXPz0+PPfaYduzYkWYYyvXHaIcOHeTm5mY/Rr/88kslJSWpe/fuDt9/Ly8vhYeHp3s8Zne/cup8lZmsHH+pHn74Ybm7u9unY2NjtWvXLrVt21YeHh72dj8/P7Vp08Zh2ZUrV8pms6lr164Or1eRIkVUvXp1pzxF5U5DWIVdUFCQfHx8dPDgwSz1P3funCSpaNGiaeYVK1bMPj9VwYIF0/Tz9PRUXFzcTVSbvrJly2r9+vUKDg5Wv379VLZsWZUtW1bvvfdepsudO3cuw/1InX+t6/cldXxvdvbFZrOpZ8+e+uSTTzRt2jSVL19ejRo1Srfv999/rxYtWkj650ajbdu2aefOnRo2bFi2t5vefmZWY48ePRQfH68iRYpkaazqhQsXZIzJ1uuZHSVLllTfvn01Y8YM/fHHH1q0aJHi4+M1ZMiQGy4bGBjoMJ36Syqj9vj4eId2Nze3NN/7IkWKSMp8n06dOqWff/5Z7u7uDl/+/v4yxtzwET2LFi1STEyMOnTooIsXL+rixYuKjo5Whw4ddPToUa1bt86+Hw8//LDmzp2r5ORkSf+Mxb3nnntUpUoVe51JSUmaOHFimnoefPBBSUpTT3rfy3fffVd9+/ZVWFiYFi9erB07dmjnzp164IEHHI7Hc+fOqXDhwmmWT68tI1k5d+TEdq6X3XOcj4+Pww2TWTF37lzt3LlTGzdu1NNPP62oqCiHIH+jGlJSUnThwgWH9tRjMlXqcZu6rtTxsHXr1k1zDCxatCjN9z+7+5WT56uMZPX4S3X965d6nsrKMXPq1Cl73+tfrx07dvCIrTzA0wBg5+rqqmbNmmnNmjU6duzYDe/KTf0FcuLEiTR9jx8/7nCF41alPp4nISHB4cav9E4SjRo1UqNGjZScnKxdu3Zp4sSJGjhwoAoXLqyOHTumu/6CBQvqxIkTadqPHz8uSTm6L9fq0aOHhg8frmnTpmn06NEZ9lu4cKHc3d21cuVKh0cVZfZM0oxk5zmWJ06cUL9+/VSjRg3t27dPL774ot5///1MlylQoIBcXFzy7PXs0KGDxowZo7179+bYOjOSlJSkc+fOOYSnkydPSko/UKUKCgpKc0PU9fMzk3rT1MCBA9N9TNCMGTPUsmVLSVLPnj312Wefad26dQoNDdXOnTs1depUe98CBQrYr3L369cv3e1d+7QFKf1j5pNPPlHjxo0d1i1Jly9fdpguWLCgvv/++zTLp75uOaVgwYJpbkq61e1ce467XnrnuJt5RmylSpXsN1U1adJEycnJmj59uj7//HO1b9/+hjW4uLikecTVyZMnHd5BuP64Ta37888/V8mSJW9YY3b3KyfPVxnJ6vGX6vp9KFCggGw2W5aOmaCgINlsNm3ZsiXdG495qkDu48oqHAwdOlTGGPXp00dXr15NMz8xMVErVqyQJDVt2lTSPyeNa+3cuVNRUVE3dSdsRlLvEv/5558d2lNrSY+rq6vCwsLsdzj/+OOPGfZt1qyZNm7caA9TqebOnSsfH59ce6xTSEiIhgwZojZt2igiIiLDfqmPCnJ1dbW3xcXF6eOPP07TN6euVicnJ6tTp06y2Wxas2aNxowZo4kTJ2rJkiWZLufr66uwsDAtWbLEoY6UlBR98sknKl68uMqXL5/tetL7ZS398xb50aNH7Vdtc9u8efMcpufPny9JmX6IQ+vWrfXXX3+pYMGCqlOnTpqvzJ6CEBUVpe3bt+uxxx7Tpk2b0nw1a9ZMX3zxhf2qWYsWLRQSEqJZs2Zp1qxZ8vLycrhS5+PjoyZNmmj37t26++67060ns+Cdymazpfkl/fPPP6cZMhMeHq7Lly9rzZo1Du0LFy684TayIzw8XBs3bnT4AzYlJUWfffbZTa+zXr168vb2TnOOO3bsmH3oUE4bN26cChQooOHDhyslJUUVKlRQSEiI5s+f73AnfWxsrBYvXmx/QsC1rj9GP/30UyUlJdmP0ZYtW8rNzU1//fVXut//1PB8Ixmda7JzvrpZWT3+MuLr66s6depo2bJlDr/rYmJi7E8ISdW6dWsZY/T333+n+1rdaGgUbh1XVuGgXr16mjp1qp599lnVrl1bffv2VZUqVZSYmKjdu3frww8/VNWqVdWmTRtVqFBBTz31lCZOnCgXFxe1atVKhw4d0quvvqoSJUpo0KBBOVbXgw8+qMDAQPXu3Vuvvfaa3NzcNHv2bIdPLZL+GcO0ceNGPfTQQwoNDVV8fLz9atb999+f4fojIyO1cuVKNWnSRMOHD1dgYKDmzZunVatWady4cQoICMixfbne2LFjb9jnoYce0rvvvqvOnTvrqaee0rlz5/T222+n+xd9tWrVtHDhQi1atEhlypSRl5fXTZ1MIyMjtWXLFn311VcqUqSIBg8erM2bN6t3796qWbNmmqtv1xozZoyaN2+uJk2a6MUXX5SHh4emTJmivXv3asGCBTd1BWr06NHatm2bnnjiCfvjYw4ePKhJkybp3Llzeuutt7K9zuzy8PDQO++8o5iYGNWtW1fffvutRo0apVatWqlhw4YZLjdw4EAtXrxY9913nwYNGqS7775bKSkpOnLkiL766isNHjxYYWFh6S6belX1pZdeSvf5n5cvX9aGDRv0ySef6Pnnn5erq6u6d++ud999V/ny5VO7du3SHL/vvfeeGjZsqEaNGqlv374qVaqULl++rD///FMrVqzQxo0bb/hatG7dWq+//roiIyMVHh6u/fv367XXXlPp0qWVlJRk7xcREaHx48era9euGjVqlMqVK6c1a9boyy+/lOT4yLFbMWzYMK1YsULNmjXTsGHD5O3trWnTptkfDXYz28mfP79effVV/e9//1P37t3VqVMnnTt3TiNHjpSXl5ciIyNzpPZrFShQQEOHDtVLL72k+fPnq2vXrho3bpy6dOmi1q1b6+mnn1ZCQoLeeustXbx4Md3zx5IlS+Tm5qbmzZtr3759evXVV1W9enX7+N1SpUrptdde07Bhw3TgwAH7WNlTp07p+++/l6+vr0aOHHnDWqtVq6YlS5Zo6tSpql27tlxcXFSnTp1sna8ys2LFinQ/mKF9+/ZZPv4y89prr+mhhx5Sy5Yt9fzzzys5OVlvvfWW/Pz8HD6psUGDBnrqqafUs2dP7dq1S/fdd598fX114sQJbd26VdWqVVPfvn2ztW/IJife3AUL27Nnj4mIiDChoaHGw8PD/uiT4cOHm9OnT9v7JScnmzfffNOUL1/euLu7m6CgINO1a1dz9OhRh/WFh4ebKlWqpNlOREREmrtJlc7TAIwx5vvvvzf169c3vr6+JiQkxERGRprp06c73Om7fft28+ijj5qSJUsaT09PU7BgQRMeHu5wV3fqNq59GoAxxvzyyy+mTZs2JiAgwHh4eJjq1as73KlszL93R3/22WcO7al3nF7f/3oZPa7meund0T9z5kxToUIF4+npacqUKWPGjBljZsyYkeZO50OHDpkWLVoYf39/+2NsMqv92nmpTwP46quvjIuLS5rX6Ny5cyY0NNTUrVvX4Q7a9GzZssU0bdrU+Pr6Gm9vb3PvvfeaFStWOPTJztMAduzYYfr162eqV69uAgMDjaurqylUqJB54IEH0txNn9Fd5Q899FCa9aZ3vKVXV0REhPH19TU///yzady4sfH29jaBgYGmb9++aR7ldf3TAIz55xFOr7zyiqlQoYLx8PCwPzpq0KBBGT765urVqyY4ONjUqFEjw9clKSnJFC9e3FSrVs3e9vvvvxtJRpJZt25dussdPHjQ9OrVy4SEhBh3d3dTqFAhU79+fTNq1Ch7n8yOmYSEBPPiiy+akJAQ4+XlZWrVqmWWLVuW7s/0kSNHTLt27Yyfn5/x9/c3jz32mFm9erWRZL744gt7v+x838LDw9P8jGzZssWEhYUZT09PU6RIETNkyBD7Ey1Sn+iRkcx+NqdPn27uvvtu+/ftkUcecXi8kzH/Hh9Zldn24uLi0jwOb9myZSYsLMx4eXkZX19f06xZM7Nt2zaH5VJfvx9++MG0adPG/np36tTJnDp1Ks12li1bZpo0aWLy5ctnPD09TcmSJU379u3N+vXrs7Rf58+fN+3btzf58+c3NpvN4XuX1fNVelL3I6MvY7J+/N3oHLN06VJTrVo1+2Ppxo4da5577jlToECBNH1nzpxpwsLC7Oe0smXLmu7du5tdu3Zluj+4dTZjcugJvQDwH9ajRw99/vnniomJcXYp/wlvvPGGXnnlFR05ciRXP7WqRYsWOnTokH7//fdc2wb+OxITE+1PDfnqq6+cXQ7+P4YBAABy1aRJkyRJFStWVGJiojZu3Kj3339fXbt2zdGg+sILL6hmzZoqUaKEzp8/r3nz5mndunXpfqoXIEm9e/dW8+bNVbRoUZ08eVLTpk1TVFTUDZ8gg7xFWAUA5CofHx+NHz9ehw4dUkJCgkJDQ/Xyyy/rlVdeydHtJCcna/jw4Tp58qRsNpsqV66sjz/+2P5RqsD1Ll++rBdffFFnzpyRu7u7atWqpdWrV2d6jwPyHsMAAAAAYFk8ugoAAACWRVgFAACAZRFWAQAAYFmEVQAAAFgWYRUAAACW9Z99dJV3zf7OLgG47cTtnqT4rH1SIYBreLlJV67ycB0gO3w8svbR21xZBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGURVgEAAGBZhFUAAABYFmEVAAAAlkVYBQAAgGW5ObsA3N5e7NVCbZtWV/lShRWXkKjvfjqgYe99oT8On7b3CQ7016jnH9H99SopwM9bW3/8Uy+M+0x/HTlj7/PlR8/rvjp3Oaz7sy9/UPf/m5Vn+wI42w+7dmr2zBmK+nWvzpw5o/HvT1bTZvfb51+JjdWE8e9o08b1ir54UcVCQtS5Szd16NjZiVUDzjVj+gfauH6dDh08IE8vL1WvXlPPDxqsUqXL2PtsWP+VFn+2SFG/7tPFixe18LOlqlCxkhOrRnZwZRW3pFGtcpq26BuFd39brftOkqurq1ZO7S8fLw97n0/HP6XSxYP0+MAPdG+nsTpy4rxWTxvg0EeSZizeplL3D7V/9R+1IK93B3CquLgrqlChgv5v2PB057/15hh9u3WL3hj7lpauWK2u3Xpo7BujtGnj+jyuFLCOH3ft1BMdO2vuvEWa+uFMJScnqe/TTyruyhV7n7i4OFWvUUsDBg52YqW4WVxZxS15pP8Uh+mnR3yioxvHqmblEtr2418qFxqssLtLq9ZjoxR14KQk6fkxi3Rkw1h1aFVbs5duty8bF39Vp85dztP6AStp2ChcDRuFZzj/p5/2qM0jbVX3njBJUvsOT+jzzxZp3969atL0/gyXA/7LJk+b7jA94vUxahZeX7/+uk+169SVJLVu84gk6fjfx/K8Ptw6rqwiR+Xz85IkXYj+5y9aT49//h6Kv5pk75OSYnQ1MUn1a5R1WPaJB+vo6Max+uHzYRoz6FH5+XjmUdXA7aFmrVravGmjTp06JWOMvv9uhw4fOqj6DRo6uzTAMmJi/rnoERAQ4ORKkFOcemX12LFjmjp1qr799ludPHlSNptNhQsXVv369fXMM8+oRIkSziwPN+HNwY9p249/6te/TkiS9h86qcPHz+n1AQ+r/6gFio27que7NVXRQgEqEvTviWTh6p06dPycTp29pCrlium1AW1UrXyIWved5KxdASzn/4a+opGRr6pF0/vk5uYmm82myNdGqVbtOs4uDbAEY4zeeWusataqrXJ3lXd2OcghTgurW7duVatWrVSiRAm1aNFCLVq0kDFGp0+f1rJlyzRx4kStWbNGDRo0yHQ9CQkJSkhIcGjz9OSKnDOM/78OqnZXMTXrOd7elpSUok4vTtfUyC468c1bSkpK1sbv9mvt1n0Oy85a+q39/7/+dUJ/Hjmtb+e/rBoVi2vPb7xtA0jS/Hkf6+ef9+i9SVNVrFgx/bBrl954faQKFQrWvfXqO7s8wOnGjn5df/y+X7PmzHd2KchBTgurgwYN0pNPPqnx48dnOH/gwIHauXNnpusZM2aMRo4c6dAWGRmZY3Uia959+XG1Dq+m+3tP0N+nLzrM2x11VPd2HKt8fl7ycHfT2Qsx+mbui/rh1yMZrm931FFdTUxSudBgwiogKT4+Xu9PGK/x70/SfeGNJUnlK1TU/v1RmjNrBmEVd7yxb7yuzV9v1IzZn6hwkSLOLgc5yGljVvfu3atnnnkmw/lPP/209u7de8P1DB06VNHR0Q5fQ4cOzclScQPjX35cjzStrgeefl+Hj5/LsN+lmHidvRCjsqGFVKtyqFZ+/XOGfSuXLSoPdzedOBudGyUDt52kpCQlJSXKxcXm0O7i4qoUY5xUFeB8xhiNHf2aNm5Ypw9mzFZI8eLOLgk5zGlXVosWLapvv/1WFSpUSHf+9u3bVbRo0Ruux9PTk7f9nWjC0A56olUdPT7oQ8XExqtwQX9JUnRMvOITEiVJ7e6vqTMXYnT05HlVvauY3h7SXiu+/lkbdvwmSSpdPEgdH6yjL7f+qrMXYlSpbBGNHdROu6OOavueA07bNyCvXYmN1ZEj/77j8PexY/otKkoBAQEqWqyY6tS9R+++/ZY8Pb1UtFgx/bBzp1YuX6YXX/o/J1YNONeY0a9pzeqVGv/eZPn6+urs2X+e4e3n5y8vr39u+o2OvqiTJ07o9Ol/ngF+6NBBSVLBoCAFBRVyTuHIMpsxzvmTfMqUKRo0aJD69Omj5s2bq3DhwrLZbDp58qTWrVun6dOna8KECZlefc2Md83+OVwx0hO3O/0boPoM/1ifrPhOkvRsp3AN6n6/ggv66+TZS5q38juN+XCtEpOSJUnFC+fXzNERqly2mPx8PHTs5EWt3bpXoz9YowuXrqS7fuSOuN2TFJ90437IHTu//05P9uyepv3hRx7V62+M1dkzZ/TehHe1/dutuhQdraLFiumx9k+oW0QP2Wy2dNaIvOLlJl25yhVuZ6hZrWK67SNff0MPt20nSVq+bIkiX/1fmj5P9+2nZ54dkKv1IWM+Hlk7bzktrErSokWLNH78eP3www9KTv4nuLi6uqp27dp64YUX1KFDh5teN2EVyD7CKnBzCKtA9t0WYTVVYmKizp49K0kKCgqSu7v7La+TsApkH2EVuDmEVSD7shpWLfEJVu7u7lkanwoAAIA7C59gBQAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCyCKsAAACwLMIqAAAALIuwCgAAAMsirAIAAMCybMYY4+wiAAAAgPS4ObuA3PLXmThnlwDcdsoW8lZA54+dXQZw24me303RcSnOLgO4rQR4Z+0NfoYBAAAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLLcstJp+fLlWV7hww8/fNPFAAAAANfKUlht27ZtllZms9mUnJx8K/UAAAAAdlkKqykpKbldBwAAAJDGLY1ZjY+Pz6k6AAAAgDSyHVaTk5P1+uuvKyQkRH5+fjpw4IAk6dVXX9WMGTNyvEAAAADcubIdVkePHq3Zs2dr3Lhx8vDwsLdXq1ZN06dPz9HiAAAAcGfLdlidO3euPvzwQ3Xp0kWurq729rvvvlu//fZbjhYHAACAO1u2w+rff/+tcuXKpWlPSUlRYmJijhQFAAAASDcRVqtUqaItW7akaf/ss89Us2bNHCkKAAAAkLL46KprRUZGqlu3bvr777+VkpKiJUuWaP/+/Zo7d65WrlyZGzUCAADgDpXtK6tt2rTRokWLtHr1atlsNg0fPlxRUVFasWKFmjdvnhs1AgAA4A6V7SurktSyZUu1bNkyp2sBAAAAHNxUWJWkXbt2KSoqSjabTZUqVVLt2rVzsi4AAAAg+2H12LFj6tSpk7Zt26b8+fNLki5evKj69etrwYIFKlGiRE7XCAAAgDtUtses9urVS4mJiYqKitL58+d1/vx5RUVFyRij3r1750aNAAAAuENl+8rqli1b9O2336pChQr2tgoVKmjixIlq0KBBjhYHAACAO1u2r6yGhoam+/D/pKQkhYSE5EhRAAAAgHQTYXXcuHEaMGCAdu3aJWOMpH9utnr++ef19ttv53iBAAAAuHPZTGrizESBAgVks9ns07GxsUpKSpKb2z+jCFL/7+vrq/Pnz+detdnw15k4Z5cA3HbKFvJWQOePnV0GcNuJnt9N0XEpzi4DuK0EeGftmmmWxqxOmDDhVmoBAAAAbkqWwmpERERu1wEAAACkcdMfCiBJcXFxaW62ypcv3y0VBAAAAKTK9g1WsbGx6t+/v4KDg+Xn56cCBQo4fAEAAAA5Jdth9aWXXtLGjRs1ZcoUeXp6avr06Ro5cqSKFSumuXPn5kaNAAAAuENlexjAihUrNHfuXDVu3Fi9evVSo0aNVK5cOZUsWVLz5s1Tly5dcqNOAAAA3IGyfWX1/PnzKl26tKR/xqemPqqqYcOG+uabb3K2OgAAANzRsh1Wy5Qpo0OHDkmSKleurE8//VTSP1dc8+fPn5O1AQAA4A6X7bDas2dP/fTTT5KkoUOH2seuDho0SEOGDMnxAgEAAHDnyvaY1UGDBtn/36RJE/3222/atWuXypYtq+rVq+docbg9fTJjqubP+sChrUBgQc1bvkGS9O7oV7V+zQqH+RUqV9P4D/nkJNw5Xni4qtrULaG7igUo/mqyvvvjjCIX/Kg/T1yy95nydH11CS/rsNzOP87o/si19ukeTe9S+/qlVL1UoPL5eCj0yYWKvuL4SEHgv2z2jA+1acM6HT50QJ6eXqpWvaYGDByskqVK2/vcU6NSussOGPiiuvXonVel4ibd0nNWJSk0NFShoaE6evSoevXqpZkzZ+ZEXbjNlSxdVqMn/BtYXV0cL+LXDmugQf8baZ92d3fPs9oAK2hQKVgfrduvH/86JzdXF73aoYaW/l8zhb20QlcSkuz91u35W89+8K19OjHJ8SM9vT1cteGn49rw03GN6FQrz+oHrOLHH3bq8Sc6q1KVqkpOTtbUSRM0oG9vLVqyUt7ePpKk1esd76nZvnWLRo18RU3vb+GMkpFNtxxWU50/f15z5swhrEKS5OrqqsCCQRnOd/dwz3Q+8F/32JsbHaaf/eBbHfigg2qUDtS3v522tyckpeh0dHyG65m69jdJUsNKhXOnUMDi3p/ykcP08JFvqGXTBor6dZ9q1a4rSQoKKuTQZ/PXG1W7bphCipfIszpx83IsrALX+vvYEXV9pLncPdxVoXI1RTw1QEVDitvn/7J7lzq1biJfP39Vq1lbEU8NUP4CgU6sGHCuAB8PSdKFmKsO7Q0rFdafUx9X9JWr2hZ1Sq99ukdnL2UcXoE7XUzMZUlSQEBAuvPPnTurbVs3K/K1MXlZFm4BYRU5rkLlahr8yiiFlCipi+fPaeGcj/Ri3whN/Xix8gXkV+17G6phk+YKLlJMp47/rY+nT9bQ5/ro/RkL5O7h4ezyAacY3bW2vv3tlKKOXbS3rf/pby377rCOno1VyWA/DWtfXSuGNVf4sFW6et1wAACSMUYT3nlT1WvWVtly5dPts2r5Mvn6+KpJs+Z5XB1ulqXD6tGjRxUZGZnp0IKEhAQlJCQ4tHl6euZ2achE3XoN/50oe5cqVa2u3k+01vo1K9SuYzeFN2tpn12qTDndVbGyerRvpe+3b1GD8GZOqBhwrrd73KMqoQX0wMgvHdqX7Dhs/3/UsYvafeCc9r7/qFrWDNGKnUfzukzA8t4a87r+/H2/Ppw9L8M+K75YopYPtiYr3EayHFbbtWuX6fyLFy/eai1pZGUc7JgxYzRy5EiHtsjISHXr93KO14Ob4+XtrZJlyun4sSPpzg8MKqTgIkV1/Gj684H/snERddWqdnE9+NpXOn7+SqZ9T12M09GzsSpbJF8eVQfcPt4aO0rfbN6kD2Z+rMKFi6TbZ/ePu3T40EGNfvPdPK4OtyLLYTWjsR/Xzu/evXu2Nr58+fJM5x84cOCG6xg6dKheeOEFhzZPT08du8RbZFaRePWqjh4+qKrV079T+VL0RZ05fYobrnDHeatHXbWuE6qHRn2lw2dibti/gJ+HQgJ9dfJiXB5UB9wejDF6e+wofb1xvaZOn6OQa+6PuN7ypYtVsXIVla9QMQ8rxK3KclidNWtWjm+8bdu2stlsMsZk2Mdms2W6Dk9Pzwwu5XMyd5bpk95VWIP7VKhwUV28cF4L53ykK7GxataqjeKuXNG8mdPUoHEzBRYM0qkTxzXnw4nKF5Bf9cKbOrt0IM+80/Meta9fWp3f2aSYuEQFB3hJki5dSVR8YrJ8Pd009LG79cXOIzp1IU6hhfw0/IkaOnc5Xit3/vsuRHCAlwrn91aZwv6SpMolCigmPlHHzsbqQuzVdLcN/JeMe+M1fblmld6eMEk+vr46e/aMJMnPz19eXl72fjExMdqw7ks9P/glZ5WKm+TUMatFixbV5MmT1bZt23Tn79mzR7Vr187bonDLzp45pTdHDNWl6AsKyF9AFarcrfEfzFXhIsWUkBCvQwf+0Ia1KxQbc1kFChZS9Vp19H8jx8nHx9fZpQN55snmFSRJq4e3dGjvO22b5n9zQMkpRpVDC6hjo7IK8HXXyQtx2vLrKfV8f4ti4v99Dmuv+8tr6GP/fiDL2siWDusB/usWf7ZQkvTMkxEO7cNHvqHWjzxqn163drWMjFo+8FCe1odbZzOZXdbMZQ8//LBq1Kih1157Ld35P/30k2rWrKmUlOy/pf/XGa6sAtlVtpC3AjrzSWJAdkXP76boOIafAdkR4O1y405y8pXVIUOGKDY2NsP55cqV06ZNm/KwIgAAAFiJU8Nqo0aNMp3v6+ur8PDwPKoGAAAAVpO1668AAACAE9xUWP3444/VoEEDFStWTIcP//PQ6gkTJuiLL77I0eIAAABwZ8t2WJ06dapeeOEFPfjgg7p48aKSk5MlSfnz59eECRNyuj4AAADcwbIdVidOnKiPPvpIw4YNk6urq729Tp06+uWXX3K0OAAAANzZsh1WDx48qJo1a6Zp9/T0zPTOfgAAACC7sh1WS5curT179qRpX7NmjSpXrpwTNQEAAACSbuLRVUOGDFG/fv0UHx8vY4y+//57LViwQGPGjNH06dNzo0YAAADcobIdVnv27KmkpCS99NJLunLlijp37qyQkBC999576tixY27UCAAAgDvULX3c6tmzZ5WSkqLg4OCcrClH8HGrQPbxcavAzeHjVoHsy5OPWw0KCrqVxQEAAIBMZTusli5dWjabLcP5Bw4cuKWCAAAAgFTZDqsDBw50mE5MTNTu3bu1du1aDRkyJKfqAgAAALIfVp9//vl02ydPnqxdu3bdckEAAABAqmw/ZzUjrVq10uLFi3NqdQAAAEDOhdXPP/9cgYGBObU6AAAAIPvDAGrWrOlwg5UxRidPntSZM2c0ZcqUHC0OAAAAd7Zsh9W2bds6TLu4uKhQoUJq3LixKlasmFN1AQAAANkLq0lJSSpVqpRatmypIkWK5FZNAAAAgKRsjll1c3NT3759lZCQkFv1AAAAAHbZvsEqLCxMu3fvzo1aAAAAAAfZHrP67LPPavDgwTp27Jhq164tX19fh/l33313jhUHAACAO1uWw2qvXr00YcIEPfHEE5Kk5557zj7PZrPJGCObzabk5OScrxIAAAB3pCyH1Tlz5mjs2LE6ePBgbtYDAAAA2GU5rBpjJEklS5bMtWIAAACAa2XrBqtrPwwAAAAAyG3ZusGqfPnyNwys58+fv6WCAAAAgFTZCqsjR45UQEBAbtUCAAAAOMhWWO3YsaOCg4NzqxYAAADAQZbHrDJeFQAAAHkty2E19WkAAAAAQF7J8jCAlJSU3KwDAAAASCNbj64CAAAA8hJhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBl2YwxxtlFAAAAAOlxc3YBueWvM3HOLgG47ZQt5K34JGdXAdx+vNwk70enO7sM4LYSt/TJLPVjGAAAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsy83ZBeC/55MZUzV/1gcObQUCC2re8g2SpHdHv6r1a1Y4zK9QuZrGf/hxntUIWNEPu3Zq9swZivp1r86cOaPx709W02b32+dXr1Ih3eUGDR6iHr2ezKsyAad6sV11tb23lMoXD1Dc1WR999spDZu7U38cj3boV6F4fo3qVleNqhSVi4sUdeSiur69QUfPxkqSejWvoCfuK6caZQoqn4+HinSZq+grV52xS7gBwipyRcnSZTV6wr+B1dXF8SJ+7bAGGvS/kfZpd3f3PKsNsKq4uCuqUKGCHnm0nQYPHJBm/oavtzpMb936jUa8Okz3N2+ZVyUCTteoShFNW/OrfvjzjNxcXTSiSx2tjHxANZ9brCsJSZKk0kX8teGN1pqz/neNWvijoq9cVcXi+RWfmGxfj4+nm9btPqp1u4/q9W73OGt3kAWEVeQKV1dXBRYMynC+u4d7pvOBO1HDRuFq2Cg8w/lBhQo5TH+9cYPq3hOm4iVK5HZpgGU88vqXDtNPT/xGR+d0Vc2yQdr260lJ0sjOdfTlD0c1bO739n6HTl12WG7Syn2SpEZViuZyxbhVhFXkir+PHVHXR5rL3cNdFSpXU8RTA1Q0pLh9/i+7d6lT6yby9fNXtZq1FfHUAOUvEOjEioHby7mzZ7Xlm816ffRYZ5cCOFU+Hw9J0oWYBEmSzSY9UKeE3l36s5YPf0DVyxTU4VOX9dbin7Ti+8POLBU3iRuskOMqVK6mwa+M0uvvTtFzLw3XhXNn9WLfCF2KvihJqn1vQw0Z/obGvP+R+vQfrD+i9mnoc32UeJWxQkBWLf9iqXx8fNWseQtnlwI41Zs9w7Tt15P69cgFSVJwgLf8vT30YrvqWrf7mNqMWKPl3x3SwpfvV8MqRZxcLW6G06+sxsXF6YcfflBgYKAqV67sMC8+Pl6ffvqpunfvnuHyCQkJSkhIcGjz9PTMlVqRNXXrNfx3ouxdqlS1uno/0Vrr16xQu47dFN7s3/F1pcqU010VK6tH+1b6fvsWNQhv5oSKgdvPsqWL9WDrNpzvcEcb/1R9VSsVqGb/+/emXRebTZK08vvDmrhiryTp50PnFVahsPq0rKSt+046pVbcPKdeWf39999VqVIl3XfffapWrZoaN26sEydO2OdHR0erZ8+ema5jzJgxCggIcPgaM2ZMbpeObPDy9lbJMuV0/NiRdOcHBhVScJGiOn40/fkAHP34wy4dOnhQ7R573NmlAE7z7pP11LpuqFq+ukp/n7tibz97OV6JSSmKOnrRof/+YxdVIsgvj6tETnBqWH355ZdVrVo1nT59Wvv371e+fPnUoEEDHTmS9dAydOhQRUdHO3wNHTo0F6tGdiVevaqjhw9meEPVpeiLOnP6FDdcAVm0dPHnqlyliipUrOjsUgCnGN+nnh65t5QeGL5ah0/HOMxLTErRD3+eUfmQAIf2u4oF6MgZx5uscHtw6jCAb7/9VuvXr1dQUJCCgoK0fPly9evXT40aNdKmTZvk6+t7w3V4enpm8DZYXM4XjCyZPuldhTW4T4UKF9XFC+e1cM5HuhIbq2at2ijuyhXNmzlNDRo3U2DBIJ06cVxzPpyofAH5VS+8qbNLB5zqSmyswx/rfx87pt+iohQQEKCixYpJkmJiYvTVV2s1eMjLzioTcKoJT9XXE/eV1eNj1ikmLlGF83tLkqKvXFX81X8eTTV+2c/6eHBTbf31pDb/ckItahbXg///Kmyqwvm9VTi/t8oWzSdJqlqygC7HJero2Vj7zVqwBqeG1bi4OLm5OZYwefJkubi4KDw8XPPnz3dSZbgVZ8+c0psjhupS9AUF5C+gClXu1vgP5qpwkWJKSIjXoQN/aMPaFYqNuawCBQupeq06+r+R4+Tjc+M/ToD/sn379urJnv+O0X973D9Dmh5+5FG9/sY/d/2vXb1KMkatHmztlBoBZ3u61T/3t6wb5fgz0Of9zfpk0x+SpOXfHdaAD7ZpSLvqeqd3Pf1+PFqdxq3Xt1Gn7P2fbFlJr3SsZZ9e/0abNOuBNdiMMcZZG7/nnns0YMAAdevWLc28/v37a968ebp06ZKSk5PTWTpzf53hyiqQXWULeSs+ydlVALcfLzfJ+9Hpzi4DuK3ELc3aJ+85dczqo48+qgULFqQ7b9KkSerUqZOcmKUBAADgZE69spqbuLIKZB9XVoGbw5VVIPtuiyurAAAAQGYIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAswioAAAAsi7AKAAAAyyKsAgAAwLIIqwAAALAsmzHGOLsI3DkSEhI0ZswYDR06VJ6ens4uB7gt8HMD3Bx+dv4bCKvIU5cuXVJAQICio6OVL18+Z5cD3Bb4uQFuDj87/w0MAwAAAIBlEVYBAABgWYRVAAAAWBZhFXnK09NTkZGRDHQHsoGfG+Dm8LPz38ANVgAAALAsrqwCAADAsgirAAAAsCzCKgAAACyLsAoAAADLIqwiz0yZMkWlS5eWl5eXateurS1btji7JMDSvvnmG7Vp00bFihWTzWbTsmXLnF0ScFsYM2aM6tatK39/fwUHB6tt27bav3+/s8vCTSKsIk8sWrRIAwcO1LBhw7R79241atRIrVq10pEjR5xdGmBZsbGxql69uiZNmuTsUoDbyubNm9WvXz/t2LFD69atU1JSklq0aKHY2Fhnl4abwKOrkCfCwsJUq1YtTZ061d5WqVIltW3bVmPGjHFiZcDtwWazaenSpWrbtq2zSwFuO2fOnFFwcLA2b96s++67z9nlIJu4sopcd/XqVf3www9q0aKFQ3uLFi307bffOqkqAMCdIjo6WpIUGBjo5EpwMwiryHVnz55VcnKyChcu7NBeuHBhnTx50klVAQDuBMYYvfDCC2rYsKGqVq3q7HJwE9ycXQDuHDabzWHaGJOmDQCAnNS/f3/9/PPP2rp1q7NLwU0irCLXBQUFydXVNc1V1NOnT6e52goAQE4ZMGCAli9frm+++UbFixd3djm4SQwDQK7z8PBQ7dq1tW7dOof2devWqX79+k6qCgDwX2WMUf/+/bVkyRJt3LhRpUuXdnZJuAVcWUWeeOGFF9StWzfVqVNH9erV04cffqgjR47omWeecXZpgGXFxMTozz//tE8fPHhQe/bsUWBgoEJDQ51YGWBt/fr10/z58/XFF1/I39/f/s5eQECAvL29nVwdsotHVyHPTJkyRePGjdOJEydUtWpVjR8/nkeIAJn4+uuv1aRJkzTtERERmj17dt4XBNwmMrofYtasWerRo0feFoNbRlgFAACAZTFmFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQBu0YgRI1SjRg37dI8ePdS2bds8r+PQoUOy2Wzas2dPrm3j+n29GXlRJ4D/DsIqgP+kHj16yGazyWazyd3dXWXKlNGLL76o2NjYXN/2e++9l+WPQ83r4Na4cWMNHDgwT7YFADnBzdkFAEBueeCBBzRr1iwlJiZqy5YtevLJJxUbG6upU6em6ZuYmCh3d/cc2W5AQECOrAcAwJVVAP9hnp6eKlKkiEqUKKHOnTurS5cuWrZsmaR/386eOXOmypQpI09PTxljFB0draeeekrBwcHKly+fmjZtqp9++slhvWPHjlXhwoXl7++v3r17Kz4+3mH+9cMAUlJS9Oabb6pcuXLy9PRUaGioRo8eLUkqXbq0JKlmzZqy2Wxq3LixfblZs2apUqVK8vLyUsWKFTVlyhSH7Xz//feqWbOmvLy8VKdOHe3evfuWX7OXX35Z5cuXl4+Pj8qUKaNXX31ViYmJafp98MEHKlGihHx8fPT444/r4sWLDvNvVDsAZBVXVgHcMby9vR2C159//qlPP/1UixcvlqurqyTpoYceUmBgoFavXq2AgAB98MEHatasmX7//XcFBgbq008/VWRkpCZPnqxGjRrp448/1vvvv68yZcpkuN2hQ4fqo48+0vjx49WwYUOdOHFCv/32m6R/Auc999yj9evXq0qVKvLw8JAkffTRR4qMjNSkSZNUs2ZN7d69W3369JGvr68iIiIUGxur1q1bq2nTpvrkk0908OBBPf/887f8Gvn7+2v27NkqVqyYfvnlF/Xp00f+/v566aWX0rxuK1as0KVLl9S7d2/169dP8+bNy1LtAJAtBgD+gyIiIswjjzxin/7uu+9MwYIFTYcOHYwxxkRGRhp3d3dz+vRpe58NGzaYfPnymfj4eId1lS1b1nzwwQfGGGPq1atnnnnmGYf5YWFhpnr16ulu+9KlS8bT09N89NFH6dZ58OBBI8ns3r3bob1EiRJm/vz5Dm2vv/66qVevnjHGmA8++MAEBgaa2NhY+/ypU6emu65rhYeHm+effz7D+dcbN26cqV27tn06MjLSuLq6mqNHj9rb1qxZY1xcXMyJEyeyVHtG+wwA6eHKKoD/rJUrV8rPz09JSUlKTEzUI488ookTJ9rnlyxZUoUKFbJP//DDD4qJiVHBggUd1hMXF6e//vpLkhQVFaVnnnnGYX69evW0adOmdGuIiopSQkKCmjVrluW6z5w5o6NHj6p3797q06ePvT0pKck+HjYqKkrVq1eXj4+PQx236vPPP9eECRP0559/KiYmRklJScqXL59Dn9DQUBUvXtxhuykpKdq/f79cXV1vWDsAZAdhFcB/VpMmTTR16lS5u7urWLFiaW6g8vX1dZhOSUlR0aJF9fXXX6dZV/78+W+qBm9v72wvk5KSIumft9PDwsIc5qUOVzDG3FQ9mdmxY4c6duyokSNHqmXLlgoICNDChQv1zjvvZLqczWaz/5uV2gEgOwirAP6zfH19Va5cuSz3r1Wrlk6ePCk3NzeVKlUq3T6VKlXSjh071L17d3vbjh07MlznXXfdJW9vb23YsEFPPvlkmvmpY1STk5PtbYULF1ZISIgOHDigLl26pLveypUr6+OPP1ZcXJw9EGdWR1Zs27ZNJUuW1LBhw+xthw8fTtPvyJEjOn78uIoVKyZJ2r59u1xcXFS+fPks1Q4A2UFYBYD/7/7771e9evXUtm1bvfnmm6pQoYKOHz+u1atXq23btqpTp46ef/55RUREqE6dOmrYsKHmzZunffv2ZXiDlZeXl15++WW99NJL8vDwUIMGDXTmzBnt27dPvXv3VnBwsLy9vbV27VoVL15cXl5eCggI0IgRI/Tcc88pX758atWqlRISErRr1y5duHBBL7zwgjp37qxhw4apd+/eeuWVV3To0CG9/fbbWdrPM2fOpHmua5EiRVSuXDkdOXJECxcuVN26dbVq1SotXbo03X2KiIjQ22+/rUuXLum5555Thw4dVKRIEUm6Ye0AkC3OHjQLALnh+husrhcZGelwU1SqS5cumQEDBphixYoZd3d3U6JECdOlSxdz5MgRe5/Ro0eboKAg4+fnZyIiIsxLL72U4Q1WxhiTnJxsRo0aZUqWLGnc3d1NaGioeeONN+zzP/roI1OiRAnj4uJiwsPD7e3z5s0zNWrUMB4eHqZAgQLmvvvuM0uWLLHP3759u6levbrx8PAwNWrUMIsXL87SDVaS0nxFRkYaY4wZMmSIKViwoPHz8zNPPPGEGT9+vAkICEjzuk2ZMsUUK1bMeHl5mXbt2pnz5887bCez2rnBCkB22IzJhYFPAAAAQA7gQwEAAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJZFWAUAAIBlEVYBAABgWYRVAAAAWBZhFQAAAJb1/wByYXm+MgtwFwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the average probabilities across all models\n",
    "average_probs = np.mean([\n",
    "    model_prob_df[[f'model_{i}_probs_class_0', f'model_{i}_probs_class_1', f'model_{i}_probs_class_2']].values\n",
    "    for i in range(1, n_models + 1)\n",
    "], axis=0)\n",
    "\n",
    "# Determine predicted labels from the average probabilities\n",
    "predicted_labels_from_average = np.argmax(average_probs, axis=1)\n",
    "\n",
    "# Calculate accuracy of the averaged model\n",
    "average_model_accuracy = np.mean(predicted_labels_from_average == model_prob_df['True_labels'].values)\n",
    "\n",
    "print(\"Accuracy of the averaged model:\", average_model_accuracy)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    \"\"\" Convert array of labels to one-hot encoded numpy array. \"\"\"\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def categorical_cross_entropy(true_labels, predicted_probs):\n",
    "    \"\"\" Compute the categorical cross-entropy loss. \"\"\"\n",
    "    true_labels_one_hot = one_hot_encode(true_labels, num_classes=predicted_probs.shape[1])\n",
    "    log_probs = np.log(predicted_probs + 1e-15)  # Adding a small epsilon to avoid log(0)\n",
    "    loss = -np.sum(true_labels_one_hot * log_probs) / true_labels_one_hot.shape[0]\n",
    "    return loss\n",
    "\n",
    "# Assuming 'average_probs' is already calculated as suggested in the previous step\n",
    "true_labels = model_prob_df['True_labels'].values\n",
    "loss = categorical_cross_entropy(true_labels, average_probs)\n",
    "\n",
    "print(\"Categorical Cross-Entropy Loss of the averaged model:\", loss)\n",
    "\n",
    "# Plotting the confusion matrix for the Simple Averaging method\n",
    "plot_confusion_matrix(true_labels, predicted_labels_from_average, 'Confusion Matrix of Simple Averaging for Roberta Large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the majority vote: 0.737\n",
      "Adjusted Categorical Cross-Entropy Loss for the majority vote: 1.1017980634493731\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have a DataFrame called 'model_prob_df' which includes the predicted probabilities for each class\n",
    "# from each model and it looks something like this:\n",
    "# Columns: ['model_1_probs_class_0', 'model_1_probs_class_1', 'model_1_probs_class_2', ..., 'model_5_probs_class_0', 'model_5_probs_class_1', 'model_5_probs_class_2', 'True_labels']\n",
    "\n",
    "# Extract predicted labels for each model\n",
    "predicted_labels = {}\n",
    "n_models = 5  # Adjust the number of models based on your ensemble\n",
    "for i in range(1, n_models + 1):\n",
    "    probs = model_prob_df[[f'model_{i}_probs_class_0', f'model_{i}_probs_class_1', f'model_{i}_probs_class_2']].values\n",
    "    predicted_labels[f'model_{i}'] = np.argmax(probs, axis=1)\n",
    "\n",
    "# Constructing an array of all predictions\n",
    "all_predictions = np.vstack([predicted_labels[f'model_{i}'] for i in range(1, n_models + 1)])\n",
    "\n",
    "# Majority vote calculation\n",
    "majority_vote = np.apply_along_axis(lambda x: np.bincount(x, minlength=3).argmax(), 0, all_predictions)\n",
    "\n",
    "# Calculate the accuracy of the majority vote\n",
    "true_labels = model_prob_df['True_labels'].values\n",
    "majority_vote_accuracy = np.mean(majority_vote == true_labels)\n",
    "\n",
    "print(\"Accuracy of the majority vote:\", majority_vote_accuracy)\n",
    "# Assuming majority_vote contains the predicted labels from your majority vote procedure\n",
    "num_classes = 3  # Set this to the number of classes in your dataset\n",
    "majority_vote_probs = one_hot_encode(majority_vote, num_classes)\n",
    "\n",
    "def smooth_one_hot(true_labels, num_classes, smoothing=0.1):\n",
    "    \"\"\"\n",
    "    Apply label smoothing. Default epsilon is 0.1.\n",
    "    This helps to mitigate the issue with hard zero probabilities leading to infinite loss.\n",
    "    \"\"\"\n",
    "    # Create an array where all elements are equal to a small value (smoothing / num_classes)\n",
    "    confidence = 1.0 - smoothing\n",
    "    smooth_prob = smoothing / num_classes\n",
    "    one_hot_labels = np.eye(num_classes)[true_labels]\n",
    "    return one_hot_labels * confidence + smooth_prob\n",
    "\n",
    "# Calculate the smoothed probabilities for the majority vote predictions\n",
    "majority_vote_smooth_probs = smooth_one_hot(majority_vote, num_classes, smoothing=0.05)  # Smoothing with a small epsilon value\n",
    "\n",
    "# Calculate loss with the smoothed probabilities\n",
    "loss = categorical_cross_entropy(true_labels, majority_vote_smooth_probs)\n",
    "\n",
    "print(\"Adjusted Categorical Cross-Entropy Loss for the majority vote:\", loss)\n",
    "\n",
    "\n",
    "# Plotting the confusion matrix for the Majority Vote method\n",
    "plot_confusion_matrix(true_labels, majority_vote, 'Confusion Matrix of Majority Vote for Roberta Large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
