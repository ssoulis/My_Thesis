{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2933,"sourceType":"datasetVersion","datasetId":1670},{"sourceId":4548821,"sourceType":"datasetVersion","datasetId":2655798},{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775},{"sourceId":8083662,"sourceType":"datasetVersion","datasetId":4771616},{"sourceId":8083668,"sourceType":"datasetVersion","datasetId":4771621},{"sourceId":8083678,"sourceType":"datasetVersion","datasetId":4771629},{"sourceId":8084913,"sourceType":"datasetVersion","datasetId":4772442}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the SNLI test data (including true labels)\nsnli_test_path = \"/kaggle/input/stanford-natural-language-inference-corpus/snli_1.0_test.csv\"\nsnli_test_df = pd.read_csv(snli_test_path)\n\n# Define file paths for SNLI prediction files\nsnli_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_snli_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_snli_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_snli_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_snli = \"/kaggle/working/combined_snli_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_snli_df = pd.DataFrame(columns=columns)\n\nlabel_mapping = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n\n# Load and merge the predictions\nfor model, path in snli_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_snli_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_snli_df['True_Label'] = snli_test_df['gold_label'].map(label_mapping)\n\n# Convert True_Label to integer type\ncombined_snli_df['True_Label'] = combined_snli_df['True_Label'].astype('Int64')\n\n# Save the combined DataFrame to CSV\ncombined_snli_df.to_csv(output_csv_path_snli, index=False)\n\nprint(f\"Combined SNLI predictions with true labels saved to {output_csv_path_snli}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-12T10:26:32.273082Z","iopub.execute_input":"2024-04-12T10:26:32.273803Z","iopub.status.idle":"2024-04-12T10:26:32.796471Z","shell.execute_reply.started":"2024-04-12T10:26:32.273766Z","shell.execute_reply":"2024-04-12T10:26:32.795096Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Combined SNLI predictions with true labels saved to /kaggle/working/combined_snli_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:32.798393Z","iopub.execute_input":"2024-04-12T10:26:32.798751Z","iopub.status.idle":"2024-04-12T10:26:32.825019Z","shell.execute_reply.started":"2024-04-12T10:26:32.798721Z","shell.execute_reply":"2024-04-12T10:26:32.823621Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.034767         0.962592               0.002641   \n1            0.001921         0.319032               0.679047   \n2            0.998783         0.000764               0.000453   \n3            0.001001         0.997708               0.001291   \n4            0.001080         0.301363               0.697557   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.012451         0.927093               0.060457   \n1            0.752766         0.242251               0.004983   \n2            0.000254         0.004494               0.995253   \n3            0.005844         0.990736               0.003419   \n4            0.278348         0.718575               0.003076   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.008653        0.947434              0.043913           1  \n1           0.740332        0.256434              0.003235           0  \n2           0.004677        0.060481              0.934843           2  \n3           0.034056        0.956687              0.009257           1  \n4           0.498761        0.499270              0.001969           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_matched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_matched.csv\"\nmnli_matched_test_df = pd.read_csv(mnli_matched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_matched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_matched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_matched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_matched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_matched = \"/kaggle/working/combined_mnli_matched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_matched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_matched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_matched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_matched_df['True_Label'] = mnli_matched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_matched_df.to_csv(output_csv_path_mnli_matched, index=False)\n\nprint(f\"Combined MNLI-matched predictions with true labels saved to {output_csv_path_mnli_matched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:32.826451Z","iopub.execute_input":"2024-04-12T10:26:32.826800Z","iopub.status.idle":"2024-04-12T10:26:33.171966Z","shell.execute_reply.started":"2024-04-12T10:26:32.826772Z","shell.execute_reply":"2024-04-12T10:26:33.170607Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Combined MNLI-matched predictions with true labels saved to /kaggle/working/combined_mnli_matched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_matched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.175533Z","iopub.execute_input":"2024-04-12T10:26:33.175969Z","iopub.status.idle":"2024-04-12T10:26:33.196973Z","shell.execute_reply.started":"2024-04-12T10:26:33.175933Z","shell.execute_reply":"2024-04-12T10:26:33.195730Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005164         0.993364               0.001472   \n1            0.999153         0.000526               0.000321   \n2            0.000989         0.044792               0.954219   \n3            0.994965         0.004808               0.000228   \n4            0.999657         0.000220               0.000123   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.017844         0.950246               0.031909   \n1            0.001413         0.002030               0.996557   \n2            0.954781         0.042249               0.002970   \n3            0.000343         0.003511               0.996146   \n4            0.000079         0.000496               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.010844        0.983012              0.006144           1  \n1           0.005388        0.007536              0.987076           2  \n2           0.853862        0.143483              0.002655           0  \n3           0.004128        0.070757              0.925115           2  \n4           0.003864        0.029262              0.966875           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005164</td>\n      <td>0.993364</td>\n      <td>0.001472</td>\n      <td>0.017844</td>\n      <td>0.950246</td>\n      <td>0.031909</td>\n      <td>0.010844</td>\n      <td>0.983012</td>\n      <td>0.006144</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.999153</td>\n      <td>0.000526</td>\n      <td>0.000321</td>\n      <td>0.001413</td>\n      <td>0.002030</td>\n      <td>0.996557</td>\n      <td>0.005388</td>\n      <td>0.007536</td>\n      <td>0.987076</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000989</td>\n      <td>0.044792</td>\n      <td>0.954219</td>\n      <td>0.954781</td>\n      <td>0.042249</td>\n      <td>0.002970</td>\n      <td>0.853862</td>\n      <td>0.143483</td>\n      <td>0.002655</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.994965</td>\n      <td>0.004808</td>\n      <td>0.000228</td>\n      <td>0.000343</td>\n      <td>0.003511</td>\n      <td>0.996146</td>\n      <td>0.004128</td>\n      <td>0.070757</td>\n      <td>0.925115</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999657</td>\n      <td>0.000220</td>\n      <td>0.000123</td>\n      <td>0.000079</td>\n      <td>0.000496</td>\n      <td>0.999425</td>\n      <td>0.003864</td>\n      <td>0.029262</td>\n      <td>0.966875</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_mismatched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_mismatched.csv\"\nmnli_mismatched_test_df = pd.read_csv(mnli_mismatched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_mismatched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_mismatched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_mismatched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_mismatched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_mismatched = \"/kaggle/working/combined_mnli_mismatched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_mismatched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_mismatched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_mismatched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_mismatched_df['True_Label'] = mnli_mismatched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_mismatched_df.to_csv(output_csv_path_mnli_mismatched, index=False)\n\nprint(f\"Combined MNLI-mismatched predictions with true labels saved to {output_csv_path_mnli_mismatched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.198558Z","iopub.execute_input":"2024-04-12T10:26:33.198894Z","iopub.status.idle":"2024-04-12T10:26:33.498001Z","shell.execute_reply.started":"2024-04-12T10:26:33.198862Z","shell.execute_reply":"2024-04-12T10:26:33.496783Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Combined MNLI-mismatched predictions with true labels saved to /kaggle/working/combined_mnli_mismatched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_mismatched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.500983Z","iopub.execute_input":"2024-04-12T10:26:33.501392Z","iopub.status.idle":"2024-04-12T10:26:33.522731Z","shell.execute_reply.started":"2024-04-12T10:26:33.501355Z","shell.execute_reply":"2024-04-12T10:26:33.521543Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.999667         0.000160               0.000173   \n1            0.998119         0.000962               0.000919   \n2            0.000552         0.004809               0.994639   \n3            0.827653         0.171961               0.000386   \n4            0.000292         0.002875               0.996833   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.000068         0.000402               0.999529   \n1            0.000183         0.001511               0.998306   \n2            0.986062         0.012020               0.001918   \n3            0.000478         0.270953               0.728569   \n4            0.975167         0.021904               0.002929   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.000894        0.003787              0.995318           2  \n1           0.006421        0.010224              0.983355           2  \n2           0.975041        0.023354              0.001605           0  \n3           0.001722        0.796122              0.202156           2  \n4           0.965952        0.032748              0.001300           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.999667</td>\n      <td>0.000160</td>\n      <td>0.000173</td>\n      <td>0.000068</td>\n      <td>0.000402</td>\n      <td>0.999529</td>\n      <td>0.000894</td>\n      <td>0.003787</td>\n      <td>0.995318</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.998119</td>\n      <td>0.000962</td>\n      <td>0.000919</td>\n      <td>0.000183</td>\n      <td>0.001511</td>\n      <td>0.998306</td>\n      <td>0.006421</td>\n      <td>0.010224</td>\n      <td>0.983355</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000552</td>\n      <td>0.004809</td>\n      <td>0.994639</td>\n      <td>0.986062</td>\n      <td>0.012020</td>\n      <td>0.001918</td>\n      <td>0.975041</td>\n      <td>0.023354</td>\n      <td>0.001605</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.827653</td>\n      <td>0.171961</td>\n      <td>0.000386</td>\n      <td>0.000478</td>\n      <td>0.270953</td>\n      <td>0.728569</td>\n      <td>0.001722</td>\n      <td>0.796122</td>\n      <td>0.202156</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000292</td>\n      <td>0.002875</td>\n      <td>0.996833</td>\n      <td>0.975167</td>\n      <td>0.021904</td>\n      <td>0.002929</td>\n      <td>0.965952</td>\n      <td>0.032748</td>\n      <td>0.001300</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nanli_r1_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r1.csv\"\nanli_r1_test_df = pd.read_csv(anli_r1_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nanli_r1_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r1_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r1_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r1_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r1 = \"/kaggle/working/combined_anli_r1_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r1_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r1_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r1_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r1_df['True_Label'] = anli_r1_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r1_df.to_csv(output_csv_path_anli_r1, index=False)\n\nprint(f\"Combined ANLI Round 1 predictions with true labels saved to {output_csv_path_anli_r1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.524462Z","iopub.execute_input":"2024-04-12T10:26:33.524799Z","iopub.status.idle":"2024-04-12T10:26:33.638916Z","shell.execute_reply.started":"2024-04-12T10:26:33.524771Z","shell.execute_reply":"2024-04-12T10:26:33.637693Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Combined ANLI Round 1 predictions with true labels saved to /kaggle/working/combined_anli_r1_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r1_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.640611Z","iopub.execute_input":"2024-04-12T10:26:33.643650Z","iopub.status.idle":"2024-04-12T10:26:33.661302Z","shell.execute_reply.started":"2024-04-12T10:26:33.643609Z","shell.execute_reply":"2024-04-12T10:26:33.659845Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.015388         0.976305               0.008307   \n1            0.224603         0.501549               0.273848   \n2            0.006642         0.976690               0.016669   \n3            0.966494         0.032235               0.001272   \n4            0.880736         0.028293               0.090971   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.996714         0.000376               0.002910   \n1            0.875720         0.000724               0.123556   \n2            0.999484         0.000330               0.000186   \n3            0.000686         0.998181               0.001133   \n4            0.000378         0.000197               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.322974        0.667628              0.009398           0  \n1           0.998526        0.000604              0.000869           0  \n2           0.783352        0.212241              0.004407           0  \n3           0.002134        0.989523              0.008343           1  \n4           0.023283        0.013253              0.963464           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015388</td>\n      <td>0.976305</td>\n      <td>0.008307</td>\n      <td>0.996714</td>\n      <td>0.000376</td>\n      <td>0.002910</td>\n      <td>0.322974</td>\n      <td>0.667628</td>\n      <td>0.009398</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.224603</td>\n      <td>0.501549</td>\n      <td>0.273848</td>\n      <td>0.875720</td>\n      <td>0.000724</td>\n      <td>0.123556</td>\n      <td>0.998526</td>\n      <td>0.000604</td>\n      <td>0.000869</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.006642</td>\n      <td>0.976690</td>\n      <td>0.016669</td>\n      <td>0.999484</td>\n      <td>0.000330</td>\n      <td>0.000186</td>\n      <td>0.783352</td>\n      <td>0.212241</td>\n      <td>0.004407</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.966494</td>\n      <td>0.032235</td>\n      <td>0.001272</td>\n      <td>0.000686</td>\n      <td>0.998181</td>\n      <td>0.001133</td>\n      <td>0.002134</td>\n      <td>0.989523</td>\n      <td>0.008343</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.880736</td>\n      <td>0.028293</td>\n      <td>0.090971</td>\n      <td>0.000378</td>\n      <td>0.000197</td>\n      <td>0.999425</td>\n      <td>0.023283</td>\n      <td>0.013253</td>\n      <td>0.963464</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 2 test data (including true labels)\nanli_r2_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r2.csv\"\nanli_r2_test_df = pd.read_csv(anli_r2_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r2_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r2_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r2_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r2_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r2 = \"/kaggle/working/combined_anli_r2_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r2_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r2_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r2_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r2_df['True_Label'] = anli_r2_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r2_df.to_csv(output_csv_path_anli_r2, index=False)\n\nprint(f\"Combined ANLI Round 2 predictions with true labels saved to {output_csv_path_anli_r2}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.663131Z","iopub.execute_input":"2024-04-12T10:26:33.663523Z","iopub.status.idle":"2024-04-12T10:26:33.788995Z","shell.execute_reply.started":"2024-04-12T10:26:33.663489Z","shell.execute_reply":"2024-04-12T10:26:33.788067Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Combined ANLI Round 2 predictions with true labels saved to /kaggle/working/combined_anli_r2_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r2_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.792711Z","iopub.execute_input":"2024-04-12T10:26:33.793570Z","iopub.status.idle":"2024-04-12T10:26:33.813383Z","shell.execute_reply.started":"2024-04-12T10:26:33.793529Z","shell.execute_reply":"2024-04-12T10:26:33.811837Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.001309         0.029617               0.969075   \n1            0.724144         0.273676               0.002180   \n2            0.071604         0.917894               0.010503   \n3            0.066162         0.929179               0.004659   \n4            0.906199         0.089873               0.003928   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.999506         0.000264               0.000230   \n1            0.026951         0.054230               0.918819   \n2            0.001282         0.998108               0.000610   \n3            0.007091         0.992694               0.000215   \n4            0.006259         0.989432               0.004309   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.863365        0.133388              0.003246           0  \n1           0.072900        0.904344              0.022756           1  \n2           0.027402        0.972218              0.000380           0  \n3           0.632171        0.365194              0.002635           1  \n4           0.064109        0.234642              0.701249           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001309</td>\n      <td>0.029617</td>\n      <td>0.969075</td>\n      <td>0.999506</td>\n      <td>0.000264</td>\n      <td>0.000230</td>\n      <td>0.863365</td>\n      <td>0.133388</td>\n      <td>0.003246</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.724144</td>\n      <td>0.273676</td>\n      <td>0.002180</td>\n      <td>0.026951</td>\n      <td>0.054230</td>\n      <td>0.918819</td>\n      <td>0.072900</td>\n      <td>0.904344</td>\n      <td>0.022756</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.071604</td>\n      <td>0.917894</td>\n      <td>0.010503</td>\n      <td>0.001282</td>\n      <td>0.998108</td>\n      <td>0.000610</td>\n      <td>0.027402</td>\n      <td>0.972218</td>\n      <td>0.000380</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.066162</td>\n      <td>0.929179</td>\n      <td>0.004659</td>\n      <td>0.007091</td>\n      <td>0.992694</td>\n      <td>0.000215</td>\n      <td>0.632171</td>\n      <td>0.365194</td>\n      <td>0.002635</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.906199</td>\n      <td>0.089873</td>\n      <td>0.003928</td>\n      <td>0.006259</td>\n      <td>0.989432</td>\n      <td>0.004309</td>\n      <td>0.064109</td>\n      <td>0.234642</td>\n      <td>0.701249</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 3 test data (including true labels)\nanli_r3_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r3.csv\"\nanli_r3_test_df = pd.read_csv(anli_r3_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r3_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r3_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r3_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r3_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r3 = \"/kaggle/working/combined_anli_r3_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r3_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r3_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r3_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r3_df['True_Label'] = anli_r3_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r3_df.to_csv(output_csv_path_anli_r3, index=False)\n\nprint(f\"Combined ANLI Round 3 predictions with true labels saved to {output_csv_path_anli_r3}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.815221Z","iopub.execute_input":"2024-04-12T10:26:33.815705Z","iopub.status.idle":"2024-04-12T10:26:33.940795Z","shell.execute_reply.started":"2024-04-12T10:26:33.815671Z","shell.execute_reply":"2024-04-12T10:26:33.939513Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Combined ANLI Round 3 predictions with true labels saved to /kaggle/working/combined_anli_r3_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r3_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.942499Z","iopub.execute_input":"2024-04-12T10:26:33.943858Z","iopub.status.idle":"2024-04-12T10:26:33.964596Z","shell.execute_reply.started":"2024-04-12T10:26:33.943809Z","shell.execute_reply":"2024-04-12T10:26:33.963479Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005921         0.960529               0.033551   \n1            0.009586         0.934714               0.055700   \n2            0.003428         0.976393               0.020179   \n3            0.004633         0.023985               0.971382   \n4            0.017428         0.633695               0.348877   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.022959         0.976533               0.000509   \n1            0.999611         0.000205               0.000185   \n2            0.002020         0.997897               0.000083   \n3            0.974441         0.024459               0.001100   \n4            0.984416         0.011166               0.004419   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.001848        0.998084              0.000067           0  \n1           0.951772        0.048075              0.000153           0  \n2           0.001014        0.998984              0.000002           0  \n3           0.996749        0.000989              0.002262           0  \n4           0.000518        0.128416              0.871066           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005921</td>\n      <td>0.960529</td>\n      <td>0.033551</td>\n      <td>0.022959</td>\n      <td>0.976533</td>\n      <td>0.000509</td>\n      <td>0.001848</td>\n      <td>0.998084</td>\n      <td>0.000067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009586</td>\n      <td>0.934714</td>\n      <td>0.055700</td>\n      <td>0.999611</td>\n      <td>0.000205</td>\n      <td>0.000185</td>\n      <td>0.951772</td>\n      <td>0.048075</td>\n      <td>0.000153</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003428</td>\n      <td>0.976393</td>\n      <td>0.020179</td>\n      <td>0.002020</td>\n      <td>0.997897</td>\n      <td>0.000083</td>\n      <td>0.001014</td>\n      <td>0.998984</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004633</td>\n      <td>0.023985</td>\n      <td>0.971382</td>\n      <td>0.974441</td>\n      <td>0.024459</td>\n      <td>0.001100</td>\n      <td>0.996749</td>\n      <td>0.000989</td>\n      <td>0.002262</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017428</td>\n      <td>0.633695</td>\n      <td>0.348877</td>\n      <td>0.984416</td>\n      <td>0.011166</td>\n      <td>0.004419</td>\n      <td>0.000518</td>\n      <td>0.128416</td>\n      <td>0.871066</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values\nmissing_values_anli1 = combined_anli_r1_df.isnull().sum()\n\nmissing_values_anli2 = combined_anli_r2_df.isnull().sum()\n\nmissing_values_anli3 = combined_anli_r3_df.isnull().sum()\n\nmissing_values_snli = combined_snli_df.isnull().sum()\n\nmissing_values_mnli_matched = combined_mnli_matched_df.isnull().sum()\n\nmissing_values_mnli_mismatched = combined_mnli_mismatched_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.966596Z","iopub.execute_input":"2024-04-12T10:26:33.967240Z","iopub.status.idle":"2024-04-12T10:26:33.979809Z","shell.execute_reply.started":"2024-04-12T10:26:33.967206Z","shell.execute_reply":"2024-04-12T10:26:33.978567Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"missing_values_anli1","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.981746Z","iopub.execute_input":"2024-04-12T10:26:33.982199Z","iopub.status.idle":"2024-04-12T10:26:33.995743Z","shell.execute_reply.started":"2024-04-12T10:26:33.982157Z","shell.execute_reply":"2024-04-12T10:26:33.994515Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli2","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:33.997174Z","iopub.execute_input":"2024-04-12T10:26:33.997616Z","iopub.status.idle":"2024-04-12T10:26:34.010898Z","shell.execute_reply.started":"2024-04-12T10:26:33.997578Z","shell.execute_reply":"2024-04-12T10:26:34.009714Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli3","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:34.012647Z","iopub.execute_input":"2024-04-12T10:26:34.013112Z","iopub.status.idle":"2024-04-12T10:26:34.024689Z","shell.execute_reply.started":"2024-04-12T10:26:34.013070Z","shell.execute_reply":"2024-04-12T10:26:34.023423Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_snli","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:34.026337Z","iopub.execute_input":"2024-04-12T10:26:34.026693Z","iopub.status.idle":"2024-04-12T10:26:34.037895Z","shell.execute_reply.started":"2024-04-12T10:26:34.026661Z","shell.execute_reply":"2024-04-12T10:26:34.036682Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment         0\nDeberta_Neutral            0\nDeberta_Contradiction      0\nRoberta_Entailment         0\nRoberta_Neutral            0\nRoberta_Contradiction      0\nAlbert_Entailment          0\nAlbert_Neutral             0\nAlbert_Contradiction       0\nTrue_Label               176\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_matched","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:34.039250Z","iopub.execute_input":"2024-04-12T10:26:34.039758Z","iopub.status.idle":"2024-04-12T10:26:34.050957Z","shell.execute_reply.started":"2024-04-12T10:26:34.039718Z","shell.execute_reply":"2024-04-12T10:26:34.049791Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_mismatched","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:34.052567Z","iopub.execute_input":"2024-04-12T10:26:34.053089Z","iopub.status.idle":"2024-04-12T10:26:34.064471Z","shell.execute_reply.started":"2024-04-12T10:26:34.053055Z","shell.execute_reply":"2024-04-12T10:26:34.063132Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"combined_snli_df.dropna(subset=['True_Label'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:34.066020Z","iopub.execute_input":"2024-04-12T10:26:34.067812Z","iopub.status.idle":"2024-04-12T10:26:34.081893Z","shell.execute_reply.started":"2024-04-12T10:26:34.067776Z","shell.execute_reply":"2024-04-12T10:26:34.080652Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Verify missing values again after removal\nmissing_values_snli_after_removal = combined_snli_df.isnull().sum()\nprint(missing_values_snli_after_removal)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:34.083895Z","iopub.execute_input":"2024-04-12T10:26:34.084397Z","iopub.status.idle":"2024-04-12T10:26:34.095519Z","shell.execute_reply.started":"2024-04-12T10:26:34.084352Z","shell.execute_reply":"2024-04-12T10:26:34.094425Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T10:26:34.097827Z","iopub.execute_input":"2024-04-12T10:26:34.098811Z","iopub.status.idle":"2024-04-12T10:26:34.121870Z","shell.execute_reply.started":"2024-04-12T10:26:34.098760Z","shell.execute_reply":"2024-04-12T10:26:34.120598Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 9824 entries, 0 to 9999\nData columns (total 10 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   Deberta_Entailment     9824 non-null   float64\n 1   Deberta_Neutral        9824 non-null   float64\n 2   Deberta_Contradiction  9824 non-null   float64\n 3   Roberta_Entailment     9824 non-null   float64\n 4   Roberta_Neutral        9824 non-null   float64\n 5   Roberta_Contradiction  9824 non-null   float64\n 6   Albert_Entailment      9824 non-null   float64\n 7   Albert_Neutral         9824 non-null   float64\n 8   Albert_Contradiction   9824 non-null   float64\n 9   True_Label             9824 non-null   Int64  \ndtypes: Int64(1), float64(9)\nmemory usage: 853.8 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to add difference features to the dataset\ndef add_difference_features(df):\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        df[f'Deberta_Roberta_{label}_diff'] = abs(df[f'Deberta_{label}'] - df[f'Roberta_{label}'])\n        df[f'Deberta_Albert_{label}_diff'] = abs(df[f'Deberta_{label}'] - df[f'Albert_{label}'])\n        df[f'Roberta_Albert_{label}_diff'] = abs(df[f'Roberta_{label}'] - df[f'Albert_{label}'])\n    return df\n\n# Apply this function to each dataset\ncombined_snli_df = add_difference_features(combined_snli_df)\ncombined_mnli_matched_df = add_difference_features(combined_mnli_matched_df)\ncombined_mnli_mismatched_df = add_difference_features(combined_mnli_mismatched_df)\ncombined_anli_r1_df = add_difference_features(combined_anli_r1_df)\ncombined_anli_r2_df = add_difference_features(combined_anli_r2_df)\ncombined_anli_r3_df = add_difference_features(combined_anli_r3_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:02:32.542672Z","iopub.execute_input":"2024-04-12T11:02:32.543205Z","iopub.status.idle":"2024-04-12T11:02:32.588685Z","shell.execute_reply.started":"2024-04-12T11:02:32.543171Z","shell.execute_reply":"2024-04-12T11:02:32.587527Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"combined_mnli_matched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:02:43.431589Z","iopub.execute_input":"2024-04-12T11:02:43.432254Z","iopub.status.idle":"2024-04-12T11:02:43.460146Z","shell.execute_reply.started":"2024-04-12T11:02:43.432214Z","shell.execute_reply":"2024-04-12T11:02:43.458620Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005164         0.993364               0.001472   \n1            0.999153         0.000526               0.000321   \n2            0.000989         0.044792               0.954219   \n3            0.994965         0.004808               0.000228   \n4            0.999657         0.000220               0.000123   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.017844         0.950246               0.031909   \n1            0.001413         0.002030               0.996557   \n2            0.954781         0.042249               0.002970   \n3            0.000343         0.003511               0.996146   \n4            0.000079         0.000496               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \\\n0           0.010844        0.983012              0.006144           1   \n1           0.005388        0.007536              0.987076           2   \n2           0.853862        0.143483              0.002655           0   \n3           0.004128        0.070757              0.925115           2   \n4           0.003864        0.029262              0.966875           2   \n\n   Deberta_Roberta_Entailment_diff  Deberta_Albert_Entailment_diff  \\\n0                         0.012681                        0.005680   \n1                         0.997740                        0.993764   \n2                         0.953792                        0.852873   \n3                         0.994622                        0.990837   \n4                         0.999579                        0.995794   \n\n   Roberta_Albert_Entailment_diff  Deberta_Roberta_Neutral_diff  \\\n0                        0.007000                      0.043117   \n1                        0.003975                      0.001504   \n2                        0.100919                      0.002543   \n3                        0.003785                      0.001297   \n4                        0.003785                      0.000277   \n\n   Deberta_Albert_Neutral_diff  Roberta_Albert_Neutral_diff  \\\n0                     0.010352                     0.032766   \n1                     0.007010                     0.005505   \n2                     0.098691                     0.101234   \n3                     0.065949                     0.067246   \n4                     0.029042                     0.028765   \n\n   Deberta_Roberta_Contradiction_diff  Deberta_Albert_Contradiction_diff  \\\n0                            0.030437                           0.004671   \n1                            0.996236                           0.986755   \n2                            0.951249                           0.951564   \n3                            0.995919                           0.924888   \n4                            0.999302                           0.966752   \n\n   Roberta_Albert_Contradiction_diff  \n0                           0.025766  \n1                           0.009481  \n2                           0.000315  \n3                           0.071031  \n4                           0.032550  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n      <th>Deberta_Roberta_Entailment_diff</th>\n      <th>Deberta_Albert_Entailment_diff</th>\n      <th>Roberta_Albert_Entailment_diff</th>\n      <th>Deberta_Roberta_Neutral_diff</th>\n      <th>Deberta_Albert_Neutral_diff</th>\n      <th>Roberta_Albert_Neutral_diff</th>\n      <th>Deberta_Roberta_Contradiction_diff</th>\n      <th>Deberta_Albert_Contradiction_diff</th>\n      <th>Roberta_Albert_Contradiction_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005164</td>\n      <td>0.993364</td>\n      <td>0.001472</td>\n      <td>0.017844</td>\n      <td>0.950246</td>\n      <td>0.031909</td>\n      <td>0.010844</td>\n      <td>0.983012</td>\n      <td>0.006144</td>\n      <td>1</td>\n      <td>0.012681</td>\n      <td>0.005680</td>\n      <td>0.007000</td>\n      <td>0.043117</td>\n      <td>0.010352</td>\n      <td>0.032766</td>\n      <td>0.030437</td>\n      <td>0.004671</td>\n      <td>0.025766</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.999153</td>\n      <td>0.000526</td>\n      <td>0.000321</td>\n      <td>0.001413</td>\n      <td>0.002030</td>\n      <td>0.996557</td>\n      <td>0.005388</td>\n      <td>0.007536</td>\n      <td>0.987076</td>\n      <td>2</td>\n      <td>0.997740</td>\n      <td>0.993764</td>\n      <td>0.003975</td>\n      <td>0.001504</td>\n      <td>0.007010</td>\n      <td>0.005505</td>\n      <td>0.996236</td>\n      <td>0.986755</td>\n      <td>0.009481</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000989</td>\n      <td>0.044792</td>\n      <td>0.954219</td>\n      <td>0.954781</td>\n      <td>0.042249</td>\n      <td>0.002970</td>\n      <td>0.853862</td>\n      <td>0.143483</td>\n      <td>0.002655</td>\n      <td>0</td>\n      <td>0.953792</td>\n      <td>0.852873</td>\n      <td>0.100919</td>\n      <td>0.002543</td>\n      <td>0.098691</td>\n      <td>0.101234</td>\n      <td>0.951249</td>\n      <td>0.951564</td>\n      <td>0.000315</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.994965</td>\n      <td>0.004808</td>\n      <td>0.000228</td>\n      <td>0.000343</td>\n      <td>0.003511</td>\n      <td>0.996146</td>\n      <td>0.004128</td>\n      <td>0.070757</td>\n      <td>0.925115</td>\n      <td>2</td>\n      <td>0.994622</td>\n      <td>0.990837</td>\n      <td>0.003785</td>\n      <td>0.001297</td>\n      <td>0.065949</td>\n      <td>0.067246</td>\n      <td>0.995919</td>\n      <td>0.924888</td>\n      <td>0.071031</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999657</td>\n      <td>0.000220</td>\n      <td>0.000123</td>\n      <td>0.000079</td>\n      <td>0.000496</td>\n      <td>0.999425</td>\n      <td>0.003864</td>\n      <td>0.029262</td>\n      <td>0.966875</td>\n      <td>2</td>\n      <td>0.999579</td>\n      <td>0.995794</td>\n      <td>0.003785</td>\n      <td>0.000277</td>\n      <td>0.029042</td>\n      <td>0.028765</td>\n      <td>0.999302</td>\n      <td>0.966752</td>\n      <td>0.032550</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Function to split data\ndef split_data(df):\n    X = df.drop(columns=['True_Label'])  # Features\n    y = df['True_Label']                 # Labels\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    return X_train, X_val, y_train, y_val\n\n# Split data for each dataset\nX_train_snli, X_val_snli, y_train_snli, y_val_snli = split_data(combined_snli_df)\nX_train_mnli_matched, X_val_mnli_matched, y_train_mnli_matched, y_val_mnli_matched = split_data(combined_mnli_matched_df)\nX_train_mnli_mismatched, X_val_mnli_mismatched, y_train_mnli_mismatched, y_val_mnli_mismatched = split_data(combined_mnli_mismatched_df)\nX_train_anli_r1, X_val_anli_r1, y_train_anli_r1, y_val_anli_r1 = split_data(combined_anli_r1_df)\nX_train_anli_r2, X_val_anli_r2, y_train_anli_r2, y_val_anli_r2 = split_data(combined_anli_r2_df)\nX_train_anli_r3, X_val_anli_r3, y_train_anli_r3, y_val_anli_r3 = split_data(combined_anli_r3_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:02:59.986280Z","iopub.execute_input":"2024-04-12T11:02:59.986790Z","iopub.status.idle":"2024-04-12T11:03:00.030051Z","shell.execute_reply.started":"2024-04-12T11:02:59.986753Z","shell.execute_reply":"2024-04-12T11:03:00.029013Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"X_train_mnli_matched","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:03:08.929869Z","iopub.execute_input":"2024-04-12T11:03:08.930333Z","iopub.status.idle":"2024-04-12T11:03:08.963066Z","shell.execute_reply.started":"2024-04-12T11:03:08.930281Z","shell.execute_reply":"2024-04-12T11:03:08.961553Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n1672            0.998960         0.000485               0.000555   \n7383            0.000280         0.003708               0.996011   \n7825            0.995251         0.002183               0.002566   \n6784            0.000494         0.008504               0.991003   \n5328            0.701676         0.237751               0.060573   \n...                  ...              ...                    ...   \n5734            0.001678         0.735655               0.262667   \n5191            0.989200         0.003094               0.007706   \n5390            0.002120         0.128626               0.869254   \n860             0.997554         0.002238               0.000208   \n7270            0.001487         0.989322               0.009191   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n1672            0.001178         0.058175               0.940648   \n7383            0.963184         0.035134               0.001683   \n7825            0.004226         0.006285               0.989489   \n6784            0.997151         0.002360               0.000489   \n5328            0.020482         0.038785               0.940733   \n...                  ...              ...                    ...   \n5734            0.154772         0.807297               0.037931   \n5191            0.000496         0.001119               0.998385   \n5390            0.895957         0.101495               0.002547   \n860             0.000236         0.002361               0.997403   \n7270            0.001216         0.998411               0.000373   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  \\\n1672           0.002565        0.012469              0.984965   \n7383           0.830383        0.167441              0.002176   \n7825           0.008342        0.003635              0.988023   \n6784           0.986155        0.013108              0.000736   \n5328           0.123899        0.145232              0.730869   \n...                 ...             ...                   ...   \n5734           0.178774        0.804987              0.016240   \n5191           0.004160        0.003519              0.992321   \n5390           0.871351        0.115298              0.013351   \n860            0.000912        0.004808              0.994281   \n7270           0.067423        0.930167              0.002409   \n\n      Deberta_Roberta_Entailment_diff  Deberta_Albert_Entailment_diff  \\\n1672                         0.997782                        0.996394   \n7383                         0.962903                        0.830103   \n7825                         0.991025                        0.986909   \n6784                         0.996657                        0.985661   \n5328                         0.681194                        0.577777   \n...                               ...                             ...   \n5734                         0.153094                        0.177096   \n5191                         0.988704                        0.985040   \n5390                         0.893837                        0.869230   \n860                          0.997318                        0.996642   \n7270                         0.000271                        0.065936   \n\n      Roberta_Albert_Entailment_diff  Deberta_Roberta_Neutral_diff  \\\n1672                        0.001388                      0.057689   \n7383                        0.132801                      0.031425   \n7825                        0.004116                      0.004102   \n6784                        0.010996                      0.006144   \n5328                        0.103417                      0.198966   \n...                              ...                           ...   \n5734                        0.024002                      0.071642   \n5191                        0.003664                      0.001975   \n5390                        0.024607                      0.027131   \n860                         0.000675                      0.000123   \n7270                        0.066207                      0.009089   \n\n      Deberta_Albert_Neutral_diff  Roberta_Albert_Neutral_diff  \\\n1672                     0.011984                     0.045705   \n7383                     0.163733                     0.132308   \n7825                     0.001453                     0.002650   \n6784                     0.004605                     0.010749   \n5328                     0.092519                     0.106447   \n...                           ...                          ...   \n5734                     0.069332                     0.002310   \n5191                     0.000425                     0.002400   \n5390                     0.013328                     0.013803   \n860                      0.002569                     0.002447   \n7270                     0.059155                     0.068244   \n\n      Deberta_Roberta_Contradiction_diff  Deberta_Albert_Contradiction_diff  \\\n1672                            0.940093                           0.984410   \n7383                            0.994329                           0.993836   \n7825                            0.986923                           0.985457   \n6784                            0.990513                           0.990266   \n5328                            0.880160                           0.670296   \n...                                  ...                                ...   \n5734                            0.224736                           0.246428   \n5191                            0.990679                           0.984615   \n5390                            0.866706                           0.855903   \n860                             0.997195                           0.994073   \n7270                            0.008818                           0.006781   \n\n      Roberta_Albert_Contradiction_diff  \n1672                           0.044317  \n7383                           0.000493  \n7825                           0.001466  \n6784                           0.000247  \n5328                           0.209864  \n...                                 ...  \n5734                           0.021692  \n5191                           0.006064  \n5390                           0.010804  \n860                            0.003122  \n7270                           0.002037  \n\n[7852 rows x 18 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>Deberta_Roberta_Entailment_diff</th>\n      <th>Deberta_Albert_Entailment_diff</th>\n      <th>Roberta_Albert_Entailment_diff</th>\n      <th>Deberta_Roberta_Neutral_diff</th>\n      <th>Deberta_Albert_Neutral_diff</th>\n      <th>Roberta_Albert_Neutral_diff</th>\n      <th>Deberta_Roberta_Contradiction_diff</th>\n      <th>Deberta_Albert_Contradiction_diff</th>\n      <th>Roberta_Albert_Contradiction_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1672</th>\n      <td>0.998960</td>\n      <td>0.000485</td>\n      <td>0.000555</td>\n      <td>0.001178</td>\n      <td>0.058175</td>\n      <td>0.940648</td>\n      <td>0.002565</td>\n      <td>0.012469</td>\n      <td>0.984965</td>\n      <td>0.997782</td>\n      <td>0.996394</td>\n      <td>0.001388</td>\n      <td>0.057689</td>\n      <td>0.011984</td>\n      <td>0.045705</td>\n      <td>0.940093</td>\n      <td>0.984410</td>\n      <td>0.044317</td>\n    </tr>\n    <tr>\n      <th>7383</th>\n      <td>0.000280</td>\n      <td>0.003708</td>\n      <td>0.996011</td>\n      <td>0.963184</td>\n      <td>0.035134</td>\n      <td>0.001683</td>\n      <td>0.830383</td>\n      <td>0.167441</td>\n      <td>0.002176</td>\n      <td>0.962903</td>\n      <td>0.830103</td>\n      <td>0.132801</td>\n      <td>0.031425</td>\n      <td>0.163733</td>\n      <td>0.132308</td>\n      <td>0.994329</td>\n      <td>0.993836</td>\n      <td>0.000493</td>\n    </tr>\n    <tr>\n      <th>7825</th>\n      <td>0.995251</td>\n      <td>0.002183</td>\n      <td>0.002566</td>\n      <td>0.004226</td>\n      <td>0.006285</td>\n      <td>0.989489</td>\n      <td>0.008342</td>\n      <td>0.003635</td>\n      <td>0.988023</td>\n      <td>0.991025</td>\n      <td>0.986909</td>\n      <td>0.004116</td>\n      <td>0.004102</td>\n      <td>0.001453</td>\n      <td>0.002650</td>\n      <td>0.986923</td>\n      <td>0.985457</td>\n      <td>0.001466</td>\n    </tr>\n    <tr>\n      <th>6784</th>\n      <td>0.000494</td>\n      <td>0.008504</td>\n      <td>0.991003</td>\n      <td>0.997151</td>\n      <td>0.002360</td>\n      <td>0.000489</td>\n      <td>0.986155</td>\n      <td>0.013108</td>\n      <td>0.000736</td>\n      <td>0.996657</td>\n      <td>0.985661</td>\n      <td>0.010996</td>\n      <td>0.006144</td>\n      <td>0.004605</td>\n      <td>0.010749</td>\n      <td>0.990513</td>\n      <td>0.990266</td>\n      <td>0.000247</td>\n    </tr>\n    <tr>\n      <th>5328</th>\n      <td>0.701676</td>\n      <td>0.237751</td>\n      <td>0.060573</td>\n      <td>0.020482</td>\n      <td>0.038785</td>\n      <td>0.940733</td>\n      <td>0.123899</td>\n      <td>0.145232</td>\n      <td>0.730869</td>\n      <td>0.681194</td>\n      <td>0.577777</td>\n      <td>0.103417</td>\n      <td>0.198966</td>\n      <td>0.092519</td>\n      <td>0.106447</td>\n      <td>0.880160</td>\n      <td>0.670296</td>\n      <td>0.209864</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5734</th>\n      <td>0.001678</td>\n      <td>0.735655</td>\n      <td>0.262667</td>\n      <td>0.154772</td>\n      <td>0.807297</td>\n      <td>0.037931</td>\n      <td>0.178774</td>\n      <td>0.804987</td>\n      <td>0.016240</td>\n      <td>0.153094</td>\n      <td>0.177096</td>\n      <td>0.024002</td>\n      <td>0.071642</td>\n      <td>0.069332</td>\n      <td>0.002310</td>\n      <td>0.224736</td>\n      <td>0.246428</td>\n      <td>0.021692</td>\n    </tr>\n    <tr>\n      <th>5191</th>\n      <td>0.989200</td>\n      <td>0.003094</td>\n      <td>0.007706</td>\n      <td>0.000496</td>\n      <td>0.001119</td>\n      <td>0.998385</td>\n      <td>0.004160</td>\n      <td>0.003519</td>\n      <td>0.992321</td>\n      <td>0.988704</td>\n      <td>0.985040</td>\n      <td>0.003664</td>\n      <td>0.001975</td>\n      <td>0.000425</td>\n      <td>0.002400</td>\n      <td>0.990679</td>\n      <td>0.984615</td>\n      <td>0.006064</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>0.002120</td>\n      <td>0.128626</td>\n      <td>0.869254</td>\n      <td>0.895957</td>\n      <td>0.101495</td>\n      <td>0.002547</td>\n      <td>0.871351</td>\n      <td>0.115298</td>\n      <td>0.013351</td>\n      <td>0.893837</td>\n      <td>0.869230</td>\n      <td>0.024607</td>\n      <td>0.027131</td>\n      <td>0.013328</td>\n      <td>0.013803</td>\n      <td>0.866706</td>\n      <td>0.855903</td>\n      <td>0.010804</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>0.997554</td>\n      <td>0.002238</td>\n      <td>0.000208</td>\n      <td>0.000236</td>\n      <td>0.002361</td>\n      <td>0.997403</td>\n      <td>0.000912</td>\n      <td>0.004808</td>\n      <td>0.994281</td>\n      <td>0.997318</td>\n      <td>0.996642</td>\n      <td>0.000675</td>\n      <td>0.000123</td>\n      <td>0.002569</td>\n      <td>0.002447</td>\n      <td>0.997195</td>\n      <td>0.994073</td>\n      <td>0.003122</td>\n    </tr>\n    <tr>\n      <th>7270</th>\n      <td>0.001487</td>\n      <td>0.989322</td>\n      <td>0.009191</td>\n      <td>0.001216</td>\n      <td>0.998411</td>\n      <td>0.000373</td>\n      <td>0.067423</td>\n      <td>0.930167</td>\n      <td>0.002409</td>\n      <td>0.000271</td>\n      <td>0.065936</td>\n      <td>0.066207</td>\n      <td>0.009089</td>\n      <td>0.059155</td>\n      <td>0.068244</td>\n      <td>0.008818</td>\n      <td>0.006781</td>\n      <td>0.002037</td>\n    </tr>\n  </tbody>\n</table>\n<p>7852 rows × 18 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_train_mnli_matched","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:03:14.652720Z","iopub.execute_input":"2024-04-12T11:03:14.655014Z","iopub.status.idle":"2024-04-12T11:03:14.665063Z","shell.execute_reply.started":"2024-04-12T11:03:14.654960Z","shell.execute_reply":"2024-04-12T11:03:14.663479Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"1672    2\n7383    0\n7825    2\n6784    0\n5328    2\n       ..\n5734    1\n5191    2\n5390    0\n860     2\n7270    0\nName: True_Label, Length: 7852, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Model parameters\nlogistic_params = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'solver': ['liblinear', 'lbfgs'],\n    'penalty': ['l2']\n}\n\nxgb_params = {\n    'max_depth': [3, 5, 7],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'n_estimators': [100, 200, 300],\n    'subsample': [0.8, 0.9, 1.0]\n}\n\nmodels = {\n    \"Logistic Regression\": (LogisticRegression(random_state=42), logistic_params),\n    \"XGBoost\": (XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42), xgb_params)\n}\n\n\n# Dictionary to hold your data, assuming it's already split into training and validation sets\ndatasets = {\n    \"SNLI\": (X_train_snli, y_train_snli, X_val_snli, y_val_snli),\n    \"MNLI Matched\": (X_train_mnli_matched, y_train_mnli_matched, X_val_mnli_matched, y_val_mnli_matched),\n    \"MNLI Mismatched\": (X_train_mnli_mismatched, y_train_mnli_mismatched, X_val_mnli_mismatched, y_val_mnli_mismatched),\n    \"ANLI Round 1\": (X_train_anli_r1, y_train_anli_r1, X_val_anli_r1, y_val_anli_r1),\n    \"ANLI Round 2\": (X_train_anli_r2, y_train_anli_r2, X_val_anli_r2, y_val_anli_r2),\n    \"ANLI Round 3\": (X_train_anli_r3, y_train_anli_r3, X_val_anli_r3, y_val_anli_r3)\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:05:38.382828Z","iopub.execute_input":"2024-04-12T11:05:38.383324Z","iopub.status.idle":"2024-04-12T11:05:38.394538Z","shell.execute_reply.started":"2024-04-12T11:05:38.383280Z","shell.execute_reply":"2024-04-12T11:05:38.393301Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Define the model training functions\ndef tune_and_train_model(model, X_train, y_train, param_grid, model_name, task_name):\n    from sklearn.model_selection import GridSearchCV\n    print(f\"Starting hyperparameter tuning for {task_name} using {model_name}...\")\n    \n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1)\n    grid_search.fit(X_train, y_train)\n    \n    print(f\"Best parameters for {task_name} using {model_name}: {grid_search.best_params_}\")\n    print(f\"Best score for {task_name} using {model_name}: {grid_search.best_score_ * 100:.2f}%\\n\")\n    \n    return grid_search.best_estimator_\n\ndef evaluate_model(model, X_val, y_val, task_name):\n    y_pred = model.predict(X_val)\n    accuracy = accuracy_score(y_val, y_pred)\n    print(f\"Accuracy on {task_name}: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:05:42.816888Z","iopub.execute_input":"2024-04-12T11:05:42.817399Z","iopub.status.idle":"2024-04-12T11:05:42.827642Z","shell.execute_reply.started":"2024-04-12T11:05:42.817358Z","shell.execute_reply":"2024-04-12T11:05:42.825952Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Loop through each dataset\nfor task_name, data in datasets.items():\n    X_train, y_train, X_val, y_val = data\n    print(f\"Processing {task_name} dataset...\")\n    \n    # Loop through each model type\n    for model_name, (model, params) in models.items():\n        print(f\"Training {model_name} on {task_name}...\")\n        best_model = tune_and_train_model(model, X_train, y_train, params, model_name, task_name)\n        evaluate_model(best_model, X_val, y_val, task_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T11:05:52.370055Z","iopub.execute_input":"2024-04-12T11:05:52.370470Z","iopub.status.idle":"2024-04-12T11:53:30.989542Z","shell.execute_reply.started":"2024-04-12T11:05:52.370439Z","shell.execute_reply":"2024-04-12T11:53:30.988264Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Processing SNLI dataset...\nTraining Logistic Regression on SNLI...\nStarting hyperparameter tuning for SNLI using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for SNLI using Logistic Regression: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score for SNLI using Logistic Regression: 92.70%\n\nAccuracy on SNLI: 93.23%\nTraining XGBoost on SNLI...\nStarting hyperparameter tuning for SNLI using XGBoost...\nFitting 5 folds for each of 81 candidates, totalling 405 fits\nBest parameters for SNLI using XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\nBest score for SNLI using XGBoost: 92.95%\n\nAccuracy on SNLI: 92.98%\nProcessing MNLI Matched dataset...\nTraining Logistic Regression on MNLI Matched...\nStarting hyperparameter tuning for MNLI Matched using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for MNLI Matched using Logistic Regression: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\nBest score for MNLI Matched using Logistic Regression: 91.72%\n\nAccuracy on MNLI Matched: 92.15%\nTraining XGBoost on MNLI Matched...\nStarting hyperparameter tuning for MNLI Matched using XGBoost...\nFitting 5 folds for each of 81 candidates, totalling 405 fits\nBest parameters for MNLI Matched using XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.9}\nBest score for MNLI Matched using XGBoost: 91.93%\n\nAccuracy on MNLI Matched: 91.90%\nProcessing MNLI Mismatched dataset...\nTraining Logistic Regression on MNLI Mismatched...\nStarting hyperparameter tuning for MNLI Mismatched using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for MNLI Mismatched using Logistic Regression: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score for MNLI Mismatched using Logistic Regression: 91.86%\n\nAccuracy on MNLI Mismatched: 91.87%\nTraining XGBoost on MNLI Mismatched...\nStarting hyperparameter tuning for MNLI Mismatched using XGBoost...\nFitting 5 folds for each of 81 candidates, totalling 405 fits\nBest parameters for MNLI Mismatched using XGBoost: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\nBest score for MNLI Mismatched using XGBoost: 91.88%\n\nAccuracy on MNLI Mismatched: 91.61%\nProcessing ANLI Round 1 dataset...\nTraining Logistic Regression on ANLI Round 1...\nStarting hyperparameter tuning for ANLI Round 1 using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for ANLI Round 1 using Logistic Regression: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\nBest score for ANLI Round 1 using Logistic Regression: 76.50%\n\nAccuracy on ANLI Round 1: 72.50%\nTraining XGBoost on ANLI Round 1...\nStarting hyperparameter tuning for ANLI Round 1 using XGBoost...\nFitting 5 folds for each of 81 candidates, totalling 405 fits\nBest parameters for ANLI Round 1 using XGBoost: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\nBest score for ANLI Round 1 using XGBoost: 77.62%\n\nAccuracy on ANLI Round 1: 66.50%\nProcessing ANLI Round 2 dataset...\nTraining Logistic Regression on ANLI Round 2...\nStarting hyperparameter tuning for ANLI Round 2 using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for ANLI Round 2 using Logistic Regression: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\nBest score for ANLI Round 2 using Logistic Regression: 66.38%\n\nAccuracy on ANLI Round 2: 74.00%\nTraining XGBoost on ANLI Round 2...\nStarting hyperparameter tuning for ANLI Round 2 using XGBoost...\nFitting 5 folds for each of 81 candidates, totalling 405 fits\nBest parameters for ANLI Round 2 using XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.9}\nBest score for ANLI Round 2 using XGBoost: 66.12%\n\nAccuracy on ANLI Round 2: 70.00%\nProcessing ANLI Round 3 dataset...\nTraining Logistic Regression on ANLI Round 3...\nStarting hyperparameter tuning for ANLI Round 3 using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters for ANLI Round 3 using Logistic Regression: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score for ANLI Round 3 using Logistic Regression: 65.42%\n\nAccuracy on ANLI Round 3: 68.75%\nTraining XGBoost on ANLI Round 3...\nStarting hyperparameter tuning for ANLI Round 3 using XGBoost...\nFitting 5 folds for each of 81 candidates, totalling 405 fits\nBest parameters for ANLI Round 3 using XGBoost: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.9}\nBest score for ANLI Round 3 using XGBoost: 67.60%\n\nAccuracy on ANLI Round 3: 68.75%\n","output_type":"stream"}]}]}