{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2933,"sourceType":"datasetVersion","datasetId":1670},{"sourceId":4548821,"sourceType":"datasetVersion","datasetId":2655798},{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775},{"sourceId":8083662,"sourceType":"datasetVersion","datasetId":4771616},{"sourceId":8083668,"sourceType":"datasetVersion","datasetId":4771621},{"sourceId":8083678,"sourceType":"datasetVersion","datasetId":4771629},{"sourceId":8084913,"sourceType":"datasetVersion","datasetId":4772442}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the SNLI test data (including true labels)\nsnli_test_path = \"/kaggle/input/stanford-natural-language-inference-corpus/snli_1.0_test.csv\"\nsnli_test_df = pd.read_csv(snli_test_path)\n\n# Define file paths for SNLI prediction files\nsnli_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_snli_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_snli_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_snli_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_snli = \"/kaggle/working/combined_snli_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_snli_df = pd.DataFrame(columns=columns)\n\nlabel_mapping = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n\n# Load and merge the predictions\nfor model, path in snli_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_snli_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_snli_df['True_Label'] = snli_test_df['gold_label'].map(label_mapping)\n\n# Convert True_Label to integer type\ncombined_snli_df['True_Label'] = combined_snli_df['True_Label'].astype('Int64')\n\n# Save the combined DataFrame to CSV\ncombined_snli_df.to_csv(output_csv_path_snli, index=False)\n\nprint(f\"Combined SNLI predictions with true labels saved to {output_csv_path_snli}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T09:34:33.378818Z","iopub.execute_input":"2024-04-17T09:34:33.379162Z","iopub.status.idle":"2024-04-17T09:34:34.809473Z","shell.execute_reply.started":"2024-04-17T09:34:33.379134Z","shell.execute_reply":"2024-04-17T09:34:34.808504Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Combined SNLI predictions with true labels saved to /kaggle/working/combined_snli_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:34.811220Z","iopub.execute_input":"2024-04-17T09:34:34.811518Z","iopub.status.idle":"2024-04-17T09:34:34.833654Z","shell.execute_reply.started":"2024-04-17T09:34:34.811471Z","shell.execute_reply":"2024-04-17T09:34:34.832867Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.034767         0.962592               0.002641   \n1            0.001921         0.319032               0.679047   \n2            0.998783         0.000764               0.000453   \n3            0.001001         0.997708               0.001291   \n4            0.001080         0.301363               0.697557   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.012451         0.927093               0.060457   \n1            0.752766         0.242251               0.004983   \n2            0.000254         0.004494               0.995253   \n3            0.005844         0.990736               0.003419   \n4            0.278348         0.718575               0.003076   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.008653        0.947434              0.043913           1  \n1           0.740332        0.256434              0.003235           0  \n2           0.004677        0.060481              0.934843           2  \n3           0.034056        0.956687              0.009257           1  \n4           0.498761        0.499270              0.001969           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_matched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_matched.csv\"\nmnli_matched_test_df = pd.read_csv(mnli_matched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_matched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_matched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_matched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_matched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_matched = \"/kaggle/working/combined_mnli_matched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_matched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_matched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_matched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_matched_df['True_Label'] = mnli_matched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_matched_df.to_csv(output_csv_path_mnli_matched, index=False)\n\nprint(f\"Combined MNLI-matched predictions with true labels saved to {output_csv_path_mnli_matched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:34.834814Z","iopub.execute_input":"2024-04-17T09:34:34.835116Z","iopub.status.idle":"2024-04-17T09:34:35.135997Z","shell.execute_reply.started":"2024-04-17T09:34:34.835089Z","shell.execute_reply":"2024-04-17T09:34:35.134954Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Combined MNLI-matched predictions with true labels saved to /kaggle/working/combined_mnli_matched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_matched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.138564Z","iopub.execute_input":"2024-04-17T09:34:35.138983Z","iopub.status.idle":"2024-04-17T09:34:35.153413Z","shell.execute_reply.started":"2024-04-17T09:34:35.138951Z","shell.execute_reply":"2024-04-17T09:34:35.152436Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005164         0.993364               0.001472   \n1            0.999153         0.000526               0.000321   \n2            0.000989         0.044792               0.954219   \n3            0.994965         0.004808               0.000228   \n4            0.999657         0.000220               0.000123   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.017844         0.950246               0.031909   \n1            0.001413         0.002030               0.996557   \n2            0.954781         0.042249               0.002970   \n3            0.000343         0.003511               0.996146   \n4            0.000079         0.000496               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.010844        0.983012              0.006144           1  \n1           0.005388        0.007536              0.987076           2  \n2           0.853862        0.143483              0.002655           0  \n3           0.004128        0.070757              0.925115           2  \n4           0.003864        0.029262              0.966875           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005164</td>\n      <td>0.993364</td>\n      <td>0.001472</td>\n      <td>0.017844</td>\n      <td>0.950246</td>\n      <td>0.031909</td>\n      <td>0.010844</td>\n      <td>0.983012</td>\n      <td>0.006144</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.999153</td>\n      <td>0.000526</td>\n      <td>0.000321</td>\n      <td>0.001413</td>\n      <td>0.002030</td>\n      <td>0.996557</td>\n      <td>0.005388</td>\n      <td>0.007536</td>\n      <td>0.987076</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000989</td>\n      <td>0.044792</td>\n      <td>0.954219</td>\n      <td>0.954781</td>\n      <td>0.042249</td>\n      <td>0.002970</td>\n      <td>0.853862</td>\n      <td>0.143483</td>\n      <td>0.002655</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.994965</td>\n      <td>0.004808</td>\n      <td>0.000228</td>\n      <td>0.000343</td>\n      <td>0.003511</td>\n      <td>0.996146</td>\n      <td>0.004128</td>\n      <td>0.070757</td>\n      <td>0.925115</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999657</td>\n      <td>0.000220</td>\n      <td>0.000123</td>\n      <td>0.000079</td>\n      <td>0.000496</td>\n      <td>0.999425</td>\n      <td>0.003864</td>\n      <td>0.029262</td>\n      <td>0.966875</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_mismatched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_mismatched.csv\"\nmnli_mismatched_test_df = pd.read_csv(mnli_mismatched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_mismatched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_mismatched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_mismatched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_mismatched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_mismatched = \"/kaggle/working/combined_mnli_mismatched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_mismatched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_mismatched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_mismatched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_mismatched_df['True_Label'] = mnli_mismatched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_mismatched_df.to_csv(output_csv_path_mnli_mismatched, index=False)\n\nprint(f\"Combined MNLI-mismatched predictions with true labels saved to {output_csv_path_mnli_mismatched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.154461Z","iopub.execute_input":"2024-04-17T09:34:35.154789Z","iopub.status.idle":"2024-04-17T09:34:35.458308Z","shell.execute_reply.started":"2024-04-17T09:34:35.154760Z","shell.execute_reply":"2024-04-17T09:34:35.457374Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Combined MNLI-mismatched predictions with true labels saved to /kaggle/working/combined_mnli_mismatched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_mismatched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.459667Z","iopub.execute_input":"2024-04-17T09:34:35.460257Z","iopub.status.idle":"2024-04-17T09:34:35.475049Z","shell.execute_reply.started":"2024-04-17T09:34:35.460223Z","shell.execute_reply":"2024-04-17T09:34:35.474113Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.999667         0.000160               0.000173   \n1            0.998119         0.000962               0.000919   \n2            0.000552         0.004809               0.994639   \n3            0.827653         0.171961               0.000386   \n4            0.000292         0.002875               0.996833   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.000068         0.000402               0.999529   \n1            0.000183         0.001511               0.998306   \n2            0.986062         0.012020               0.001918   \n3            0.000478         0.270953               0.728569   \n4            0.975167         0.021904               0.002929   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.000894        0.003787              0.995318           2  \n1           0.006421        0.010224              0.983355           2  \n2           0.975041        0.023354              0.001605           0  \n3           0.001722        0.796122              0.202156           2  \n4           0.965952        0.032748              0.001300           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.999667</td>\n      <td>0.000160</td>\n      <td>0.000173</td>\n      <td>0.000068</td>\n      <td>0.000402</td>\n      <td>0.999529</td>\n      <td>0.000894</td>\n      <td>0.003787</td>\n      <td>0.995318</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.998119</td>\n      <td>0.000962</td>\n      <td>0.000919</td>\n      <td>0.000183</td>\n      <td>0.001511</td>\n      <td>0.998306</td>\n      <td>0.006421</td>\n      <td>0.010224</td>\n      <td>0.983355</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000552</td>\n      <td>0.004809</td>\n      <td>0.994639</td>\n      <td>0.986062</td>\n      <td>0.012020</td>\n      <td>0.001918</td>\n      <td>0.975041</td>\n      <td>0.023354</td>\n      <td>0.001605</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.827653</td>\n      <td>0.171961</td>\n      <td>0.000386</td>\n      <td>0.000478</td>\n      <td>0.270953</td>\n      <td>0.728569</td>\n      <td>0.001722</td>\n      <td>0.796122</td>\n      <td>0.202156</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000292</td>\n      <td>0.002875</td>\n      <td>0.996833</td>\n      <td>0.975167</td>\n      <td>0.021904</td>\n      <td>0.002929</td>\n      <td>0.965952</td>\n      <td>0.032748</td>\n      <td>0.001300</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nanli_r1_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r1.csv\"\nanli_r1_test_df = pd.read_csv(anli_r1_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nanli_r1_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r1_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r1_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r1_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r1 = \"/kaggle/working/combined_anli_r1_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r1_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r1_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r1_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r1_df['True_Label'] = anli_r1_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r1_df.to_csv(output_csv_path_anli_r1, index=False)\n\nprint(f\"Combined ANLI Round 1 predictions with true labels saved to {output_csv_path_anli_r1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.476184Z","iopub.execute_input":"2024-04-17T09:34:35.476462Z","iopub.status.idle":"2024-04-17T09:34:35.596228Z","shell.execute_reply.started":"2024-04-17T09:34:35.476439Z","shell.execute_reply":"2024-04-17T09:34:35.595233Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Combined ANLI Round 1 predictions with true labels saved to /kaggle/working/combined_anli_r1_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r1_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.597340Z","iopub.execute_input":"2024-04-17T09:34:35.597617Z","iopub.status.idle":"2024-04-17T09:34:35.614764Z","shell.execute_reply.started":"2024-04-17T09:34:35.597594Z","shell.execute_reply":"2024-04-17T09:34:35.613808Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.015388         0.976305               0.008307   \n1            0.224603         0.501549               0.273848   \n2            0.006642         0.976690               0.016669   \n3            0.966494         0.032235               0.001272   \n4            0.880736         0.028293               0.090971   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.996714         0.000376               0.002910   \n1            0.875720         0.000724               0.123556   \n2            0.999484         0.000330               0.000186   \n3            0.000686         0.998181               0.001133   \n4            0.000378         0.000197               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.322974        0.667628              0.009398           0  \n1           0.998526        0.000604              0.000869           0  \n2           0.783352        0.212241              0.004407           0  \n3           0.002134        0.989523              0.008343           1  \n4           0.023283        0.013253              0.963464           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015388</td>\n      <td>0.976305</td>\n      <td>0.008307</td>\n      <td>0.996714</td>\n      <td>0.000376</td>\n      <td>0.002910</td>\n      <td>0.322974</td>\n      <td>0.667628</td>\n      <td>0.009398</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.224603</td>\n      <td>0.501549</td>\n      <td>0.273848</td>\n      <td>0.875720</td>\n      <td>0.000724</td>\n      <td>0.123556</td>\n      <td>0.998526</td>\n      <td>0.000604</td>\n      <td>0.000869</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.006642</td>\n      <td>0.976690</td>\n      <td>0.016669</td>\n      <td>0.999484</td>\n      <td>0.000330</td>\n      <td>0.000186</td>\n      <td>0.783352</td>\n      <td>0.212241</td>\n      <td>0.004407</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.966494</td>\n      <td>0.032235</td>\n      <td>0.001272</td>\n      <td>0.000686</td>\n      <td>0.998181</td>\n      <td>0.001133</td>\n      <td>0.002134</td>\n      <td>0.989523</td>\n      <td>0.008343</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.880736</td>\n      <td>0.028293</td>\n      <td>0.090971</td>\n      <td>0.000378</td>\n      <td>0.000197</td>\n      <td>0.999425</td>\n      <td>0.023283</td>\n      <td>0.013253</td>\n      <td>0.963464</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 2 test data (including true labels)\nanli_r2_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r2.csv\"\nanli_r2_test_df = pd.read_csv(anli_r2_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r2_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r2_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r2_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r2_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r2 = \"/kaggle/working/combined_anli_r2_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r2_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r2_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r2_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r2_df['True_Label'] = anli_r2_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r2_df.to_csv(output_csv_path_anli_r2, index=False)\n\nprint(f\"Combined ANLI Round 2 predictions with true labels saved to {output_csv_path_anli_r2}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.615787Z","iopub.execute_input":"2024-04-17T09:34:35.616019Z","iopub.status.idle":"2024-04-17T09:34:35.717619Z","shell.execute_reply.started":"2024-04-17T09:34:35.615998Z","shell.execute_reply":"2024-04-17T09:34:35.716728Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Combined ANLI Round 2 predictions with true labels saved to /kaggle/working/combined_anli_r2_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r2_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.721035Z","iopub.execute_input":"2024-04-17T09:34:35.721338Z","iopub.status.idle":"2024-04-17T09:34:35.735582Z","shell.execute_reply.started":"2024-04-17T09:34:35.721314Z","shell.execute_reply":"2024-04-17T09:34:35.734680Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.001309         0.029617               0.969075   \n1            0.724144         0.273676               0.002180   \n2            0.071604         0.917894               0.010503   \n3            0.066162         0.929179               0.004659   \n4            0.906199         0.089873               0.003928   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.999506         0.000264               0.000230   \n1            0.026951         0.054230               0.918819   \n2            0.001282         0.998108               0.000610   \n3            0.007091         0.992694               0.000215   \n4            0.006259         0.989432               0.004309   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.863365        0.133388              0.003246           0  \n1           0.072900        0.904344              0.022756           1  \n2           0.027402        0.972218              0.000380           0  \n3           0.632171        0.365194              0.002635           1  \n4           0.064109        0.234642              0.701249           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001309</td>\n      <td>0.029617</td>\n      <td>0.969075</td>\n      <td>0.999506</td>\n      <td>0.000264</td>\n      <td>0.000230</td>\n      <td>0.863365</td>\n      <td>0.133388</td>\n      <td>0.003246</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.724144</td>\n      <td>0.273676</td>\n      <td>0.002180</td>\n      <td>0.026951</td>\n      <td>0.054230</td>\n      <td>0.918819</td>\n      <td>0.072900</td>\n      <td>0.904344</td>\n      <td>0.022756</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.071604</td>\n      <td>0.917894</td>\n      <td>0.010503</td>\n      <td>0.001282</td>\n      <td>0.998108</td>\n      <td>0.000610</td>\n      <td>0.027402</td>\n      <td>0.972218</td>\n      <td>0.000380</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.066162</td>\n      <td>0.929179</td>\n      <td>0.004659</td>\n      <td>0.007091</td>\n      <td>0.992694</td>\n      <td>0.000215</td>\n      <td>0.632171</td>\n      <td>0.365194</td>\n      <td>0.002635</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.906199</td>\n      <td>0.089873</td>\n      <td>0.003928</td>\n      <td>0.006259</td>\n      <td>0.989432</td>\n      <td>0.004309</td>\n      <td>0.064109</td>\n      <td>0.234642</td>\n      <td>0.701249</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 3 test data (including true labels)\nanli_r3_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r3.csv\"\nanli_r3_test_df = pd.read_csv(anli_r3_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r3_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r3_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r3_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r3_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r3 = \"/kaggle/working/combined_anli_r3_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r3_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r3_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r3_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r3_df['True_Label'] = anli_r3_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r3_df.to_csv(output_csv_path_anli_r3, index=False)\n\nprint(f\"Combined ANLI Round 3 predictions with true labels saved to {output_csv_path_anli_r3}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.737040Z","iopub.execute_input":"2024-04-17T09:34:35.737413Z","iopub.status.idle":"2024-04-17T09:34:35.877284Z","shell.execute_reply.started":"2024-04-17T09:34:35.737384Z","shell.execute_reply":"2024-04-17T09:34:35.876329Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Combined ANLI Round 3 predictions with true labels saved to /kaggle/working/combined_anli_r3_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r3_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.878542Z","iopub.execute_input":"2024-04-17T09:34:35.879173Z","iopub.status.idle":"2024-04-17T09:34:35.893915Z","shell.execute_reply.started":"2024-04-17T09:34:35.879137Z","shell.execute_reply":"2024-04-17T09:34:35.893003Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005921         0.960529               0.033551   \n1            0.009586         0.934714               0.055700   \n2            0.003428         0.976393               0.020179   \n3            0.004633         0.023985               0.971382   \n4            0.017428         0.633695               0.348877   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.022959         0.976533               0.000509   \n1            0.999611         0.000205               0.000185   \n2            0.002020         0.997897               0.000083   \n3            0.974441         0.024459               0.001100   \n4            0.984416         0.011166               0.004419   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.001848        0.998084              0.000067           0  \n1           0.951772        0.048075              0.000153           0  \n2           0.001014        0.998984              0.000002           0  \n3           0.996749        0.000989              0.002262           0  \n4           0.000518        0.128416              0.871066           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005921</td>\n      <td>0.960529</td>\n      <td>0.033551</td>\n      <td>0.022959</td>\n      <td>0.976533</td>\n      <td>0.000509</td>\n      <td>0.001848</td>\n      <td>0.998084</td>\n      <td>0.000067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009586</td>\n      <td>0.934714</td>\n      <td>0.055700</td>\n      <td>0.999611</td>\n      <td>0.000205</td>\n      <td>0.000185</td>\n      <td>0.951772</td>\n      <td>0.048075</td>\n      <td>0.000153</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003428</td>\n      <td>0.976393</td>\n      <td>0.020179</td>\n      <td>0.002020</td>\n      <td>0.997897</td>\n      <td>0.000083</td>\n      <td>0.001014</td>\n      <td>0.998984</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004633</td>\n      <td>0.023985</td>\n      <td>0.971382</td>\n      <td>0.974441</td>\n      <td>0.024459</td>\n      <td>0.001100</td>\n      <td>0.996749</td>\n      <td>0.000989</td>\n      <td>0.002262</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017428</td>\n      <td>0.633695</td>\n      <td>0.348877</td>\n      <td>0.984416</td>\n      <td>0.011166</td>\n      <td>0.004419</td>\n      <td>0.000518</td>\n      <td>0.128416</td>\n      <td>0.871066</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values\nmissing_values_anli1 = combined_anli_r1_df.isnull().sum()\n\nmissing_values_anli2 = combined_anli_r2_df.isnull().sum()\n\nmissing_values_anli3 = combined_anli_r3_df.isnull().sum()\n\nmissing_values_snli = combined_snli_df.isnull().sum()\n\nmissing_values_mnli_matched = combined_mnli_matched_df.isnull().sum()\n\nmissing_values_mnli_mismatched = combined_mnli_mismatched_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.895065Z","iopub.execute_input":"2024-04-17T09:34:35.895347Z","iopub.status.idle":"2024-04-17T09:34:35.907253Z","shell.execute_reply.started":"2024-04-17T09:34:35.895323Z","shell.execute_reply":"2024-04-17T09:34:35.906395Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"missing_values_anli1","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.908347Z","iopub.execute_input":"2024-04-17T09:34:35.908712Z","iopub.status.idle":"2024-04-17T09:34:35.918306Z","shell.execute_reply.started":"2024-04-17T09:34:35.908678Z","shell.execute_reply":"2024-04-17T09:34:35.917457Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli2","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.919325Z","iopub.execute_input":"2024-04-17T09:34:35.919647Z","iopub.status.idle":"2024-04-17T09:34:35.928213Z","shell.execute_reply.started":"2024-04-17T09:34:35.919618Z","shell.execute_reply":"2024-04-17T09:34:35.927408Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli3","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.929282Z","iopub.execute_input":"2024-04-17T09:34:35.929637Z","iopub.status.idle":"2024-04-17T09:34:35.937707Z","shell.execute_reply.started":"2024-04-17T09:34:35.929615Z","shell.execute_reply":"2024-04-17T09:34:35.936893Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_snli","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.938837Z","iopub.execute_input":"2024-04-17T09:34:35.939174Z","iopub.status.idle":"2024-04-17T09:34:35.947365Z","shell.execute_reply.started":"2024-04-17T09:34:35.939153Z","shell.execute_reply":"2024-04-17T09:34:35.946535Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment         0\nDeberta_Neutral            0\nDeberta_Contradiction      0\nRoberta_Entailment         0\nRoberta_Neutral            0\nRoberta_Contradiction      0\nAlbert_Entailment          0\nAlbert_Neutral             0\nAlbert_Contradiction       0\nTrue_Label               176\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_matched","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.948572Z","iopub.execute_input":"2024-04-17T09:34:35.948888Z","iopub.status.idle":"2024-04-17T09:34:35.958106Z","shell.execute_reply.started":"2024-04-17T09:34:35.948856Z","shell.execute_reply":"2024-04-17T09:34:35.957281Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_mismatched","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.959099Z","iopub.execute_input":"2024-04-17T09:34:35.959362Z","iopub.status.idle":"2024-04-17T09:34:35.967957Z","shell.execute_reply.started":"2024-04-17T09:34:35.959335Z","shell.execute_reply":"2024-04-17T09:34:35.967134Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"combined_snli_df.dropna(subset=['True_Label'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.969007Z","iopub.execute_input":"2024-04-17T09:34:35.969297Z","iopub.status.idle":"2024-04-17T09:34:35.980335Z","shell.execute_reply.started":"2024-04-17T09:34:35.969270Z","shell.execute_reply":"2024-04-17T09:34:35.979586Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Verify missing values again after removal\nmissing_values_snli_after_removal = combined_snli_df.isnull().sum()\nprint(missing_values_snli_after_removal)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.981372Z","iopub.execute_input":"2024-04-17T09:34:35.981679Z","iopub.status.idle":"2024-04-17T09:34:35.988428Z","shell.execute_reply.started":"2024-04-17T09:34:35.981638Z","shell.execute_reply":"2024-04-17T09:34:35.987531Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:35.989890Z","iopub.execute_input":"2024-04-17T09:34:35.990179Z","iopub.status.idle":"2024-04-17T09:34:36.009388Z","shell.execute_reply.started":"2024-04-17T09:34:35.990155Z","shell.execute_reply":"2024-04-17T09:34:36.008505Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 9824 entries, 0 to 9999\nData columns (total 10 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   Deberta_Entailment     9824 non-null   float64\n 1   Deberta_Neutral        9824 non-null   float64\n 2   Deberta_Contradiction  9824 non-null   float64\n 3   Roberta_Entailment     9824 non-null   float64\n 4   Roberta_Neutral        9824 non-null   float64\n 5   Roberta_Contradiction  9824 non-null   float64\n 6   Albert_Entailment      9824 non-null   float64\n 7   Albert_Neutral         9824 non-null   float64\n 8   Albert_Contradiction   9824 non-null   float64\n 9   True_Label             9824 non-null   Int64  \ndtypes: Int64(1), float64(9)\nmemory usage: 853.8 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:36.010431Z","iopub.execute_input":"2024-04-17T09:34:36.011723Z","iopub.status.idle":"2024-04-17T09:34:36.028968Z","shell.execute_reply.started":"2024-04-17T09:34:36.011699Z","shell.execute_reply":"2024-04-17T09:34:36.028127Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0               0.034767         0.962592               0.002641   \n1               0.001921         0.319032               0.679047   \n2               0.998783         0.000764               0.000453   \n3               0.001001         0.997708               0.001291   \n4               0.001080         0.301363               0.697557   \n...                  ...              ...                    ...   \n9995            0.998825         0.001033               0.000142   \n9996            0.000704         0.009793               0.989503   \n9997            0.999171         0.000493               0.000336   \n9998            0.000267         0.002178               0.997556   \n9999            0.003641         0.995224               0.001135   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0               0.012451         0.927093               0.060457   \n1               0.752766         0.242251               0.004983   \n2               0.000254         0.004494               0.995253   \n3               0.005844         0.990736               0.003419   \n4               0.278348         0.718575               0.003076   \n...                  ...              ...                    ...   \n9995            0.001264         0.028942               0.969794   \n9996            0.780946         0.217053               0.002001   \n9997            0.000054         0.000765               0.999181   \n9998            0.983402         0.015884               0.000714   \n9999            0.000904         0.995495               0.003601   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0              0.008653        0.947434              0.043913           1  \n1              0.740332        0.256434              0.003235           0  \n2              0.004677        0.060481              0.934843           2  \n3              0.034056        0.956687              0.009257           1  \n4              0.498761        0.499270              0.001969           0  \n...                 ...             ...                   ...         ...  \n9995           0.006420        0.057240              0.936340           2  \n9996           0.894637        0.104095              0.001267           0  \n9997           0.000838        0.002670              0.996493           2  \n9998           0.984347        0.015223              0.000430           0  \n9999           0.005047        0.990218              0.004735           1  \n\n[9824 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>0.998825</td>\n      <td>0.001033</td>\n      <td>0.000142</td>\n      <td>0.001264</td>\n      <td>0.028942</td>\n      <td>0.969794</td>\n      <td>0.006420</td>\n      <td>0.057240</td>\n      <td>0.936340</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>0.000704</td>\n      <td>0.009793</td>\n      <td>0.989503</td>\n      <td>0.780946</td>\n      <td>0.217053</td>\n      <td>0.002001</td>\n      <td>0.894637</td>\n      <td>0.104095</td>\n      <td>0.001267</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>0.999171</td>\n      <td>0.000493</td>\n      <td>0.000336</td>\n      <td>0.000054</td>\n      <td>0.000765</td>\n      <td>0.999181</td>\n      <td>0.000838</td>\n      <td>0.002670</td>\n      <td>0.996493</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>0.000267</td>\n      <td>0.002178</td>\n      <td>0.997556</td>\n      <td>0.983402</td>\n      <td>0.015884</td>\n      <td>0.000714</td>\n      <td>0.984347</td>\n      <td>0.015223</td>\n      <td>0.000430</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>0.003641</td>\n      <td>0.995224</td>\n      <td>0.001135</td>\n      <td>0.000904</td>\n      <td>0.995495</td>\n      <td>0.003601</td>\n      <td>0.005047</td>\n      <td>0.990218</td>\n      <td>0.004735</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9824 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef calculate_margin(row):\n    # Assuming the row only contains the probabilities\n    sorted_probs = np.sort(row)  # Sort probabilities in ascending order\n    if len(sorted_probs) > 1:\n        return sorted_probs[-1] - sorted_probs[-2]  # Difference between the highest and second highest\n    else:\n        return 0  # This handles the edge case where there is only one probability value\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:36.030161Z","iopub.execute_input":"2024-04-17T09:34:36.030499Z","iopub.status.idle":"2024-04-17T09:34:36.036633Z","shell.execute_reply.started":"2024-04-17T09:34:36.030456Z","shell.execute_reply":"2024-04-17T09:34:36.035740Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Applying to a sample DataFrame with made-up column names\ncombined_snli_df['confidence_margin_entailment'] = combined_snli_df[['Deberta_Entailment', 'Roberta_Entailment', 'Albert_Entailment']].apply(calculate_margin, axis=1)\ncombined_snli_df['confidence_margin_neutral'] = combined_snli_df[['Deberta_Neutral', 'Roberta_Neutral', 'Albert_Neutral']].apply(calculate_margin, axis=1)\ncombined_snli_df['confidence_margin_contradiction'] = combined_snli_df[['Deberta_Contradiction', 'Roberta_Contradiction', 'Albert_Contradiction']].apply(calculate_margin, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:36.037639Z","iopub.execute_input":"2024-04-17T09:34:36.037871Z","iopub.status.idle":"2024-04-17T09:34:36.885082Z","shell.execute_reply.started":"2024-04-17T09:34:36.037851Z","shell.execute_reply":"2024-04-17T09:34:36.884054Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"combined_snli_df","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:36.886316Z","iopub.execute_input":"2024-04-17T09:34:36.886971Z","iopub.status.idle":"2024-04-17T09:34:36.909260Z","shell.execute_reply.started":"2024-04-17T09:34:36.886937Z","shell.execute_reply":"2024-04-17T09:34:36.908312Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0               0.034767         0.962592               0.002641   \n1               0.001921         0.319032               0.679047   \n2               0.998783         0.000764               0.000453   \n3               0.001001         0.997708               0.001291   \n4               0.001080         0.301363               0.697557   \n...                  ...              ...                    ...   \n9995            0.998825         0.001033               0.000142   \n9996            0.000704         0.009793               0.989503   \n9997            0.999171         0.000493               0.000336   \n9998            0.000267         0.002178               0.997556   \n9999            0.003641         0.995224               0.001135   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0               0.012451         0.927093               0.060457   \n1               0.752766         0.242251               0.004983   \n2               0.000254         0.004494               0.995253   \n3               0.005844         0.990736               0.003419   \n4               0.278348         0.718575               0.003076   \n...                  ...              ...                    ...   \n9995            0.001264         0.028942               0.969794   \n9996            0.780946         0.217053               0.002001   \n9997            0.000054         0.000765               0.999181   \n9998            0.983402         0.015884               0.000714   \n9999            0.000904         0.995495               0.003601   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \\\n0              0.008653        0.947434              0.043913           1   \n1              0.740332        0.256434              0.003235           0   \n2              0.004677        0.060481              0.934843           2   \n3              0.034056        0.956687              0.009257           1   \n4              0.498761        0.499270              0.001969           0   \n...                 ...             ...                   ...         ...   \n9995           0.006420        0.057240              0.936340           2   \n9996           0.894637        0.104095              0.001267           0   \n9997           0.000838        0.002670              0.996493           2   \n9998           0.984347        0.015223              0.000430           0   \n9999           0.005047        0.990218              0.004735           1   \n\n      confidence_margin_entailment  confidence_margin_neutral  \\\n0                         0.022316                   0.015158   \n1                         0.012435                   0.062598   \n2                         0.994106                   0.055987   \n3                         0.028212                   0.006972   \n4                         0.220412                   0.219305   \n...                            ...                        ...   \n9995                      0.992405                   0.028298   \n9996                      0.113691                   0.112958   \n9997                      0.998334                   0.001905   \n9998                      0.000945                   0.000661   \n9999                      0.001406                   0.000271   \n\n      confidence_margin_contradiction  \n0                            0.016543  \n1                            0.674064  \n2                            0.060410  \n3                            0.005837  \n4                            0.694481  \n...                               ...  \n9995                         0.033454  \n9996                         0.987502  \n9997                         0.002688  \n9998                         0.996842  \n9999                         0.001134  \n\n[9824 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n      <th>confidence_margin_entailment</th>\n      <th>confidence_margin_neutral</th>\n      <th>confidence_margin_contradiction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n      <td>0.022316</td>\n      <td>0.015158</td>\n      <td>0.016543</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n      <td>0.012435</td>\n      <td>0.062598</td>\n      <td>0.674064</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n      <td>0.994106</td>\n      <td>0.055987</td>\n      <td>0.060410</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n      <td>0.028212</td>\n      <td>0.006972</td>\n      <td>0.005837</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n      <td>0.220412</td>\n      <td>0.219305</td>\n      <td>0.694481</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>0.998825</td>\n      <td>0.001033</td>\n      <td>0.000142</td>\n      <td>0.001264</td>\n      <td>0.028942</td>\n      <td>0.969794</td>\n      <td>0.006420</td>\n      <td>0.057240</td>\n      <td>0.936340</td>\n      <td>2</td>\n      <td>0.992405</td>\n      <td>0.028298</td>\n      <td>0.033454</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>0.000704</td>\n      <td>0.009793</td>\n      <td>0.989503</td>\n      <td>0.780946</td>\n      <td>0.217053</td>\n      <td>0.002001</td>\n      <td>0.894637</td>\n      <td>0.104095</td>\n      <td>0.001267</td>\n      <td>0</td>\n      <td>0.113691</td>\n      <td>0.112958</td>\n      <td>0.987502</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>0.999171</td>\n      <td>0.000493</td>\n      <td>0.000336</td>\n      <td>0.000054</td>\n      <td>0.000765</td>\n      <td>0.999181</td>\n      <td>0.000838</td>\n      <td>0.002670</td>\n      <td>0.996493</td>\n      <td>2</td>\n      <td>0.998334</td>\n      <td>0.001905</td>\n      <td>0.002688</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>0.000267</td>\n      <td>0.002178</td>\n      <td>0.997556</td>\n      <td>0.983402</td>\n      <td>0.015884</td>\n      <td>0.000714</td>\n      <td>0.984347</td>\n      <td>0.015223</td>\n      <td>0.000430</td>\n      <td>0</td>\n      <td>0.000945</td>\n      <td>0.000661</td>\n      <td>0.996842</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>0.003641</td>\n      <td>0.995224</td>\n      <td>0.001135</td>\n      <td>0.000904</td>\n      <td>0.995495</td>\n      <td>0.003601</td>\n      <td>0.005047</td>\n      <td>0.990218</td>\n      <td>0.004735</td>\n      <td>1</td>\n      <td>0.001406</td>\n      <td>0.000271</td>\n      <td>0.001134</td>\n    </tr>\n  </tbody>\n</table>\n<p>9824 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef add_prediction_flags(df):\n    # Assuming model prediction columns and a 'True_Label' column exist\n    for model in ['Deberta', 'Roberta', 'Albert']:\n        # Calculate the predicted class by finding the argmax across each set of prediction columns for the model\n        entailment_col = f\"{model}_Entailment\"\n        neutral_col = f\"{model}_Neutral\"\n        contradiction_col = f\"{model}_Contradiction\"\n        \n        # Create a DataFrame slice of the relevant columns\n        model_preds = df[[entailment_col, neutral_col, contradiction_col]]\n        \n        # Argmax will give us 0 for entailment, 1 for neutral, 2 for contradiction based on column order\n        df[f\"{model}_Predicted\"] = np.argmax(model_preds.values, axis=1)\n        \n        # Generate binary flags (1 if prediction is correct, 0 if incorrect)\n        df[f\"{model}_Correct\"] = (df[f\"{model}_Predicted\"] == df['True_Label']).astype(int)\n\n# Apply the function to your combined DataFrame\nadd_prediction_flags(combined_snli_df)\n\n# You can apply this function to other combined DataFrames similarly\nadd_prediction_flags(combined_mnli_matched_df)\nadd_prediction_flags(combined_mnli_mismatched_df)\nadd_prediction_flags(combined_anli_r1_df)\nadd_prediction_flags(combined_anli_r2_df)\nadd_prediction_flags(combined_anli_r3_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:36.910476Z","iopub.execute_input":"2024-04-17T09:34:36.911227Z","iopub.status.idle":"2024-04-17T09:34:36.948550Z","shell.execute_reply.started":"2024-04-17T09:34:36.911194Z","shell.execute_reply":"2024-04-17T09:34:36.947848Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"combined_snli_df","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:36.953421Z","iopub.execute_input":"2024-04-17T09:34:36.953725Z","iopub.status.idle":"2024-04-17T09:34:36.977907Z","shell.execute_reply.started":"2024-04-17T09:34:36.953703Z","shell.execute_reply":"2024-04-17T09:34:36.977057Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0               0.034767         0.962592               0.002641   \n1               0.001921         0.319032               0.679047   \n2               0.998783         0.000764               0.000453   \n3               0.001001         0.997708               0.001291   \n4               0.001080         0.301363               0.697557   \n...                  ...              ...                    ...   \n9995            0.998825         0.001033               0.000142   \n9996            0.000704         0.009793               0.989503   \n9997            0.999171         0.000493               0.000336   \n9998            0.000267         0.002178               0.997556   \n9999            0.003641         0.995224               0.001135   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0               0.012451         0.927093               0.060457   \n1               0.752766         0.242251               0.004983   \n2               0.000254         0.004494               0.995253   \n3               0.005844         0.990736               0.003419   \n4               0.278348         0.718575               0.003076   \n...                  ...              ...                    ...   \n9995            0.001264         0.028942               0.969794   \n9996            0.780946         0.217053               0.002001   \n9997            0.000054         0.000765               0.999181   \n9998            0.983402         0.015884               0.000714   \n9999            0.000904         0.995495               0.003601   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \\\n0              0.008653        0.947434              0.043913           1   \n1              0.740332        0.256434              0.003235           0   \n2              0.004677        0.060481              0.934843           2   \n3              0.034056        0.956687              0.009257           1   \n4              0.498761        0.499270              0.001969           0   \n...                 ...             ...                   ...         ...   \n9995           0.006420        0.057240              0.936340           2   \n9996           0.894637        0.104095              0.001267           0   \n9997           0.000838        0.002670              0.996493           2   \n9998           0.984347        0.015223              0.000430           0   \n9999           0.005047        0.990218              0.004735           1   \n\n      confidence_margin_entailment  confidence_margin_neutral  \\\n0                         0.022316                   0.015158   \n1                         0.012435                   0.062598   \n2                         0.994106                   0.055987   \n3                         0.028212                   0.006972   \n4                         0.220412                   0.219305   \n...                            ...                        ...   \n9995                      0.992405                   0.028298   \n9996                      0.113691                   0.112958   \n9997                      0.998334                   0.001905   \n9998                      0.000945                   0.000661   \n9999                      0.001406                   0.000271   \n\n      confidence_margin_contradiction  Deberta_Predicted  Deberta_Correct  \\\n0                            0.016543                  1                1   \n1                            0.674064                  2                0   \n2                            0.060410                  0                0   \n3                            0.005837                  1                1   \n4                            0.694481                  2                0   \n...                               ...                ...              ...   \n9995                         0.033454                  0                0   \n9996                         0.987502                  2                0   \n9997                         0.002688                  0                0   \n9998                         0.996842                  2                0   \n9999                         0.001134                  1                1   \n\n      Roberta_Predicted  Roberta_Correct  Albert_Predicted  Albert_Correct  \n0                     1                1                 1               1  \n1                     0                1                 0               1  \n2                     2                1                 2               1  \n3                     1                1                 1               1  \n4                     1                0                 1               0  \n...                 ...              ...               ...             ...  \n9995                  2                1                 2               1  \n9996                  0                1                 0               1  \n9997                  2                1                 2               1  \n9998                  0                1                 0               1  \n9999                  1                1                 1               1  \n\n[9824 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n      <th>confidence_margin_entailment</th>\n      <th>confidence_margin_neutral</th>\n      <th>confidence_margin_contradiction</th>\n      <th>Deberta_Predicted</th>\n      <th>Deberta_Correct</th>\n      <th>Roberta_Predicted</th>\n      <th>Roberta_Correct</th>\n      <th>Albert_Predicted</th>\n      <th>Albert_Correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n      <td>0.022316</td>\n      <td>0.015158</td>\n      <td>0.016543</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n      <td>0.012435</td>\n      <td>0.062598</td>\n      <td>0.674064</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n      <td>0.994106</td>\n      <td>0.055987</td>\n      <td>0.060410</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n      <td>0.028212</td>\n      <td>0.006972</td>\n      <td>0.005837</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n      <td>0.220412</td>\n      <td>0.219305</td>\n      <td>0.694481</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>0.998825</td>\n      <td>0.001033</td>\n      <td>0.000142</td>\n      <td>0.001264</td>\n      <td>0.028942</td>\n      <td>0.969794</td>\n      <td>0.006420</td>\n      <td>0.057240</td>\n      <td>0.936340</td>\n      <td>2</td>\n      <td>0.992405</td>\n      <td>0.028298</td>\n      <td>0.033454</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>0.000704</td>\n      <td>0.009793</td>\n      <td>0.989503</td>\n      <td>0.780946</td>\n      <td>0.217053</td>\n      <td>0.002001</td>\n      <td>0.894637</td>\n      <td>0.104095</td>\n      <td>0.001267</td>\n      <td>0</td>\n      <td>0.113691</td>\n      <td>0.112958</td>\n      <td>0.987502</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>0.999171</td>\n      <td>0.000493</td>\n      <td>0.000336</td>\n      <td>0.000054</td>\n      <td>0.000765</td>\n      <td>0.999181</td>\n      <td>0.000838</td>\n      <td>0.002670</td>\n      <td>0.996493</td>\n      <td>2</td>\n      <td>0.998334</td>\n      <td>0.001905</td>\n      <td>0.002688</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>0.000267</td>\n      <td>0.002178</td>\n      <td>0.997556</td>\n      <td>0.983402</td>\n      <td>0.015884</td>\n      <td>0.000714</td>\n      <td>0.984347</td>\n      <td>0.015223</td>\n      <td>0.000430</td>\n      <td>0</td>\n      <td>0.000945</td>\n      <td>0.000661</td>\n      <td>0.996842</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>0.003641</td>\n      <td>0.995224</td>\n      <td>0.001135</td>\n      <td>0.000904</td>\n      <td>0.995495</td>\n      <td>0.003601</td>\n      <td>0.005047</td>\n      <td>0.990218</td>\n      <td>0.004735</td>\n      <td>1</td>\n      <td>0.001406</td>\n      <td>0.000271</td>\n      <td>0.001134</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9824 rows × 19 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n# Assuming 'combined_snli_df' is already loaded as described\n\n# Features and Labels\nX_snli = combined_snli_df.drop('True_Label', axis=1).values\ny_snli = combined_snli_df['True_Label'].values\n\n# Features and Labels\nX_mnli_matched = combined_mnli_matched_df.drop('True_Label', axis=1).values\ny_mnli_matched = combined_mnli_matched_df['True_Label'].values\n\n# Features and Labels\nX_mnli_mismatched = combined_mnli_mismatched_df.drop('True_Label', axis=1).values\ny_mnli_mismatched = combined_mnli_mismatched_df['True_Label'].values\n\n# Features and Labels\nX_anli_r1 = combined_anli_r1_df.drop('True_Label', axis=1).values\ny_anli_r1 = combined_anli_r1_df['True_Label'].values\n\n# Features and Labels\nX_anli_r2 = combined_anli_r2_df.drop('True_Label', axis=1).values\ny_anli_r2 = combined_anli_r2_df['True_Label'].values\n\n# Features and Labels\nX_anli_r3 = combined_anli_r3_df.drop('True_Label', axis=1).values\ny_anli_r3 = combined_anli_r3_df['True_Label'].values\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:36.981149Z","iopub.execute_input":"2024-04-17T09:34:36.981959Z","iopub.status.idle":"2024-04-17T09:34:49.123515Z","shell.execute_reply.started":"2024-04-17T09:34:36.981920Z","shell.execute_reply":"2024-04-17T09:34:49.122535Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"2024-04-17 09:34:39.745838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-17 09:34:39.745933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-17 09:34:39.863963: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Function to scale features\ndef scale_features(X):\n    scaler = StandardScaler()\n    return scaler.fit_transform(X)\n\n# Apply feature scaling\nX_snli_scaled = scale_features(X_snli)\nX_mnli_matched_scaled = scale_features(X_mnli_matched)\nX_mnli_mismatched_scaled = scale_features(X_mnli_mismatched)\nX_anli_r1_scaled = scale_features(X_anli_r1)\nX_anli_r2_scaled = scale_features(X_anli_r2)\nX_anli_r3_scaled = scale_features(X_anli_r3)\n\n# One-hot encode labels for each dataset using TensorFlow/Keras utility\ny_encoded_snli = tf.keras.utils.to_categorical(y_snli)\ny_encoded_mnli_matched = tf.keras.utils.to_categorical(y_mnli_matched)\ny_encoded_mnli_mismatched = tf.keras.utils.to_categorical(y_mnli_mismatched)\ny_encoded_anli_r1 = tf.keras.utils.to_categorical(y_anli_r1)\ny_encoded_anli_r2 = tf.keras.utils.to_categorical(y_anli_r2)\ny_encoded_anli_r3 = tf.keras.utils.to_categorical(y_anli_r3)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:49.124664Z","iopub.execute_input":"2024-04-17T09:34:49.125180Z","iopub.status.idle":"2024-04-17T09:34:49.144139Z","shell.execute_reply.started":"2024-04-17T09:34:49.125155Z","shell.execute_reply":"2024-04-17T09:34:49.143040Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"X_snli_scaled","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:49.145403Z","iopub.execute_input":"2024-04-17T09:34:49.146157Z","iopub.status.idle":"2024-04-17T09:34:49.163438Z","shell.execute_reply.started":"2024-04-17T09:34:49.146124Z","shell.execute_reply":"2024-04-17T09:34:49.162640Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[-0.65460956,  1.48536003, -0.76075099, ...,  0.29794821,\n         0.04084633,  0.29713748],\n       [-0.72705336, -0.01460591,  0.75051539, ...,  0.29794821,\n        -1.19384399,  0.29713748],\n       [ 1.47158549, -0.75640249, -0.76564053, ...,  0.29794821,\n         1.27553666,  0.29713748],\n       ...,\n       [ 1.47244222, -0.75703522, -0.76590179, ...,  0.29794821,\n         1.27553666,  0.29713748],\n       [-0.73070171, -0.75310812,  1.46214563, ...,  0.29794821,\n        -1.19384399,  0.29713748],\n       [-0.72325989,  1.56141689, -0.76411608, ...,  0.29794821,\n         0.04084633,  0.29713748]])"},"metadata":{}}]},{"cell_type":"code","source":"X_snli_rnn = X_snli_scaled.reshape(X_snli_scaled.shape[0], 1, X_snli_scaled.shape[1])\nX_mnli_matched_rnn = X_mnli_matched_scaled.reshape(X_mnli_matched_scaled.shape[0], 1, X_mnli_matched_scaled.shape[1])\nX_mnli_mismatched_rnn = X_mnli_mismatched_scaled.reshape(X_mnli_mismatched_scaled.shape[0], 1, X_mnli_mismatched_scaled.shape[1])\nX_anli_r1_rnn = X_anli_r1_scaled.reshape(X_anli_r1_scaled.shape[0], 1, X_anli_r1_scaled.shape[1])\nX_anli_r2_rnn = X_anli_r2_scaled.reshape(X_anli_r2_scaled.shape[0], 1, X_anli_r2_scaled.shape[1])\nX_anli_r3_rnn = X_anli_r3_scaled.reshape(X_anli_r3_scaled.shape[0], 1, X_anli_r3_scaled.shape[1])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:49.164675Z","iopub.execute_input":"2024-04-17T09:34:49.164946Z","iopub.status.idle":"2024-04-17T09:34:49.173380Z","shell.execute_reply.started":"2024-04-17T09:34:49.164924Z","shell.execute_reply":"2024-04-17T09:34:49.172600Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"X_snli_rnn","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:49.174722Z","iopub.execute_input":"2024-04-17T09:34:49.175039Z","iopub.status.idle":"2024-04-17T09:34:49.185182Z","shell.execute_reply.started":"2024-04-17T09:34:49.175010Z","shell.execute_reply":"2024-04-17T09:34:49.184257Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"array([[[-0.65460956,  1.48536003, -0.76075099, ...,  0.29794821,\n          0.04084633,  0.29713748]],\n\n       [[-0.72705336, -0.01460591,  0.75051539, ...,  0.29794821,\n         -1.19384399,  0.29713748]],\n\n       [[ 1.47158549, -0.75640249, -0.76564053, ...,  0.29794821,\n          1.27553666,  0.29713748]],\n\n       ...,\n\n       [[ 1.47244222, -0.75703522, -0.76590179, ...,  0.29794821,\n          1.27553666,  0.29713748]],\n\n       [[-0.73070171, -0.75310812,  1.46214563, ...,  0.29794821,\n         -1.19384399,  0.29713748]],\n\n       [[-0.72325989,  1.56141689, -0.76411608, ...,  0.29794821,\n          0.04084633,  0.29713748]]])"},"metadata":{}}]},{"cell_type":"code","source":"X_snli_rnn.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:49.186269Z","iopub.execute_input":"2024-04-17T09:34:49.186612Z","iopub.status.idle":"2024-04-17T09:34:49.194874Z","shell.execute_reply.started":"2024-04-17T09:34:49.186587Z","shell.execute_reply":"2024-04-17T09:34:49.193991Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(9824, 1, 18)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\n\ndef create_rnn_model(input_shape, num_classes):\n    model = Sequential([\n        Input(shape=input_shape),\n        SimpleRNN(128, activation='relu', return_sequences=True),  # RNN layer\n        Dropout(0.5),\n        SimpleRNN(64, activation='relu'),  # Second RNN layer\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\ndef train_and_evaluate_kfold(X, y, name, n_splits=5):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    all_scores = []\n\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n\n        model = create_rnn_model(X_train.shape[1:], y_train.shape[1])  # Adjust input shape for RNN\n\n        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n        print(f\"Training fold for {name}...\")\n        history = model.fit(X_train, y_train, epochs=10, batch_size=32,\n                            validation_data=(X_val, y_val), callbacks=[early_stopping])\n\n        val_loss, val_accuracy = model.evaluate(X_val, y_val)\n        all_scores.append(val_accuracy)\n        print(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n\n    average_accuracy = np.mean(all_scores)\n    print(f\"Average Validation Accuracy for {name}: {average_accuracy * 100:.2f}%\")\n    return average_accuracy\n\n# Example usage:\n# X_snli_rnn and y_encoded_snli should be prepared before calling this function\naverage_accuracy_snli = train_and_evaluate_kfold(X_snli_rnn, y_encoded_snli, 'SNLI RNN Model')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:34:49.196032Z","iopub.execute_input":"2024-04-17T09:34:49.196856Z","iopub.status.idle":"2024-04-17T09:36:22.336734Z","shell.execute_reply.started":"2024-04-17T09:34:49.196827Z","shell.execute_reply":"2024-04-17T09:36:22.335889Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Training fold for SNLI RNN Model...\nEpoch 1/10\n\u001b[1m 93/246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7618 - loss: 0.6011","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713346496.127855      80 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - accuracy: 0.8471 - loss: 0.4043 - val_accuracy: 0.9735 - val_loss: 0.0825\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.1085 - val_accuracy: 0.9771 - val_loss: 0.0579\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.0747 - val_accuracy: 0.9842 - val_loss: 0.0454\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.0656 - val_accuracy: 0.9827 - val_loss: 0.0424\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0469 - val_accuracy: 0.9863 - val_loss: 0.0343\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0483 - val_accuracy: 0.9863 - val_loss: 0.0307\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0374 - val_accuracy: 0.9868 - val_loss: 0.0273\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0366 - val_accuracy: 0.9883 - val_loss: 0.0249\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0336 - val_accuracy: 0.9903 - val_loss: 0.0216\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0268 - val_accuracy: 0.9878 - val_loss: 0.0236\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9863 - loss: 0.0250\nValidation accuracy: 99.03%\nTraining fold for SNLI RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - accuracy: 0.8449 - loss: 0.4012 - val_accuracy: 0.9664 - val_loss: 0.0952\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1199 - val_accuracy: 0.9776 - val_loss: 0.0659\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.0828 - val_accuracy: 0.9832 - val_loss: 0.0512\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0647 - val_accuracy: 0.9863 - val_loss: 0.0408\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0490 - val_accuracy: 0.9898 - val_loss: 0.0349\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0436 - val_accuracy: 0.9919 - val_loss: 0.0309\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0351 - val_accuracy: 0.9913 - val_loss: 0.0253\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0349 - val_accuracy: 0.9929 - val_loss: 0.0230\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0309 - val_accuracy: 0.9934 - val_loss: 0.0208\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0260 - val_accuracy: 0.9944 - val_loss: 0.0189\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0185   \nValidation accuracy: 99.44%\nTraining fold for SNLI RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - accuracy: 0.8541 - loss: 0.3983 - val_accuracy: 0.9710 - val_loss: 0.0912\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1074 - val_accuracy: 0.9781 - val_loss: 0.0673\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9619 - loss: 0.0884 - val_accuracy: 0.9847 - val_loss: 0.0519\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0641 - val_accuracy: 0.9903 - val_loss: 0.0434\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0557 - val_accuracy: 0.9852 - val_loss: 0.0385\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0466 - val_accuracy: 0.9868 - val_loss: 0.0304\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0387 - val_accuracy: 0.9868 - val_loss: 0.0262\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0342 - val_accuracy: 0.9903 - val_loss: 0.0236\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0324 - val_accuracy: 0.9913 - val_loss: 0.0202\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0293 - val_accuracy: 0.9903 - val_loss: 0.0206\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9892 - loss: 0.0214\nValidation accuracy: 99.13%\nTraining fold for SNLI RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - accuracy: 0.8369 - loss: 0.4183 - val_accuracy: 0.9720 - val_loss: 0.0876\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1102 - val_accuracy: 0.9751 - val_loss: 0.0660\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.0828 - val_accuracy: 0.9837 - val_loss: 0.0509\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0636 - val_accuracy: 0.9858 - val_loss: 0.0399\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0558 - val_accuracy: 0.9873 - val_loss: 0.0333\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0403 - val_accuracy: 0.9883 - val_loss: 0.0283\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0437 - val_accuracy: 0.9903 - val_loss: 0.0232\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0329 - val_accuracy: 0.9929 - val_loss: 0.0202\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0314 - val_accuracy: 0.9949 - val_loss: 0.0182\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0282 - val_accuracy: 0.9934 - val_loss: 0.0170\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0145\nValidation accuracy: 99.34%\nTraining fold for SNLI RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - accuracy: 0.8229 - loss: 0.4372 - val_accuracy: 0.9684 - val_loss: 0.0926\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1155 - val_accuracy: 0.9735 - val_loss: 0.0680\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0865 - val_accuracy: 0.9852 - val_loss: 0.0526\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.0649 - val_accuracy: 0.9863 - val_loss: 0.0403\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0604 - val_accuracy: 0.9893 - val_loss: 0.0338\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0533 - val_accuracy: 0.9903 - val_loss: 0.0298\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0447 - val_accuracy: 0.9929 - val_loss: 0.0266\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0419 - val_accuracy: 0.9944 - val_loss: 0.0238\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0336 - val_accuracy: 0.9959 - val_loss: 0.0219\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0298 - val_accuracy: 0.9959 - val_loss: 0.0171\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9955 - loss: 0.0179\nValidation accuracy: 99.59%\nAverage Validation Accuracy for SNLI RNN Model: 99.31%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Training and evaluating on MNLI Matched dataset:\")\naverage_accuracy_mnli_matched = train_and_evaluate_kfold(X_mnli_matched_rnn, y_encoded_mnli_matched, 'MNLI Matched RNN Model')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:36:22.337999Z","iopub.execute_input":"2024-04-17T09:36:22.338282Z","iopub.status.idle":"2024-04-17T09:37:42.735054Z","shell.execute_reply.started":"2024-04-17T09:36:22.338257Z","shell.execute_reply":"2024-04-17T09:37:42.734185Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Training and evaluating on MNLI Matched dataset:\nTraining fold for MNLI Matched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.8607 - loss: 0.3961 - val_accuracy: 0.9674 - val_loss: 0.0911\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1216 - val_accuracy: 0.9812 - val_loss: 0.0596\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0832 - val_accuracy: 0.9878 - val_loss: 0.0408\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0613 - val_accuracy: 0.9934 - val_loss: 0.0278\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0448 - val_accuracy: 0.9954 - val_loss: 0.0216\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0408 - val_accuracy: 0.9949 - val_loss: 0.0183\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0319 - val_accuracy: 0.9939 - val_loss: 0.0185\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0273 - val_accuracy: 0.9959 - val_loss: 0.0139\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0286 - val_accuracy: 0.9944 - val_loss: 0.0129\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0296 - val_accuracy: 0.9939 - val_loss: 0.0128\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0125\nValidation accuracy: 99.39%\nTraining fold for MNLI Matched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.8373 - loss: 0.4259 - val_accuracy: 0.9598 - val_loss: 0.0897\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1144 - val_accuracy: 0.9822 - val_loss: 0.0577\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9624 - loss: 0.0921 - val_accuracy: 0.9837 - val_loss: 0.0429\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0664 - val_accuracy: 0.9888 - val_loss: 0.0330\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0592 - val_accuracy: 0.9908 - val_loss: 0.0246\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0402 - val_accuracy: 0.9949 - val_loss: 0.0215\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0369 - val_accuracy: 0.9924 - val_loss: 0.0198\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0363 - val_accuracy: 0.9929 - val_loss: 0.0175\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0337 - val_accuracy: 0.9954 - val_loss: 0.0148\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0230 - val_accuracy: 0.9934 - val_loss: 0.0159\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0144\nValidation accuracy: 99.54%\nTraining fold for MNLI Matched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.8375 - loss: 0.4150 - val_accuracy: 0.9562 - val_loss: 0.0955\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1053 - val_accuracy: 0.9817 - val_loss: 0.0626\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.0823 - val_accuracy: 0.9868 - val_loss: 0.0447\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0561 - val_accuracy: 0.9878 - val_loss: 0.0351\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0488 - val_accuracy: 0.9888 - val_loss: 0.0289\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0472 - val_accuracy: 0.9924 - val_loss: 0.0214\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0358 - val_accuracy: 0.9944 - val_loss: 0.0179\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0279 - val_accuracy: 0.9949 - val_loss: 0.0162\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0269 - val_accuracy: 0.9944 - val_loss: 0.0143\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0238 - val_accuracy: 0.9954 - val_loss: 0.0130\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0105\nValidation accuracy: 99.54%\nTraining fold for MNLI Matched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.8515 - loss: 0.3864 - val_accuracy: 0.9664 - val_loss: 0.1040\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1237 - val_accuracy: 0.9832 - val_loss: 0.0628\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0792 - val_accuracy: 0.9868 - val_loss: 0.0427\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0600 - val_accuracy: 0.9908 - val_loss: 0.0312\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0503 - val_accuracy: 0.9908 - val_loss: 0.0259\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0431 - val_accuracy: 0.9949 - val_loss: 0.0214\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0361 - val_accuracy: 0.9934 - val_loss: 0.0189\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0306 - val_accuracy: 0.9954 - val_loss: 0.0167\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0314 - val_accuracy: 0.9949 - val_loss: 0.0133\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0255 - val_accuracy: 0.9964 - val_loss: 0.0130\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0119\nValidation accuracy: 99.64%\nTraining fold for MNLI Matched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.8546 - loss: 0.4060 - val_accuracy: 0.9450 - val_loss: 0.1150\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1168 - val_accuracy: 0.9699 - val_loss: 0.0787\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.0829 - val_accuracy: 0.9786 - val_loss: 0.0559\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0640 - val_accuracy: 0.9796 - val_loss: 0.0427\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0499 - val_accuracy: 0.9806 - val_loss: 0.0380\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0430 - val_accuracy: 0.9903 - val_loss: 0.0275\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0374 - val_accuracy: 0.9934 - val_loss: 0.0230\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0325 - val_accuracy: 0.9862 - val_loss: 0.0299\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0311 - val_accuracy: 0.9918 - val_loss: 0.0212\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0246 - val_accuracy: 0.9939 - val_loss: 0.0190\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0172\nValidation accuracy: 99.39%\nAverage Validation Accuracy for MNLI Matched RNN Model: 99.50%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Training and evaluating on MNLI Mismatched dataset:\")\naverage_accuracy_mnli_mismatched = train_and_evaluate_kfold(X_mnli_mismatched_rnn, y_encoded_mnli_mismatched, 'MNLI Mismatched RNN Model')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:37:42.736458Z","iopub.execute_input":"2024-04-17T09:37:42.736842Z","iopub.status.idle":"2024-04-17T09:39:31.690890Z","shell.execute_reply.started":"2024-04-17T09:37:42.736810Z","shell.execute_reply":"2024-04-17T09:39:31.689798Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Training and evaluating on MNLI Mismatched dataset:\nTraining fold for MNLI Mismatched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - accuracy: 0.8547 - loss: 0.3856 - val_accuracy: 0.9573 - val_loss: 0.0965\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1116 - val_accuracy: 0.9756 - val_loss: 0.0676\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.0760 - val_accuracy: 0.9827 - val_loss: 0.0495\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0648 - val_accuracy: 0.9929 - val_loss: 0.0390\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0510 - val_accuracy: 0.9832 - val_loss: 0.0381\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0453 - val_accuracy: 0.9853 - val_loss: 0.0317\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0353 - val_accuracy: 0.9858 - val_loss: 0.0310\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0355 - val_accuracy: 0.9883 - val_loss: 0.0259\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0297 - val_accuracy: 0.9934 - val_loss: 0.0199\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0319 - val_accuracy: 0.9888 - val_loss: 0.0218\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0188\nValidation accuracy: 99.34%\nTraining fold for MNLI Mismatched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - accuracy: 0.8663 - loss: 0.3673 - val_accuracy: 0.9583 - val_loss: 0.0974\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1148 - val_accuracy: 0.9781 - val_loss: 0.0656\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.0767 - val_accuracy: 0.9832 - val_loss: 0.0500\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0599 - val_accuracy: 0.9883 - val_loss: 0.0376\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0556 - val_accuracy: 0.9853 - val_loss: 0.0338\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0434 - val_accuracy: 0.9878 - val_loss: 0.0274\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0387 - val_accuracy: 0.9883 - val_loss: 0.0242\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0336 - val_accuracy: 0.9939 - val_loss: 0.0214\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0320 - val_accuracy: 0.9919 - val_loss: 0.0213\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0322 - val_accuracy: 0.9934 - val_loss: 0.0209\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9915 - loss: 0.0227\nValidation accuracy: 99.34%\nTraining fold for MNLI Mismatched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - accuracy: 0.8651 - loss: 0.3940 - val_accuracy: 0.9613 - val_loss: 0.0942\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9535 - loss: 0.1183 - val_accuracy: 0.9771 - val_loss: 0.0633\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0834 - val_accuracy: 0.9817 - val_loss: 0.0475\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0646 - val_accuracy: 0.9893 - val_loss: 0.0347\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0519 - val_accuracy: 0.9898 - val_loss: 0.0273\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0491 - val_accuracy: 0.9914 - val_loss: 0.0250\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0340 - val_accuracy: 0.9934 - val_loss: 0.0193\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0341 - val_accuracy: 0.9929 - val_loss: 0.0180\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0282 - val_accuracy: 0.9964 - val_loss: 0.0155\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0366 - val_accuracy: 0.9954 - val_loss: 0.0141\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0152\nValidation accuracy: 99.54%\nTraining fold for MNLI Mismatched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - accuracy: 0.8635 - loss: 0.3866 - val_accuracy: 0.9680 - val_loss: 0.0890\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1229 - val_accuracy: 0.9822 - val_loss: 0.0570\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.0863 - val_accuracy: 0.9883 - val_loss: 0.0409\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0656 - val_accuracy: 0.9888 - val_loss: 0.0344\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0523 - val_accuracy: 0.9908 - val_loss: 0.0269\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0497 - val_accuracy: 0.9903 - val_loss: 0.0233\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0400 - val_accuracy: 0.9924 - val_loss: 0.0198\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0356 - val_accuracy: 0.9939 - val_loss: 0.0187\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0287 - val_accuracy: 0.9944 - val_loss: 0.0169\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0301 - val_accuracy: 0.9949 - val_loss: 0.0161\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0172\nValidation accuracy: 99.49%\nTraining fold for MNLI Mismatched RNN Model...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - accuracy: 0.8279 - loss: 0.4205 - val_accuracy: 0.9507 - val_loss: 0.1103\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1193 - val_accuracy: 0.9766 - val_loss: 0.0726\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.0828 - val_accuracy: 0.9842 - val_loss: 0.0502\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0680 - val_accuracy: 0.9893 - val_loss: 0.0405\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0556 - val_accuracy: 0.9873 - val_loss: 0.0346\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0475 - val_accuracy: 0.9858 - val_loss: 0.0357\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0383 - val_accuracy: 0.9908 - val_loss: 0.0278\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0350 - val_accuracy: 0.9903 - val_loss: 0.0262\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0304 - val_accuracy: 0.9934 - val_loss: 0.0235\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0317 - val_accuracy: 0.9944 - val_loss: 0.0222\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0182   \nValidation accuracy: 99.44%\nAverage Validation Accuracy for MNLI Mismatched RNN Model: 99.43%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Training and evaluating on ANLI Round 1 dataset:\")\naverage_accuracy_anli_r1 = train_and_evaluate_kfold(X_anli_r1_rnn, y_encoded_anli_r1, 'ANLI Round 1 RNN Model')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:39:31.692254Z","iopub.execute_input":"2024-04-17T09:39:31.692626Z","iopub.status.idle":"2024-04-17T09:40:06.387160Z","shell.execute_reply.started":"2024-04-17T09:39:31.692593Z","shell.execute_reply":"2024-04-17T09:40:06.386275Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Training and evaluating on ANLI Round 1 dataset:\nTraining fold for ANLI Round 1 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.5193 - loss: 0.9861 - val_accuracy: 0.8000 - val_loss: 0.6735\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.7048 - val_accuracy: 0.8200 - val_loss: 0.5357\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.5463 - val_accuracy: 0.8400 - val_loss: 0.4467\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.4551 - val_accuracy: 0.8550 - val_loss: 0.3748\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.4157 - val_accuracy: 0.8550 - val_loss: 0.3287\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.3586 - val_accuracy: 0.8800 - val_loss: 0.2898\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.3206 - val_accuracy: 0.8900 - val_loss: 0.2607\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2888 - val_accuracy: 0.8950 - val_loss: 0.2360\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2596 - val_accuracy: 0.8950 - val_loss: 0.2185\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2390 - val_accuracy: 0.9050 - val_loss: 0.1974\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2225 \nValidation accuracy: 90.50%\nTraining fold for ANLI Round 1 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4101 - loss: 1.1521 - val_accuracy: 0.7550 - val_loss: 0.6767\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7094 - loss: 0.7060 - val_accuracy: 0.8200 - val_loss: 0.5014\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.5680 - val_accuracy: 0.8600 - val_loss: 0.4033\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.4953 - val_accuracy: 0.8700 - val_loss: 0.3460\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.4213 - val_accuracy: 0.8950 - val_loss: 0.3037\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.3872 - val_accuracy: 0.9050 - val_loss: 0.2666\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3731 - val_accuracy: 0.9200 - val_loss: 0.2446\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3399 - val_accuracy: 0.9450 - val_loss: 0.2244\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.3091 - val_accuracy: 0.9550 - val_loss: 0.2094\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.2730 - val_accuracy: 0.9550 - val_loss: 0.1904\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.2025 \nValidation accuracy: 95.50%\nTraining fold for ANLI Round 1 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4126 - loss: 1.1070 - val_accuracy: 0.7750 - val_loss: 0.6535\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.7312 - val_accuracy: 0.8450 - val_loss: 0.4612\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.5560 - val_accuracy: 0.8800 - val_loss: 0.3659\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.5025 - val_accuracy: 0.8850 - val_loss: 0.3147\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.4497 - val_accuracy: 0.9000 - val_loss: 0.2758\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.4286 - val_accuracy: 0.9000 - val_loss: 0.2490\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3644 - val_accuracy: 0.9050 - val_loss: 0.2274\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.3422 - val_accuracy: 0.9050 - val_loss: 0.2051\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3306 - val_accuracy: 0.9100 - val_loss: 0.1884\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2904 - val_accuracy: 0.9150 - val_loss: 0.1731\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.1587 \nValidation accuracy: 91.50%\nTraining fold for ANLI Round 1 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.5306 - loss: 0.9844 - val_accuracy: 0.8350 - val_loss: 0.5284\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7552 - loss: 0.6797 - val_accuracy: 0.8650 - val_loss: 0.3637\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.4978 - val_accuracy: 0.8900 - val_loss: 0.3219\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.4267 - val_accuracy: 0.8950 - val_loss: 0.2899\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.4383 - val_accuracy: 0.9050 - val_loss: 0.2568\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3696 - val_accuracy: 0.9150 - val_loss: 0.2343\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.3313 - val_accuracy: 0.9200 - val_loss: 0.2151\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.3174 - val_accuracy: 0.9250 - val_loss: 0.2011\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3253 - val_accuracy: 0.9300 - val_loss: 0.1815\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.2953 - val_accuracy: 0.9400 - val_loss: 0.1679\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1826 \nValidation accuracy: 94.00%\nTraining fold for ANLI Round 1 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4131 - loss: 1.1683 - val_accuracy: 0.8000 - val_loss: 0.6381\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.6828 - val_accuracy: 0.8450 - val_loss: 0.5083\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.5675 - val_accuracy: 0.8600 - val_loss: 0.4385\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.5070 - val_accuracy: 0.8800 - val_loss: 0.3784\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3802 - val_accuracy: 0.8850 - val_loss: 0.3452\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.3810 - val_accuracy: 0.8950 - val_loss: 0.3171\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3409 - val_accuracy: 0.9050 - val_loss: 0.2915\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.3126 - val_accuracy: 0.9050 - val_loss: 0.2683\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2837 - val_accuracy: 0.9150 - val_loss: 0.2499\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.2785 - val_accuracy: 0.9300 - val_loss: 0.2291\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2154 \nValidation accuracy: 93.00%\nAverage Validation Accuracy for ANLI Round 1 RNN Model: 92.90%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Training and evaluating on ANLI Round 2 dataset:\")\naverage_accuracy_anli_r2 = train_and_evaluate_kfold(X_anli_r2_rnn, y_encoded_anli_r2, 'ANLI Round 2 RNN Model')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:40:06.388340Z","iopub.execute_input":"2024-04-17T09:40:06.388626Z","iopub.status.idle":"2024-04-17T09:40:39.969859Z","shell.execute_reply.started":"2024-04-17T09:40:06.388602Z","shell.execute_reply":"2024-04-17T09:40:39.969084Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Training and evaluating on ANLI Round 2 dataset:\nTraining fold for ANLI Round 2 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.4652 - loss: 1.0992 - val_accuracy: 0.7750 - val_loss: 0.6413\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6469 - loss: 0.8068 - val_accuracy: 0.8400 - val_loss: 0.4997\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.6330 - val_accuracy: 0.8650 - val_loss: 0.4057\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.5336 - val_accuracy: 0.8800 - val_loss: 0.3412\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.5394 - val_accuracy: 0.9000 - val_loss: 0.2960\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.4303 - val_accuracy: 0.9100 - val_loss: 0.2578\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8532 - loss: 0.3893 - val_accuracy: 0.9100 - val_loss: 0.2353\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.3887 - val_accuracy: 0.9100 - val_loss: 0.2133\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.3466 - val_accuracy: 0.9150 - val_loss: 0.1964\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.3236 - val_accuracy: 0.9200 - val_loss: 0.1768\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2037 \nValidation accuracy: 92.00%\nTraining fold for ANLI Round 2 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.4588 - loss: 1.0581 - val_accuracy: 0.7700 - val_loss: 0.7061\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.7180 - val_accuracy: 0.7950 - val_loss: 0.5714\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.6423 - val_accuracy: 0.8500 - val_loss: 0.4590\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.5606 - val_accuracy: 0.8700 - val_loss: 0.3898\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.5163 - val_accuracy: 0.8850 - val_loss: 0.3361\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.4333 - val_accuracy: 0.9150 - val_loss: 0.2929\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3826 - val_accuracy: 0.9200 - val_loss: 0.2538\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8736 - loss: 0.3262 - val_accuracy: 0.9200 - val_loss: 0.2258\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.3185 - val_accuracy: 0.9200 - val_loss: 0.2091\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.3194 - val_accuracy: 0.9250 - val_loss: 0.1897\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.1961 \nValidation accuracy: 92.50%\nTraining fold for ANLI Round 2 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4516 - loss: 1.0667 - val_accuracy: 0.7150 - val_loss: 0.7532\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.7479 - val_accuracy: 0.7200 - val_loss: 0.6441\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.6187 - val_accuracy: 0.7450 - val_loss: 0.5611\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7806 - loss: 0.5268 - val_accuracy: 0.7900 - val_loss: 0.4831\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.5030 - val_accuracy: 0.8200 - val_loss: 0.4223\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.4386 - val_accuracy: 0.8350 - val_loss: 0.3768\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.3599 - val_accuracy: 0.8800 - val_loss: 0.3347\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3614 - val_accuracy: 0.9100 - val_loss: 0.2977\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3354 - val_accuracy: 0.9050 - val_loss: 0.2746\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 0.3263 - val_accuracy: 0.9100 - val_loss: 0.2413\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2185 \nValidation accuracy: 91.00%\nTraining fold for ANLI Round 2 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.5411 - loss: 0.9619 - val_accuracy: 0.7950 - val_loss: 0.6292\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 0.7526 - val_accuracy: 0.8250 - val_loss: 0.4766\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.6161 - val_accuracy: 0.8550 - val_loss: 0.3768\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.5565 - val_accuracy: 0.8750 - val_loss: 0.3143\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4987 - val_accuracy: 0.9150 - val_loss: 0.2690\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8510 - loss: 0.4144 - val_accuracy: 0.9200 - val_loss: 0.2309\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8803 - loss: 0.3717 - val_accuracy: 0.9300 - val_loss: 0.2042\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.3551 - val_accuracy: 0.9500 - val_loss: 0.1854\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3499 - val_accuracy: 0.9550 - val_loss: 0.1636\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.2942 - val_accuracy: 0.9550 - val_loss: 0.1487\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1524 \nValidation accuracy: 95.50%\nTraining fold for ANLI Round 2 RNN Model...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4472 - loss: 1.1342 - val_accuracy: 0.7150 - val_loss: 0.7648\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6755 - loss: 0.7934 - val_accuracy: 0.7750 - val_loss: 0.6397\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.6377 - val_accuracy: 0.7850 - val_loss: 0.5690\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.5038 - val_accuracy: 0.8000 - val_loss: 0.5217\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.5054 - val_accuracy: 0.8100 - val_loss: 0.4843\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.4508 - val_accuracy: 0.8150 - val_loss: 0.4443\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8878 - loss: 0.3723 - val_accuracy: 0.8550 - val_loss: 0.4094\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3885 - val_accuracy: 0.8650 - val_loss: 0.3759\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.3262 - val_accuracy: 0.8750 - val_loss: 0.3483\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3271 - val_accuracy: 0.9050 - val_loss: 0.3185\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2880 \nValidation accuracy: 90.50%\nAverage Validation Accuracy for ANLI Round 2 RNN Model: 92.30%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Training and evaluating on ANLI Round 3 dataset:\")\naverage_accuracy_anli_r3 = train_and_evaluate_kfold(X_anli_r3_rnn, y_encoded_anli_r3, 'ANLI Round 3 RNN Model')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:40:39.971133Z","iopub.execute_input":"2024-04-17T09:40:39.971412Z","iopub.status.idle":"2024-04-17T09:41:14.504099Z","shell.execute_reply.started":"2024-04-17T09:40:39.971387Z","shell.execute_reply":"2024-04-17T09:41:14.503158Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Training and evaluating on ANLI Round 3 dataset:\nTraining fold for ANLI Round 3 RNN Model...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.3737 - loss: 1.1147 - val_accuracy: 0.8083 - val_loss: 0.6255\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.7573 - val_accuracy: 0.8500 - val_loss: 0.4577\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.5962 - val_accuracy: 0.8750 - val_loss: 0.3610\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8016 - loss: 0.5376 - val_accuracy: 0.8875 - val_loss: 0.3033\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.4693 - val_accuracy: 0.9208 - val_loss: 0.2637\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8696 - loss: 0.3829 - val_accuracy: 0.9250 - val_loss: 0.2325\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.3527 - val_accuracy: 0.9292 - val_loss: 0.2100\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3403 - val_accuracy: 0.9458 - val_loss: 0.1912\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2761 - val_accuracy: 0.9417 - val_loss: 0.1760\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.3032 - val_accuracy: 0.9500 - val_loss: 0.1605\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1534 \nValidation accuracy: 95.00%\nTraining fold for ANLI Round 3 RNN Model...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.4988 - loss: 1.0141 - val_accuracy: 0.8208 - val_loss: 0.6440\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 0.6875 - val_accuracy: 0.8458 - val_loss: 0.4960\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7674 - loss: 0.5574 - val_accuracy: 0.8667 - val_loss: 0.4180\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.4896 - val_accuracy: 0.8833 - val_loss: 0.3617\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.4553 - val_accuracy: 0.8875 - val_loss: 0.3188\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4128 - val_accuracy: 0.8958 - val_loss: 0.2853\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.3312 - val_accuracy: 0.8958 - val_loss: 0.2643\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: 0.3127 - val_accuracy: 0.9042 - val_loss: 0.2398\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.2716 - val_accuracy: 0.9083 - val_loss: 0.2161\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.2800 - val_accuracy: 0.9250 - val_loss: 0.1992\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.1846 \nValidation accuracy: 92.50%\nTraining fold for ANLI Round 3 RNN Model...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.4960 - loss: 1.0343 - val_accuracy: 0.7167 - val_loss: 0.7046\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.6867 - val_accuracy: 0.7542 - val_loss: 0.5609\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5899 - val_accuracy: 0.8083 - val_loss: 0.4678\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4794 - val_accuracy: 0.8667 - val_loss: 0.4080\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4786 - val_accuracy: 0.8667 - val_loss: 0.3608\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3979 - val_accuracy: 0.9000 - val_loss: 0.3226\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3421 - val_accuracy: 0.9083 - val_loss: 0.2955\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.3065 - val_accuracy: 0.9167 - val_loss: 0.2707\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2928 - val_accuracy: 0.9167 - val_loss: 0.2454\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2703 - val_accuracy: 0.9292 - val_loss: 0.2254\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.2058 \nValidation accuracy: 92.92%\nTraining fold for ANLI Round 3 RNN Model...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.4519 - loss: 1.0211 - val_accuracy: 0.7750 - val_loss: 0.6563\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6957 - loss: 0.7323 - val_accuracy: 0.8167 - val_loss: 0.5195\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.6114 - val_accuracy: 0.8500 - val_loss: 0.4457\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4634 - val_accuracy: 0.8625 - val_loss: 0.3849\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.4578 - val_accuracy: 0.9042 - val_loss: 0.3413\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.4202 - val_accuracy: 0.9167 - val_loss: 0.3049\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3819 - val_accuracy: 0.9167 - val_loss: 0.2726\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.3050 - val_accuracy: 0.9292 - val_loss: 0.2541\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8863 - loss: 0.3056 - val_accuracy: 0.9250 - val_loss: 0.2309\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.2756 - val_accuracy: 0.9333 - val_loss: 0.2165\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2253 \nValidation accuracy: 93.33%\nTraining fold for ANLI Round 3 RNN Model...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.4185 - loss: 1.0794 - val_accuracy: 0.7708 - val_loss: 0.6686\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.7407 - val_accuracy: 0.8083 - val_loss: 0.5054\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.5833 - val_accuracy: 0.8708 - val_loss: 0.4086\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.5079 - val_accuracy: 0.8958 - val_loss: 0.3480\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.4591 - val_accuracy: 0.9125 - val_loss: 0.3042\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3921 - val_accuracy: 0.9208 - val_loss: 0.2680\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3899 - val_accuracy: 0.9417 - val_loss: 0.2413\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8830 - loss: 0.3222 - val_accuracy: 0.9458 - val_loss: 0.2173\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8816 - loss: 0.3221 - val_accuracy: 0.9417 - val_loss: 0.1996\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2874 - val_accuracy: 0.9500 - val_loss: 0.1817\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1737 \nValidation accuracy: 95.00%\nAverage Validation Accuracy for ANLI Round 3 RNN Model: 93.75%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Determining the maximum number of features\nmax_features = max(X_snli_scaled.shape[1], X_mnli_matched_scaled.shape[1], X_mnli_mismatched_scaled.shape[1],\n                   X_anli_r1_scaled.shape[1], X_anli_r2_scaled.shape[1], X_anli_r3_scaled.shape[1])\n\n# Function to pad arrays to the maximum feature size\ndef pad_features(X, max_features):\n    padding = max_features - X.shape[1]\n    return np.pad(X, ((0, 0), (0, padding)), 'constant')\n\n# Pad each dataset\nX_snli_rnn = pad_features(X_snli_scaled, max_features).reshape(-1, 1, max_features)\nX_mnli_matched_rnn = pad_features(X_mnli_matched_scaled, max_features).reshape(-1, 1, max_features)\nX_mnli_mismatched_rnn = pad_features(X_mnli_mismatched_scaled, max_features).reshape(-1, 1, max_features)\nX_anli_r1_rnn = pad_features(X_anli_r1_scaled, max_features).reshape(-1, 1, max_features)\nX_anli_r2_rnn = pad_features(X_anli_r2_scaled, max_features).reshape(-1, 1, max_features)\nX_anli_r3_rnn = pad_features(X_anli_r3_scaled, max_features).reshape(-1, 1, max_features)\n\n# Concatenate all reshaped and padded arrays\nX_combined_rnn = np.concatenate((X_snli_rnn, X_mnli_matched_rnn, X_mnli_mismatched_rnn, X_anli_r1_rnn, X_anli_r2_rnn, X_anli_r3_rnn), axis=0)\ny_combined = np.concatenate((y_encoded_snli, y_encoded_mnli_matched, y_encoded_mnli_mismatched, y_encoded_anli_r1, y_encoded_anli_r2, y_encoded_anli_r3), axis=0)\n\nprint(\"Shape of combined feature set:\", X_combined_rnn.shape)\nprint(\"Shape of combined label set:\", y_combined.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:50:00.110739Z","iopub.execute_input":"2024-04-17T09:50:00.111084Z","iopub.status.idle":"2024-04-17T09:50:00.125728Z","shell.execute_reply.started":"2024-04-17T09:50:00.111059Z","shell.execute_reply":"2024-04-17T09:50:00.124736Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Shape of combined feature set: (32671, 1, 18)\nShape of combined label set: (32671, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef train_and_evaluate_kfold_all(X, y, name, n_splits=5):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    all_scores = []\n\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n\n        model = create_rnn_model(X_train.shape[1:], y_train.shape[1])\n\n        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n        print(f\"Training fold for {name}...\")\n        model.fit(X_train, y_train, epochs=10, batch_size=32,\n                  validation_data=(X_val, y_val), callbacks=[early_stopping])\n\n        val_loss, val_accuracy = model.evaluate(X_val, y_val)\n        all_scores.append(val_accuracy)\n        print(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n\n    average_accuracy = np.mean(all_scores)\n    print(f\"Average Validation Accuracy for {name}: {average_accuracy * 100:.2f}%\")\n    return model, average_accuracy\n\n\n\n# Example usage:\nmodel,average_combined_accuracy = train_and_evaluate_kfold_all(X_combined_rnn, y_combined, 'All Tasks RNN Model')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T09:57:05.525637Z","iopub.execute_input":"2024-04-17T09:57:05.526386Z","iopub.status.idle":"2024-04-17T09:59:51.706272Z","shell.execute_reply.started":"2024-04-17T09:57:05.526355Z","shell.execute_reply":"2024-04-17T09:59:51.705386Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Training fold for All Tasks RNN Model...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.8642 - loss: 0.3456 - val_accuracy: 0.9685 - val_loss: 0.0872\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1039 - val_accuracy: 0.9786 - val_loss: 0.0547\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0703 - val_accuracy: 0.9830 - val_loss: 0.0414\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0523 - val_accuracy: 0.9849 - val_loss: 0.0338\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0443 - val_accuracy: 0.9876 - val_loss: 0.0290\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0379 - val_accuracy: 0.9891 - val_loss: 0.0263\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0391 - val_accuracy: 0.9901 - val_loss: 0.0234\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0335 - val_accuracy: 0.9923 - val_loss: 0.0210\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0329 - val_accuracy: 0.9927 - val_loss: 0.0209\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0289 - val_accuracy: 0.9925 - val_loss: 0.0187\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0172\nValidation accuracy: 99.25%\nTraining fold for All Tasks RNN Model...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8912 - loss: 0.3091 - val_accuracy: 0.9699 - val_loss: 0.0882\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1049 - val_accuracy: 0.9821 - val_loss: 0.0533\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0739 - val_accuracy: 0.9852 - val_loss: 0.0417\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0557 - val_accuracy: 0.9864 - val_loss: 0.0320\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0470 - val_accuracy: 0.9891 - val_loss: 0.0270\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0394 - val_accuracy: 0.9904 - val_loss: 0.0234\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0390 - val_accuracy: 0.9910 - val_loss: 0.0243\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0365 - val_accuracy: 0.9914 - val_loss: 0.0211\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0325 - val_accuracy: 0.9911 - val_loss: 0.0220\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0304 - val_accuracy: 0.9928 - val_loss: 0.0196\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9931 - loss: 0.0170\nValidation accuracy: 99.28%\nTraining fold for All Tasks RNN Model...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.8754 - loss: 0.3363 - val_accuracy: 0.9679 - val_loss: 0.0890\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9567 - loss: 0.1088 - val_accuracy: 0.9781 - val_loss: 0.0592\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.0838 - val_accuracy: 0.9858 - val_loss: 0.0411\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0599 - val_accuracy: 0.9882 - val_loss: 0.0323\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0527 - val_accuracy: 0.9902 - val_loss: 0.0287\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0480 - val_accuracy: 0.9913 - val_loss: 0.0242\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0415 - val_accuracy: 0.9908 - val_loss: 0.0222\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0415 - val_accuracy: 0.9920 - val_loss: 0.0198\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0350 - val_accuracy: 0.9917 - val_loss: 0.0210\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0359 - val_accuracy: 0.9927 - val_loss: 0.0198\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0135\nValidation accuracy: 99.27%\nTraining fold for All Tasks RNN Model...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8825 - loss: 0.3056 - val_accuracy: 0.9706 - val_loss: 0.0841\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9601 - loss: 0.1011 - val_accuracy: 0.9787 - val_loss: 0.0527\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0744 - val_accuracy: 0.9848 - val_loss: 0.0432\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0588 - val_accuracy: 0.9873 - val_loss: 0.0347\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0495 - val_accuracy: 0.9876 - val_loss: 0.0290\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0412 - val_accuracy: 0.9890 - val_loss: 0.0259\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0400 - val_accuracy: 0.9901 - val_loss: 0.0241\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0358 - val_accuracy: 0.9904 - val_loss: 0.0223\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0359 - val_accuracy: 0.9923 - val_loss: 0.0217\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0322 - val_accuracy: 0.9916 - val_loss: 0.0200\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0170\nValidation accuracy: 99.16%\nTraining fold for All Tasks RNN Model...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.8746 - loss: 0.3282 - val_accuracy: 0.9694 - val_loss: 0.0907\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1094 - val_accuracy: 0.9793 - val_loss: 0.0531\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0752 - val_accuracy: 0.9844 - val_loss: 0.0413\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0608 - val_accuracy: 0.9864 - val_loss: 0.0323\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0503 - val_accuracy: 0.9919 - val_loss: 0.0281\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0383 - val_accuracy: 0.9911 - val_loss: 0.0246\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0410 - val_accuracy: 0.9930 - val_loss: 0.0218\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0355 - val_accuracy: 0.9927 - val_loss: 0.0206\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0322 - val_accuracy: 0.9907 - val_loss: 0.0205\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0333 - val_accuracy: 0.9934 - val_loss: 0.0178\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0149\nValidation accuracy: 99.34%\nAverage Validation Accuracy for All Tasks RNN Model: 99.26%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model after training\nmodel.save('RNN_features_ensemble.h5')\nprint(\"Model saved to 'RNN_features_ensemble'.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:00:43.691388Z","iopub.execute_input":"2024-04-17T10:00:43.692153Z","iopub.status.idle":"2024-04-17T10:00:43.718204Z","shell.execute_reply.started":"2024-04-17T10:00:43.692121Z","shell.execute_reply":"2024-04-17T10:00:43.717361Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Model saved to 'RNN_features_ensemble'.\n","output_type":"stream"}]}]}