{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2933,"sourceType":"datasetVersion","datasetId":1670},{"sourceId":4548821,"sourceType":"datasetVersion","datasetId":2655798},{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport pandas as pd\nimport torch\nfrom tqdm.auto import tqdm\n\n\n# Define model names for easy reference\nmodel_names = {\n    \"deberta\": \"microsoft/deberta-large-mnli\",\n    \"albert\": \"ynie/albert-xxlarge-v2-snli_mnli_fever_anli_R1_R2_R3-nli\",\n    \"roberta\": \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n}\n\n# Load models and tokenizers\nmodels = {name: AutoModelForSequenceClassification.from_pretrained(model_names[name]) for name in model_names}\ntokenizers = {name: AutoTokenizer.from_pretrained(model_names[name]) for name in model_names}\n\n# Check GPU availability\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-09T20:29:29.937477Z","iopub.execute_input":"2024-04-09T20:29:29.937835Z","iopub.status.idle":"2024-04-09T20:30:00.390397Z","shell.execute_reply.started":"2024-04-09T20:29:29.937805Z","shell.execute_reply":"2024-04-09T20:30:00.389539Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"119fb8bedb8b4405812767bed3b1559c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.62G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8fe1905a2c0483d9d02baab8c749eff"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/896 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd72c4eae0640fdb5bf721c4f77284c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/890M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57af22a768654a94ac9745318a80dd04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/703 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"196c5e17906649bea4c48b0c667cc889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367b9f8873db43d0a0890ea604aadf17"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8924317497b43cb8d0bb9df2520222f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7810da106c44f58bf33544e596f1f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66fd8399415b44178be67b8082bc59a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfd6157a35824d9f871dd34ca83701d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbd473f3fbec49828a0ef5fc4c524a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5136a4c4d679475580f518f99981b384"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"900f2e3947504325abdf27ee768bc32e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36cbd308c49543288a7bfeb8d485b427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d430b25e99c4b5ebb25852302860dac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7b8f69ea64a4414a8549c1d44549b85"}},"metadata":{}}]},{"cell_type":"code","source":"# MNLI-m test dataset\n\ndf_mnlim = pd.read_csv('/kaggle/input/nli-dataset-for-sentence-understanding/mnli_test_matched.csv')\n\n# MNLI-mm test dataset\n\ndf_mnlimm = pd.read_csv('/kaggle/input/nli-dataset-for-sentence-understanding/mnli_test_mismatched.csv')\n\n# ANLI test dataset round 1\n\ndf_anli1 = pd.read_csv('/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r1.csv')\n\n# ANLI test dataset round 2\n\ndf_anli2 = pd.read_csv('/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r2.csv')\n\n# ANLI test dataset round 3\n\ndf_anli3 = pd.read_csv('/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r3.csv')\n\n# SNLI test dataset\n\ndf_snli = pd.read_csv('/kaggle/input/stanford-natural-language-inference-corpus/snli_1.0_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T20:30:00.392013Z","iopub.execute_input":"2024-04-09T20:30:00.392516Z","iopub.status.idle":"2024-04-09T20:30:00.742737Z","shell.execute_reply.started":"2024-04-09T20:30:00.392488Z","shell.execute_reply":"2024-04-09T20:30:00.741920Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"datasets = {\n    \"mnli_matched\": df_mnlim,\n    \"mnli_mismatched\": df_mnlimm,\n    \"anli1\": df_anli1,\n    \"anli2\": df_anli2,\n    \"anli3\": df_anli3,\n    \"snli\": df_snli\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-09T20:30:00.744000Z","iopub.execute_input":"2024-04-09T20:30:00.744679Z","iopub.status.idle":"2024-04-09T20:30:02.338308Z","shell.execute_reply.started":"2024-04-09T20:30:00.744637Z","shell.execute_reply":"2024-04-09T20:30:02.337274Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Function for data preprocessing (specifically for ANLI dataset in this setup)\ndef preprocess_data(df, tokenizer_name):\n    concatenated_hypotheses = df['hypothesis'] + \" [SEP] \" + df['reason']\n    return tokenizers[tokenizer_name](df['premise'].tolist(), concatenated_hypotheses.tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T20:30:02.340632Z","iopub.execute_input":"2024-04-09T20:30:02.341282Z","iopub.status.idle":"2024-04-09T20:30:02.348830Z","shell.execute_reply.started":"2024-04-09T20:30:02.341247Z","shell.execute_reply":"2024-04-09T20:30:02.348029Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_predict_to_df(tokenizer, model, df, dataset_name, preprocess_fn=None):\n    all_probs = []\n    batch_size = 8  # Adjust based on your GPU memory\n    model.eval()\n    model.to(device)\n    \n    # Determine column names based on dataset\n    text_columns = ['sentence1', 'sentence2'] if 'sentence1' in df.columns else ['premise', 'hypothesis']\n    \n    for batch_start in tqdm(range(0, len(df), batch_size), desc=f\"Predicting {dataset_name}\"):\n        batch_end = min(batch_start + batch_size, len(df))\n        batch = df.iloc[batch_start:batch_end]\n        \n        if preprocess_fn:\n            tokenized_inputs = preprocess_fn(batch, tokenizer)\n        else:\n            if dataset_name == \"snli\":\n                tokenized_inputs = tokenizer(batch['sentence1'].tolist(), batch['sentence2'].tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n            else:\n                tokenized_inputs = tokenizer(batch['premise'].tolist(), batch['hypothesis'].tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n        \n        tokenized_inputs = {key: value.to(device) for key, value in tokenized_inputs.items()}\n        \n        with torch.no_grad():\n            outputs = model(**tokenized_inputs)\n            probs = torch.softmax(outputs.logits, dim=1).cpu().numpy()\n            all_probs.extend(probs)\n        \n        torch.cuda.empty_cache()\n    \n    probs_df = pd.DataFrame(all_probs, columns=['Entailment', 'Neutral', 'Contradiction'])\n    result_df = pd.concat([df[text_columns].reset_index(drop=True), probs_df], axis=1)\n    \n    return result_df\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T20:35:05.687214Z","iopub.execute_input":"2024-04-09T20:35:05.687598Z","iopub.status.idle":"2024-04-09T20:35:05.699961Z","shell.execute_reply.started":"2024-04-09T20:35:05.687566Z","shell.execute_reply":"2024-04-09T20:35:05.699104Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def process_datasets_and_save_to_csv(model_name, datasets):\n    print(f\"Processing with {model_name}\")\n    model = models[model_name].to(device)\n    tokenizer = tokenizers[model_name]\n\n    for dataset_name, df in datasets.items():\n        print(f\"Processing dataset: {dataset_name}\")\n        result_df = tokenize_and_predict_to_df(tokenizer, model, df, dataset_name, preprocess_fn=preprocess_data if \"anli\" in dataset_name else None)\n\n        csv_file_name = f\"{model_name}_{dataset_name}_results.csv\"\n        result_df.to_csv(csv_file_name, index=False)\n        print(f\"Results for {dataset_name} saved to {csv_file_name}\")\n\n    model.to('cpu')\n    del model\n    del tokenizer\n    torch.cuda.empty_cache()\n    print(f\"Finished processing and saving results for {model_name}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T20:35:07.807828Z","iopub.execute_input":"2024-04-09T20:35:07.808217Z","iopub.status.idle":"2024-04-09T20:35:07.815376Z","shell.execute_reply.started":"2024-04-09T20:35:07.808185Z","shell.execute_reply":"2024-04-09T20:35:07.814365Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for name in model_names.keys():\n    process_datasets_and_save_to_csv(name, datasets)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T20:35:09.628239Z","iopub.execute_input":"2024-04-09T20:35:09.628974Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Processing with deberta\nProcessing dataset: mnli_matched\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting mnli_matched:   0%|          | 0/1225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83ed154a0e15434caff710eebb5116b3"}},"metadata":{}},{"name":"stdout","text":"Results for mnli_matched saved to deberta_mnli_matched_results.csv\nProcessing dataset: mnli_mismatched\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting mnli_mismatched:   0%|          | 0/1231 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28221e50613a45e2b55aa5c87bf2ba72"}},"metadata":{}}]}]}